{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, precision_recall_curve, average_precision_score, mean_squared_error, r2_score, mean_absolute_error\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# preds\n",
    "\n",
    "# Load the training set of meta-model\n",
    "lipo_chemberta2_valid2 = pd.read_csv('./chemberta2/results/lipo/chemberta2_valid2_lipo_2_predictions.csv')\n",
    "lipo_molformer_valid2 = pd.read_csv('./molformer/results/lipo/molformer_valid2_lipo_2.csv')\n",
    "lipo_molbert_valid2 = pd.read_csv('./molbert/results/lipo/molbert_valid2_lipo_2.csv')\n",
    "\n",
    "# Load the test data for each model\n",
    "lipo_chemberta2_test = pd.read_csv('./chemberta2/results/lipo/chemberta2_test_lipo_2_predictions.csv')\n",
    "lipo_molformer_test = pd.read_csv('./molformer/results/lipo/molformer_test_lipo_2.csv')\n",
    "lipo_molbert_test = pd.read_csv('./molbert/results/lipo/molbert_test_lipo_2.csv')\n",
    "\n",
    "train_mean = 2.1799722222222226\n",
    "train_sd = 1.2045431891731355\n",
    "\n",
    "# features\n",
    "\n",
    "lipo_chemberta2_features_valid2 = pd.read_csv('./chemberta2/features/lipo/chemberta2_valid2_lipo_2_features.csv')\n",
    "lipo_chemberta2_features_test = pd.read_csv('./chemberta2/features/lipo/chemberta2_test_lipo_2_features.csv')\n",
    "\n",
    "lipo_molformer_features_valid2 = pd.read_csv('./molformer/features/lipo/molformer_valid2_lipo_2_features.csv')\n",
    "lipo_molformer_features_test = pd.read_csv('./molformer/features/lipo/molformer_test_lipo_2_features.csv')\n",
    "\n",
    "lipo_molbert_features_valid2 = pd.read_csv('./molbert/features/lipo/molbert_valid2_lipo_2_features.csv')\n",
    "lipo_molbert_features_test = pd.read_csv('./molbert/features/lipo/molbert_test_lipo_2_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Lipo (Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the actual and predicted values\n",
    "# Chemberta2\n",
    "lipo_chemberta_actual = lipo_chemberta2_test['target'] \n",
    "lipo_chemberta_pred = lipo_chemberta2_test['pred_raw']\n",
    "\n",
    "# Molformer\n",
    "lipo_molformer_actual = lipo_molformer_test['target']\n",
    "lipo_molformer_pred = lipo_molformer_test['pred_raw']\n",
    "\n",
    "# molbert\n",
    "lipo_molbert_actual = lipo_molbert_test['target_raw']\n",
    "lipo_molbert_pred = lipo_molbert_test['pred_raw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Chemberta2': {'MAE': 0.47080364152170984,\n",
       "  'RMSE': 0.6194242164406615,\n",
       "  'R2 Score': 0.725099924775132,\n",
       "  'Correlation': 0.8597960575490352},\n",
       " 'Molformer': {'MAE': 0.45518342900000003,\n",
       "  'RMSE': 0.6064332745501879,\n",
       "  'R2 Score': 0.7365097534650544,\n",
       "  'Correlation': 0.867404233883593},\n",
       " 'Molbert': {'MAE': 0.5100067769880953,\n",
       "  'RMSE': 0.6507887204149233,\n",
       "  'R2 Score': 0.6965560154119396,\n",
       "  'Correlation': 0.8370118646634633}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating metrics\n",
    "lipo_metrics_results = {}\n",
    "\n",
    "for model_name, actual, pred in [(\"Chemberta2\", lipo_chemberta_actual, lipo_chemberta_pred),\n",
    "                                 (\"Molformer\", lipo_molformer_actual, lipo_molformer_pred),\n",
    "                                 (\"Molbert\", lipo_molbert_actual, lipo_molbert_pred)]:\n",
    "    lipo_metrics_results[model_name] = {\n",
    "        \"MAE\": mean_absolute_error(actual, pred),\n",
    "        \"RMSE\": np.sqrt(mean_squared_error(actual, pred)),\n",
    "        \"R2 Score\": r2_score(actual, pred),\n",
    "        \"Correlation\": pearsonr(actual, pred)[0]  # Only record the correlation coefficient\n",
    "    }\n",
    "\n",
    "lipo_metrics_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardized valid2 labels\n",
    "lipo_y_ensemble_valid2 = (lipo_chemberta2_valid2['target'] - train_mean)/train_sd\n",
    "\n",
    "# Create the features for the ensemble from the prediction probabilities of being in class 1\n",
    "lipo_X_ensemble_valid2 = pd.concat([\n",
    "    lipo_chemberta2_valid2['pred_z'] - lipo_y_ensemble_valid2,\n",
    "    lipo_molformer_valid2['pred_z'] - lipo_y_ensemble_valid2, \n",
    "    lipo_molbert_valid2['pred_z'] - lipo_y_ensemble_valid2,\n",
    "    # add features from training set\n",
    "    lipo_chemberta2_valid2['pred_z'],\n",
    "    lipo_molformer_valid2['pred_z'],\n",
    "    lipo_molbert_valid2['pred_z']\n",
    "], axis=1)\n",
    "\n",
    "# change feature names of the ensemble so that they are unique\n",
    "lipo_X_ensemble_valid2.columns = ['residuals_chemberta', 'residuals_molformer', 'residuals_molbert', 'chemberta', 'molformer', 'molbert']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing for chemberta dataset...\n",
      " 64%|██████▍   | 32/50 [04:18<02:25,  8.07s/trial, best loss: 0.51995281374393]  \n",
      "Optimizing for molformer dataset...\n",
      " 78%|███████▊  | 39/50 [06:46<01:54, 10.43s/trial, best loss: 0.5174326563201829]\n",
      "Optimizing for molbert dataset...\n",
      " 46%|████▌     | 23/50 [03:51<04:31, 10.04s/trial, best loss: 0.5409159849458041]\n",
      "Models trained for chemberta, molformer, and molbert datasets.\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.early_stop import no_progress_loss\n",
    "import numpy as np\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "np.random.seed(0)\n",
    "\n",
    "# Compute residuals\n",
    "chemberta_y_residual = lipo_chemberta2_valid2['pred_z'] - lipo_y_ensemble_valid2\n",
    "molformer_y_residual = lipo_molformer_valid2['pred_z'] - lipo_y_ensemble_valid2\n",
    "molbert_y_residual = lipo_molbert_valid2['pred_z'] - lipo_y_ensemble_valid2\n",
    "\n",
    "# For input features, we use pred_z and the other features\n",
    "chemberta_X = pd.concat([lipo_chemberta2_valid2['pred_z'], \n",
    "                         lipo_chemberta2_features_valid2.iloc[:, 2:]], axis=1)\n",
    "molformer_X = pd.concat([lipo_molformer_valid2['pred_z'], \n",
    "                         lipo_molformer_features_valid2.iloc[:, 1:]], axis=1)\n",
    "molbert_X = pd.concat([lipo_molbert_valid2['pred_z'], \n",
    "                       lipo_molbert_features_valid2.iloc[:, 1:]], axis=1)\n",
    "\n",
    "# Standardize each dataset\n",
    "scaler_chemberta = StandardScaler().fit(chemberta_X)\n",
    "scaler_molformer = StandardScaler().fit(molformer_X)\n",
    "scaler_molbert = StandardScaler().fit(molbert_X)\n",
    "\n",
    "chemberta_X_scaled = scaler_chemberta.transform(chemberta_X)\n",
    "molformer_X_scaled = scaler_molformer.transform(molformer_X)\n",
    "molbert_X_scaled = scaler_molbert.transform(molbert_X)\n",
    "\n",
    "# Define RMSE scorer\n",
    "def rmse_scorer(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# Define the hyperparameter space for regression using continuous distributions\n",
    "xgb_hyperopt_space = {\n",
    "    'n_estimators': hp.quniform('n_estimators', 50, 200, 50),\n",
    "    'max_depth': hp.quniform('max_depth', 3, 7, 2),\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.001, 0.3),\n",
    "    'subsample': hp.uniform('subsample', 0.5, 1.0),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1.0)\n",
    "}\n",
    "\n",
    "# Objective function for hyperopt with XGBRegressor\n",
    "def objective(params, X_train, y_train):\n",
    "    # Convert float outputs of hp.quniform to int for certain parameters\n",
    "    params['n_estimators'] = int(params['n_estimators'])\n",
    "    params['max_depth'] = int(params['max_depth'])\n",
    "    \n",
    "    # Initialize XGBRegressor with the given parameters\n",
    "    model = xgb.XGBRegressor(**params, random_state=0)\n",
    "    \n",
    "    # RMSE as the scoring metric\n",
    "    rmse = make_scorer(rmse_scorer, greater_is_better=False)\n",
    "    score = cross_val_score(model, X_train, y_train, scoring=rmse, cv=5)\n",
    "    \n",
    "    # Minimize the negative RMSE score\n",
    "    return {'loss': -score.mean(), 'status': STATUS_OK}\n",
    "\n",
    "# Function to optimize and train the model for each dataset\n",
    "def optimize_and_train(X_train, y_train):\n",
    "    # Run the Bayesian optimization\n",
    "    trials = Trials()\n",
    "    best_params = fmin(fn=lambda params: objective(params, X_train, y_train), \n",
    "                       space=xgb_hyperopt_space, \n",
    "                       algo=tpe.suggest, \n",
    "                       max_evals=50, \n",
    "                       trials=trials,\n",
    "                       rstate=np.random.default_rng(0),  # Seed for reproducibility in hyperopt\n",
    "                       early_stop_fn=no_progress_loss(10))\n",
    "\n",
    "    # Convert the best hyperparameters to the correct data types\n",
    "    best_params['n_estimators'] = int(best_params['n_estimators'])\n",
    "    best_params['max_depth'] = int(best_params['max_depth'])\n",
    "\n",
    "    # Initialize and train the XGBoost model with the best parameters\n",
    "    model = xgb.XGBRegressor(**best_params, random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Optimizing and training for chemberta dataset\n",
    "print(\"Optimizing for chemberta dataset...\")\n",
    "best_model_chemberta = optimize_and_train(chemberta_X_scaled, chemberta_y_residual)\n",
    "\n",
    "# Optimizing and training for molformer dataset\n",
    "print(\"Optimizing for molformer dataset...\")\n",
    "best_model_molformer = optimize_and_train(molformer_X_scaled, molformer_y_residual)\n",
    "\n",
    "# Optimizing and training for molbert dataset\n",
    "print(\"Optimizing for molbert dataset...\")\n",
    "best_model_molbert = optimize_and_train(molbert_X_scaled, molbert_y_residual)\n",
    "\n",
    "# Print a confirmation message\n",
    "print(\"Models trained for chemberta, molformer, and molbert datasets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChemBERTa\n",
    "chemberta_X_test = pd.concat([lipo_chemberta2_test['pred_z'], \n",
    "                              lipo_chemberta2_features_test.iloc[:, 2:]], axis=1)\n",
    "\n",
    "# MolFormer\n",
    "molformer_X_test = pd.concat([lipo_molformer_test['pred_z'], \n",
    "                              lipo_molformer_features_test.iloc[:, 1:]], axis=1)\n",
    "\n",
    "# MolBERT\n",
    "molbert_X_test = pd.concat([lipo_molbert_test['pred_z'], \n",
    "                            lipo_molbert_features_test.iloc[:, 1:]], axis=1)\n",
    "\n",
    "# Scale the test data using the corresponding scalers\n",
    "chemberta_X_test_scaled = scaler_chemberta.transform(chemberta_X_test)\n",
    "molformer_X_test_scaled = scaler_molformer.transform(molformer_X_test)\n",
    "molbert_X_test_scaled = scaler_molbert.transform(molbert_X_test)\n",
    "\n",
    "# Predict residuals for the test set using the trained GroupLasso models\n",
    "y_pred_residuals_chemberta_test = best_model_chemberta.predict(chemberta_X_test_scaled)\n",
    "y_pred_residuals_molformer_test = best_model_molformer.predict(molformer_X_test_scaled)\n",
    "y_pred_residuals_molbert_test = best_model_molbert.predict(molbert_X_test_scaled)\n",
    "\n",
    "# Create a DataFrame to store the predicted residuals for the test set\n",
    "predicted_residuals_test = pd.DataFrame({\n",
    "    'Residuals_Chemberta': y_pred_residuals_chemberta_test,\n",
    "    'Residuals_Molformer': y_pred_residuals_molformer_test,\n",
    "    'Residuals_Molbert': y_pred_residuals_molbert_test\n",
    "})\n",
    "\n",
    "# Load test data into ensemble DataFrame, adding the predicted residuals and original predictions\n",
    "lipo_X_ensemble_test = pd.concat([\n",
    "    predicted_residuals_test,\n",
    "    lipo_chemberta2_test['pred_z'],\n",
    "    lipo_molformer_test['pred_z'],  \n",
    "    lipo_molbert_test['pred_z']\n",
    "], axis=1)\n",
    "\n",
    "# Rename feature columns so that they are unique\n",
    "lipo_X_ensemble_test.columns = ['residuals_chemberta', 'residuals_molformer', 'residuals_molbert', 'chemberta', 'molformer', 'molbert']\n",
    "\n",
    "# True test labels\n",
    "lipo_y_ensemble_test = lipo_chemberta2_test['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "lipo_X_ensemble_valid2_scaled = scaler.fit_transform(lipo_X_ensemble_valid2)\n",
    "lipo_X_ensemble_test_scaled = scaler.transform(lipo_X_ensemble_test)\n",
    "\n",
    "lipo_X_ensemble_valid2_scaled = pd.DataFrame(lipo_X_ensemble_valid2_scaled, columns=lipo_X_ensemble_valid2.columns)\n",
    "lipo_X_ensemble_test_scaled = pd.DataFrame(lipo_X_ensemble_test_scaled, columns=lipo_X_ensemble_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(840, 6)\n",
      "(420, 6)\n"
     ]
    }
   ],
   "source": [
    "lipo_X_ensemble_valid2_selected = lipo_X_ensemble_valid2_scaled\n",
    "lipo_X_ensemble_test_selected = lipo_X_ensemble_test_scaled\n",
    "\n",
    "# check shapes\n",
    "print(lipo_X_ensemble_valid2_selected.shape)\n",
    "print(lipo_X_ensemble_test_selected.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [00:09<00:09,  2.74trial/s, best loss: 0.09354631611815283]\n",
      "Best hyperparameters: {'colsample_bytree': 0.9558186054871323, 'learning_rate': 0.09634469734464615, 'max_depth': 4.0, 'n_estimators': 200.0, 'subsample': 0.8082925817075997}\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "import numpy as np\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.early_stop import no_progress_loss\n",
    "import random\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "# Define the hyperparameter space using continuous distributions\n",
    "lipo_xgb_hyperopt_space = {\n",
    "    'n_estimators': hp.quniform('n_estimators', 50, 200, 50),\n",
    "    'max_depth': hp.quniform('max_depth', 3, 7, 2),\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.001, 0.3),\n",
    "    'subsample': hp.uniform('subsample', 0.5, 1.0),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1.0)\n",
    "}\n",
    "\n",
    "# Correctly define the RMSE scorer function\n",
    "def rmse_scorer(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# Convert float outputs of hp.quniform to int for certain parameters\n",
    "def objective(params):\n",
    "    params['n_estimators'] = int(params['n_estimators'])\n",
    "    params['max_depth'] = int(params['max_depth'])\n",
    "    model = xgb.XGBRegressor(**params, random_state=0)\n",
    "    \n",
    "    # Cross-validated RMSE as the objective\n",
    "    score = cross_val_score(model, lipo_X_ensemble_valid2_selected, lipo_y_ensemble_valid2, \n",
    "                            scoring=make_scorer(rmse_scorer, greater_is_better=False), cv=5)\n",
    "    \n",
    "    # Minimize the positive RMSE (already negative from scoring)\n",
    "    return {'loss': -score.mean(), 'status': STATUS_OK}\n",
    "\n",
    "# Run the Bayesian optimization\n",
    "trials = Trials()\n",
    "lipo_xgb_best_params = fmin(fn=objective, \n",
    "                            space=lipo_xgb_hyperopt_space, \n",
    "                            algo=tpe.suggest, \n",
    "                            max_evals=50, \n",
    "                            trials=trials,\n",
    "                            rstate=np.random.default_rng(0),  # Seed for hyperopt\n",
    "                            early_stop_fn=no_progress_loss(10))\n",
    "\n",
    "print(\"Best hyperparameters:\", lipo_xgb_best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MAE': 0.4122656939824422,\n",
       " 'RMSE': 0.5339607690606882,\n",
       " 'R2 Score': 0.7957240691290287,\n",
       " 'Correlation': 0.8923536936803771}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model with the best hyperparameters\n",
    "# Convert parameters obtained from Hyperopt to the correct data type\n",
    "lipo_xgb_best_params['n_estimators'] = int(lipo_xgb_best_params['n_estimators'])\n",
    "lipo_xgb_best_params['max_depth'] = int(lipo_xgb_best_params['max_depth'])\n",
    "\n",
    "# Initialize and train the XGBoost model with the best parameters\n",
    "lipo_xgb_model = xgb.XGBRegressor(**lipo_xgb_best_params, random_state=0)\n",
    "lipo_xgb_model.fit(lipo_X_ensemble_valid2_selected, lipo_y_ensemble_valid2)\n",
    "\n",
    "# Predict the test set\n",
    "lipo_xgb_best_pred = lipo_xgb_model.predict(lipo_X_ensemble_test_selected) * train_sd + train_mean\n",
    "\n",
    "# Calculate the metrics\n",
    "lipo_xgb_best_metrics = {\n",
    "    \"MAE\": mean_absolute_error(lipo_y_ensemble_test, lipo_xgb_best_pred),\n",
    "    \"RMSE\": np.sqrt(mean_squared_error(lipo_y_ensemble_test, lipo_xgb_best_pred)),\n",
    "    \"R2 Score\": r2_score(lipo_y_ensemble_test, lipo_xgb_best_pred),\n",
    "    \"Correlation\": pearsonr(lipo_y_ensemble_test, lipo_xgb_best_pred)[0]  # Only record the correlation coefficient\n",
    "}\n",
    "\n",
    "lipo_xgb_best_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a table to record all metrics for lipo\n",
    "lipo_metrics_results[\"XGBoost\"] = lipo_xgb_best_metrics\n",
    "\n",
    "lipo_metrics_df = pd.DataFrame(lipo_metrics_results).T\n",
    "# keep 3 digits after the decimal point\n",
    "lipo_metrics_df = lipo_metrics_df.round(3)\n",
    "\n",
    "# export table to csv\n",
    "lipo_metrics_df.to_csv('./split2_lipo_metrics_xgb.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fusion-env",
   "language": "python",
   "name": "fusion-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
