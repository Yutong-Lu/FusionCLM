{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, precision_recall_curve, average_precision_score, mean_squared_error, r2_score, mean_absolute_error\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# preds\n",
    "\n",
    "# Load the training set of meta-model\n",
    "ct_chemberta2_valid2 = pd.read_csv('./chemberta2/results/clintox/chemberta2_valid2_clintox_1_predictions.csv')\n",
    "ct_molformer_valid2 = pd.read_csv('./molformer/results/clintox/molformer_valid2_clintox_1_epoch29.csv')\n",
    "ct_molbert_valid2 = pd.read_csv('./molbert/results/clintox/molbert_valid2_clintox_1.csv')\n",
    "\n",
    "# Load the test data for each model\n",
    "ct_chemberta2_test = pd.read_csv('./chemberta2/results/clintox/chemberta2_test_clintox_1_predictions.csv')\n",
    "ct_molformer_test = pd.read_csv('./molformer/results/clintox/molformer_test_clintox_1_epoch29.csv')\n",
    "ct_molbert_test = pd.read_csv('./molbert/results/clintox/molbert_test_clintox_1.csv')\n",
    "\n",
    "# features\n",
    "\n",
    "# Load the features from chemberta\n",
    "ct_chemberta2_features_valid2 = pd.read_csv('./chemberta2/features/clintox/chemberta2_valid2_clintox_1_features.csv')\n",
    "ct_chemberta2_features_test = pd.read_csv('./chemberta2/features/clintox/chemberta2_test_clintox_1_features.csv')\n",
    "\n",
    "# Load the features from molformer\n",
    "ct_molformer_features_valid2 = pd.read_csv('./molformer/features/clintox/molformer_valid2_clintox_1_features.csv')\n",
    "ct_molformer_features_test = pd.read_csv('./molformer/features/clintox/molformer_test_clintox_1_features.csv')\n",
    "\n",
    "# Load the features from molbert\n",
    "ct_molbert_features_valid2 = pd.read_csv('./molbert/features/clintox/molbert_valid2_clintox_1_features.csv')\n",
    "ct_molbert_features_test = pd.read_csv('./molbert/features/clintox/molbert_test_clintox_1_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Clintox (Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Chemberta2': {'Accuracy': 0.9798657718120806,\n",
       "  'F1 Score': 0.8421052631578947,\n",
       "  'ROC-AUC': 0.9888888888888889,\n",
       "  'PR-AUC': 0.8967813051146385},\n",
       " 'Molformer': {'Accuracy': 0.8993288590604027,\n",
       "  'F1 Score': 0.34782608695652173,\n",
       "  'ROC-AUC': 0.8412698412698414,\n",
       "  'PR-AUC': 0.44689892504271944},\n",
       " 'Molbert': {'Accuracy': 0.9261744966442953,\n",
       "  'F1 Score': 0.35294117647058826,\n",
       "  'ROC-AUC': 0.8801587301587301,\n",
       "  'PR-AUC': 0.40959504857430756}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, average_precision_score\n",
    "\n",
    "# Preparing the actual and predicted values\n",
    "# Chemberta2\n",
    "ct_chemberta_actual = ct_chemberta2_test['CT_TOX']\n",
    "ct_chemberta_pred = ct_chemberta2_test['y_pred']\n",
    "ct_chemberta_probs = ct_chemberta2_test[['softmax_class_0_prob', 'softmax_class_1_prob']]\n",
    "\n",
    "# Molformer\n",
    "ct_molformer_actual = ct_molformer_test['Actual']\n",
    "ct_molformer_pred = (ct_molformer_test['Prob_Class_1'] > 0.5).astype(int)\n",
    "ct_molformer_probs = ct_molformer_test[['Prob_Class_0', 'Prob_Class_1']]\n",
    "\n",
    "# Molbert\n",
    "ct_molbert_actual = ct_molbert_test['target']\n",
    "ct_molbert_pred = ct_molbert_test['pred']\n",
    "ct_molbert_probs = ct_molbert_test['prob']\n",
    "\n",
    "# Calculating metrics\n",
    "ct_metrics_results = {}\n",
    "\n",
    "for model_name, actual, pred, probs in [(\"Chemberta2\", ct_chemberta_actual, ct_chemberta_pred, ct_chemberta_probs['softmax_class_1_prob']),\n",
    "                                         (\"Molformer\", ct_molformer_actual, ct_molformer_pred, ct_molformer_probs['Prob_Class_1']),\n",
    "                                         (\"Molbert\", ct_molbert_actual, ct_molbert_pred, ct_molbert_probs)]:\n",
    "    ct_metrics_results[model_name] = {\n",
    "        \"Accuracy\": accuracy_score(actual, pred),\n",
    "        \"F1 Score\": f1_score(actual, pred),\n",
    "        \"ROC-AUC\": roc_auc_score(actual, probs),\n",
    "        \"PR-AUC\": average_precision_score(actual, probs)\n",
    "    }\n",
    "\n",
    "ct_metrics_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the 'smiles' values in chemberta that are not in molbert\n",
    "missing_smiles = set(ct_chemberta2_valid2['smiles']) - set(ct_molbert_valid2['smiles'])\n",
    "\n",
    "# Find the indices of these missing 'smiles' in the chemberta DataFrame\n",
    "missing_indices = ct_chemberta2_valid2.index[ct_chemberta2_valid2['smiles'].isin(missing_smiles)].tolist()\n",
    "\n",
    "# Drop the rows with these missing indices for chemberta and molformer\n",
    "ct_chemberta2_valid2 = ct_chemberta2_valid2.drop(missing_indices)\n",
    "ct_molformer_valid2 = ct_molformer_valid2.drop(missing_indices)\n",
    "ct_chemberta2_features_valid2 = ct_chemberta2_features_valid2.drop(missing_indices)\n",
    "ct_molformer_features_valid2 = ct_molformer_features_valid2.drop(missing_indices)\n",
    "ct_molbert_features_valid2 = ct_molbert_features_valid2.drop(missing_indices)\n",
    "\n",
    "# do the same for test sets\n",
    "missing_smiles = set(ct_chemberta2_test['smiles']) - set(ct_molbert_test['smiles'])\n",
    "missing_indices = ct_chemberta2_test.index[ct_chemberta2_test['smiles'].isin(missing_smiles)].tolist()\n",
    "\n",
    "ct_chemberta2_test = ct_chemberta2_test.drop(missing_indices)\n",
    "ct_molformer_test = ct_molformer_test.drop(missing_indices)\n",
    "ct_chemberta2_features_test = ct_chemberta2_features_test.drop(missing_indices)\n",
    "ct_molformer_features_test = ct_molformer_features_test.drop(missing_indices)\n",
    "ct_molbert_features_test = ct_molbert_features_test.drop(missing_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(291, 8)\n",
      "(291, 5)\n",
      "(291, 4)\n",
      "(291, 386)\n",
      "(291, 769)\n",
      "(291, 769)\n"
     ]
    }
   ],
   "source": [
    "# check shapes\n",
    "print(ct_chemberta2_valid2.shape)\n",
    "print(ct_molformer_valid2.shape)\n",
    "print(ct_molbert_valid2.shape)\n",
    "print(ct_chemberta2_features_valid2.shape)\n",
    "print(ct_molformer_features_valid2.shape)\n",
    "print(ct_molbert_features_valid2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "ct_y_ensemble_valid2 = ct_chemberta2_valid2['CT_TOX']\n",
    "\n",
    "# Convert the ensemble target to a Series if not already done\n",
    "ct_y_ensemble_valid2_s = pd.Series(ct_y_ensemble_valid2).reset_index(drop=True)\n",
    "\n",
    "# Create dataframes for each model's class 1 probability\n",
    "ct_chemberta2_prob = pd.DataFrame({'chemberta2': ct_chemberta2_valid2['softmax_class_1_prob']})\n",
    "ct_chemberta2_prob.reset_index(drop=True, inplace=True)\n",
    "\n",
    "ct_molformer_prob = pd.DataFrame({'molformer': ct_molformer_valid2['Prob_Class_1']})\n",
    "ct_molformer_prob.reset_index(drop=True, inplace=True)\n",
    "\n",
    "ct_molbert_prob = pd.DataFrame({'molbert': ct_molbert_valid2['prob']})\n",
    "ct_molbert_prob.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# do the same for features ct_chemberta2_features_valid2.iloc[:, 2:]\n",
    "ct_chemberta2_features = pd.DataFrame(ct_chemberta2_features_valid2.iloc[:, 2:])\n",
    "ct_chemberta2_features.reset_index(drop=True, inplace=True)\n",
    "\n",
    "ct_molformer_features = pd.DataFrame(ct_molformer_features_valid2.iloc[:, 1:])\n",
    "ct_molformer_features.reset_index(drop=True, inplace=True)\n",
    "\n",
    "ct_molbert_features = pd.DataFrame(ct_molbert_features_valid2.iloc[:, 1:])\n",
    "ct_molbert_features.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# ct_features = pd.concat([ct_chemberta2_features, ct_molformer_features, ct_molbert_features], axis=1)\n",
    "\n",
    "# Combine probabilities into one dataframe\n",
    "train_ct_prob = pd.concat([ct_chemberta2_prob, ct_molformer_prob, ct_molbert_prob], axis=1)\n",
    "\n",
    "# Function to calculate BCE for each row\n",
    "def calculate_bce_rowwise(y_true, y_pred):\n",
    "    return -(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
    "\n",
    "# Calculate row-wise BCE for each model\n",
    "bce_chemberta = calculate_bce_rowwise(ct_y_ensemble_valid2_s, ct_chemberta2_prob['chemberta2'])\n",
    "bce_molformer = calculate_bce_rowwise(ct_y_ensemble_valid2_s, ct_molformer_prob['molformer'])\n",
    "bce_molbert = calculate_bce_rowwise(ct_y_ensemble_valid2_s, ct_molbert_prob['molbert'])\n",
    "\n",
    "# Create a dataframe for row-wise BCE losses\n",
    "bce_loss_df = pd.DataFrame({\n",
    "    'bce_chemberta': bce_chemberta,\n",
    "    'bce_molformer': bce_molformer,\n",
    "    'bce_molbert': bce_molbert\n",
    "})\n",
    "\n",
    "# Final ensemble X matrix: Combine row-wise BCE losses, predictions, and features\n",
    "ct_X_ensemble_valid2 = pd.concat([bce_loss_df, train_ct_prob], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lorrainelu/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.688e-01, tolerance: 1.493e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/lorrainelu/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.106e-03, tolerance: 5.458e-04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/lorrainelu/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.305e-01, tolerance: 1.622e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/lorrainelu/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.214e-01, tolerance: 1.400e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/lorrainelu/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.516e-01, tolerance: 1.673e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/lorrainelu/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.194e-03, tolerance: 1.493e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/lorrainelu/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.356e-03, tolerance: 1.622e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/lorrainelu/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.730e-02, tolerance: 1.400e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/lorrainelu/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.172e-03, tolerance: 1.673e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/lorrainelu/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.800e-01, tolerance: 4.637e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/lorrainelu/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.083e-01, tolerance: 7.405e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/lorrainelu/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.592e-01, tolerance: 5.975e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/lorrainelu/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.391e-01, tolerance: 6.891e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/lorrainelu/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.997e-01, tolerance: 6.720e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/lorrainelu/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.382e-01, tolerance: 4.637e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/lorrainelu/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.176e-01, tolerance: 7.405e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/lorrainelu/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.470e-01, tolerance: 5.975e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/lorrainelu/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.399e-01, tolerance: 6.891e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/lorrainelu/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.560e-01, tolerance: 6.720e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/lorrainelu/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.403e-01, tolerance: 6.891e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/lorrainelu/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.029e-02, tolerance: 1.461e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/lorrainelu/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.130e-01, tolerance: 1.743e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/lorrainelu/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.118e-02, tolerance: 1.130e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/lorrainelu/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.887e-02, tolerance: 1.535e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/lorrainelu/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.164e-02, tolerance: 1.546e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/lorrainelu/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.043e-02, tolerance: 1.461e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/lorrainelu/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.266e-02, tolerance: 1.743e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/lorrainelu/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.488e-02, tolerance: 1.130e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/lorrainelu/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.233e-02, tolerance: 1.535e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/lorrainelu/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.836e-02, tolerance: 1.546e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Set seed for reproducibility\n",
    "seed = 0\n",
    "\n",
    "# Combine probabilities with their respective feature sets\n",
    "chemberta_X = pd.concat([ct_chemberta2_prob, ct_chemberta2_features], axis=1)\n",
    "molformer_X = pd.concat([ct_molformer_prob, ct_molformer_features], axis=1)\n",
    "molbert_X = pd.concat([ct_molbert_prob, ct_molbert_features], axis=1)\n",
    "\n",
    "# Standardize each dataset\n",
    "scaler_chemberta = StandardScaler().fit(chemberta_X)\n",
    "scaler_molformer = StandardScaler().fit(molformer_X)\n",
    "scaler_molbert = StandardScaler().fit(molbert_X)\n",
    "\n",
    "chemberta_X_scaled = scaler_chemberta.transform(chemberta_X)\n",
    "molformer_X_scaled = scaler_molformer.transform(molformer_X)\n",
    "molbert_X_scaled = scaler_molbert.transform(molbert_X)\n",
    "\n",
    "# Define the binary cross-entropy loss values as target variables (y)\n",
    "chemberta_y_bce = bce_chemberta  # Row-wise BCE loss calculated earlier\n",
    "molformer_y_bce = bce_molformer  # Row-wise BCE loss calculated earlier\n",
    "molbert_y_bce = bce_molbert      # Row-wise BCE loss calculated earlier\n",
    "\n",
    "# Initialize the ElasticNet models with l1_ratio set to 1 for LASSO, and random_state for reproducibility\n",
    "lasso_chemberta = ElasticNet(max_iter=10000, tol=0.0001, random_state=seed, l1_ratio=1.0)\n",
    "lasso_molformer = ElasticNet(max_iter=10000, tol=0.0001, random_state=seed, l1_ratio=1.0)\n",
    "lasso_molbert = ElasticNet(max_iter=10000, tol=0.0001, random_state=seed, l1_ratio=1.0)\n",
    "\n",
    "# Setup cross-validation for alpha tuning only (since l1_ratio is fixed at 1 for LASSO)\n",
    "param_grid = {\n",
    "    'alpha': np.logspace(-4, 1, 10)\n",
    "}\n",
    "\n",
    "# Set up GridSearchCV for LASSO with neg_mean_squared_error scoring and random_state\n",
    "cv_chemberta = GridSearchCV(estimator=lasso_chemberta, param_grid=param_grid, scoring='neg_mean_squared_error', cv=5)\n",
    "cv_molformer = GridSearchCV(estimator=lasso_molformer, param_grid=param_grid, scoring='neg_mean_squared_error', cv=5)\n",
    "cv_molbert = GridSearchCV(estimator=lasso_molbert, param_grid=param_grid, scoring='neg_mean_squared_error', cv=5)\n",
    "\n",
    "# Fit GridSearchCV for each dataset with BCE as the target\n",
    "cv_chemberta.fit(chemberta_X_scaled, chemberta_y_bce)\n",
    "cv_molformer.fit(molformer_X_scaled, molformer_y_bce)\n",
    "cv_molbert.fit(molbert_X_scaled, molbert_y_bce)\n",
    "\n",
    "# Retrieve the best models and parameters\n",
    "best_model_chemberta = cv_chemberta.best_estimator_\n",
    "best_model_molformer = cv_molformer.best_estimator_\n",
    "best_model_molbert = cv_molbert.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# Test data for each model\n",
    "ct_chemberta2_prob_test = pd.DataFrame({'chemberta2': ct_chemberta2_test['softmax_class_1_prob']})\n",
    "ct_chemberta2_prob_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "ct_molformer_prob_test = pd.DataFrame({'molformer': ct_molformer_test['Prob_Class_1']})\n",
    "ct_molformer_prob_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "ct_molbert_prob_test = pd.DataFrame({'molbert': ct_molbert_test['prob']})\n",
    "ct_molbert_prob_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "ct_chemberta2_features_t = pd.DataFrame(ct_chemberta2_features_test.iloc[:, 2:])\n",
    "ct_chemberta2_features_t.reset_index(drop=True, inplace=True)\n",
    "\n",
    "ct_molformer_features_t  = pd.DataFrame(ct_molformer_features_test.iloc[:, 1:])\n",
    "ct_molformer_features_t.reset_index(drop=True, inplace=True)\n",
    "\n",
    "ct_molbert_features_t = pd.DataFrame(ct_molbert_features_test.iloc[:, 1:])\n",
    "ct_molbert_features_t.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Combine probabilities with the respective feature sets for the test set\n",
    "chemberta_X_test = pd.concat([ct_chemberta2_prob_test, ct_chemberta2_features_t], axis=1)\n",
    "molformer_X_test = pd.concat([ct_molformer_prob_test, ct_molformer_features_t], axis=1)\n",
    "molbert_X_test = pd.concat([ct_molbert_prob_test, ct_molbert_features_t], axis=1)\n",
    "\n",
    "# Standardize the test set based on the previously fitted scalers\n",
    "chemberta_X_test_scaled = scaler_chemberta.transform(chemberta_X_test)\n",
    "molformer_X_test_scaled = scaler_molformer.transform(molformer_X_test)\n",
    "molbert_X_test_scaled = scaler_molbert.transform(molbert_X_test)\n",
    "\n",
    "# Predict using the best models from valid2\n",
    "chemberta_pred_test = best_model_chemberta.predict(chemberta_X_test_scaled)\n",
    "molformer_pred_test = best_model_molformer.predict(molformer_X_test_scaled)\n",
    "molbert_pred_test = best_model_molbert.predict(molbert_X_test_scaled)\n",
    "\n",
    "# Convert the predictions (numpy arrays) to pandas Series\n",
    "chemberta_pred_test_series = pd.Series(chemberta_pred_test, name='bce_chemberta')\n",
    "molformer_pred_test_series = pd.Series(molformer_pred_test, name='bce_molformer')\n",
    "molbert_pred_test_series = pd.Series(molbert_pred_test, name='bce_molbert')\n",
    "\n",
    "# Now concatenate the series with the test set probabilities\n",
    "ct_X_ensemble_test = pd.concat([\n",
    "    chemberta_pred_test_series,                     # BCE for Chemberta\n",
    "    molformer_pred_test_series,                     # BCE for Molformer\n",
    "    molbert_pred_test_series,                       # BCE for Molbert\n",
    "    ct_chemberta2_prob_test['chemberta2'],        # Chemberta test probabilities\n",
    "    ct_molformer_prob_test['molformer'],          # Molformer test probabilities\n",
    "    ct_molbert_prob_test['molbert']               # Molbert test probabilities\n",
    "], axis=1)\n",
    "\n",
    "ct_X_ensemble_test.columns = ['bce_chemberta', 'bce_molformer', 'bce_molbert', 'chemberta2', 'molformer', 'molbert']\n",
    "\n",
    "# optional for evaluation\n",
    "ct_y_ensemble_test = ct_chemberta2_test['CT_TOX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use standard scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "ct_X_ensemble_valid2_scaled = scaler.fit_transform(ct_X_ensemble_valid2)\n",
    "ct_X_ensemble_test_scaled = scaler.transform(ct_X_ensemble_test)\n",
    "\n",
    "# transform back to dataframe\n",
    "ct_X_ensemble_valid2_scaled = pd.DataFrame(ct_X_ensemble_valid2_scaled, columns=ct_X_ensemble_valid2.columns)\n",
    "ct_X_ensemble_test_scaled = pd.DataFrame(ct_X_ensemble_test_scaled, columns=ct_X_ensemble_test.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 100.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.9731543624161074,\n",
       " 'F1 Score': 0.8,\n",
       " 'ROC-AUC': 0.9825396825396826,\n",
       " 'PR-AUC': 0.8884920634920637}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, average_precision_score\n",
    "\n",
    "# Define the model with LASSO penalty\n",
    "lasso_model = LogisticRegression(penalty='l1', solver='saga', max_iter=5000, random_state=0)\n",
    "\n",
    "# Use fewer discrete values for alpha\n",
    "alphas = [0.01, 0.1, 1, 3]  # Reduced number of points focusing on lower and mid-range\n",
    "\n",
    "# Convert alphas to Cs for the parameter grid (since C is the inverse of alpha)\n",
    "Cs = [1/alpha for alpha in alphas]\n",
    "\n",
    "# Create a concise grid search using 5-fold cross-validation\n",
    "params = {\n",
    "    'C': Cs\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(lasso_model, param_grid=params, cv=5, scoring='roc_auc')\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(ct_X_ensemble_valid2_scaled, ct_y_ensemble_valid2)\n",
    "\n",
    "# Best model after grid search\n",
    "ct_best_lasso_model = grid_search.best_estimator_\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# Predict the test set\n",
    "ct_lasso_pred = ct_best_lasso_model.predict(ct_X_ensemble_test_scaled)\n",
    "ct_lasso_probs = ct_best_lasso_model.predict_proba(ct_X_ensemble_test_scaled)[:, 1]\n",
    "\n",
    "# Calculate the metrics\n",
    "ct_lasso_metrics = {\n",
    "    \"Accuracy\": accuracy_score(ct_y_ensemble_test, ct_lasso_pred),\n",
    "    \"F1 Score\": f1_score(ct_y_ensemble_test, ct_lasso_pred),\n",
    "    \"ROC-AUC\": roc_auc_score(ct_y_ensemble_test, ct_lasso_probs),\n",
    "    \"PR-AUC\": average_precision_score(ct_y_ensemble_test, ct_lasso_probs)\n",
    "}\n",
    "\n",
    "ct_lasso_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report all the metrics for ct\n",
    "ct_metrics_results[\"lasso\"] = ct_lasso_metrics\n",
    "\n",
    "ct_metrics_df = pd.DataFrame(ct_metrics_results).T\n",
    "\n",
    "# keep 3 digits after the decimal point\n",
    "ct_metrics_df = ct_metrics_df.round(3)\n",
    "\n",
    "# export as csv\n",
    "ct_metrics_df.to_csv('./split1_ct_metrics_lasso.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fusion-env",
   "language": "python",
   "name": "fusion-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
