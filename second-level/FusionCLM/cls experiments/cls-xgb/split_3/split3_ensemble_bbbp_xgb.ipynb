{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, precision_recall_curve, average_precision_score, mean_squared_error, r2_score, mean_absolute_error\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# preds\n",
    "\n",
    "# Load the training set of meta-model\n",
    "bbbp_chemberta2_valid2 = pd.read_csv('./chemberta2/results/bbbp/chemberta2_valid2_bbbp_3_predictions.csv')\n",
    "bbbp_molformer_valid2 = pd.read_csv('./molformer/results/bbbp/molformer_valid2_bbbp_3_epoch29.csv')\n",
    "bbbp_molbert_valid2 = pd.read_csv('./molbert/results/bbbp/molbert_valid2_bbbp_3.csv')\n",
    "\n",
    "# Load the test data for each model\n",
    "bbbp_chemberta2_test = pd.read_csv('./chemberta2/results/bbbp/chemberta2_test_bbbp_3_predictions.csv')\n",
    "bbbp_molformer_test = pd.read_csv('./molformer/results/bbbp/molformer_test_bbbp_3_epoch29.csv')\n",
    "bbbp_molbert_test = pd.read_csv('./molbert/results/bbbp/molbert_test_bbbp_3.csv')\n",
    "\n",
    "# features\n",
    "\n",
    "# Load the features from chemberta\n",
    "bbbp_chemberta2_features_valid2 = pd.read_csv('./chemberta2/features/bbbp/chemberta2_valid2_bbbp_3_features.csv')\n",
    "bbbp_chemberta2_features_test = pd.read_csv('./chemberta2/features/bbbp/chemberta2_test_bbbp_3_features.csv')\n",
    "\n",
    "# Load the features from molformer\n",
    "bbbp_molformer_features_valid2 = pd.read_csv('./molformer/features/bbbp/molformer_valid2_bbbp_3_features.csv')\n",
    "bbbp_molformer_features_test = pd.read_csv('./molformer/features/bbbp/molformer_test_bbbp_3_features.csv')\n",
    "\n",
    "# Load the features from molbert\n",
    "bbbp_molbert_features_valid2 = pd.read_csv('./molbert/features/bbbp/molbert_valid2_bbbp_3_features.csv')\n",
    "bbbp_molbert_features_test = pd.read_csv('./molbert/features/bbbp/molbert_test_bbbp_3_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Chemberta2': {'Accuracy': 0.8292682926829268,\n",
       "  'F1 Score': 0.8844884488448845,\n",
       "  'ROC-AUC': 0.9488724127278345,\n",
       "  'PR-AUC': 0.9882303014277589},\n",
       " 'Molformer': {'Accuracy': 0.8774509803921569,\n",
       "  'F1 Score': 0.924924924924925,\n",
       "  'ROC-AUC': 0.8789632213062777,\n",
       "  'PR-AUC': 0.965741487133955},\n",
       " 'Molbert': {'Accuracy': 0.9068627450980392,\n",
       "  'F1 Score': 0.9425981873111783,\n",
       "  'ROC-AUC': 0.9514901712111604,\n",
       "  'PR-AUC': 0.9885586344415213}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, average_precision_score\n",
    "\n",
    "# Preparing the actual and predicted values\n",
    "# Chemberta2\n",
    "bbbp_chemberta_actual = bbbp_chemberta2_test['p_np']\n",
    "bbbp_chemberta_pred = bbbp_chemberta2_test['y_pred']\n",
    "bbbp_chemberta_probs = bbbp_chemberta2_test[['softmax_class_0_prob', 'softmax_class_1_prob']]\n",
    "\n",
    "# Molformer\n",
    "bbbp_molformer_actual = bbbp_molformer_test['Actual']\n",
    "bbbp_molformer_pred = (bbbp_molformer_test['Prob_Class_1'] > 0.5).astype(int)\n",
    "bbbp_molformer_probs = bbbp_molformer_test[['Prob_Class_0', 'Prob_Class_1']]\n",
    "\n",
    "# Molbert\n",
    "bbbp_molbert_actual = bbbp_molbert_test['target']\n",
    "bbbp_molbert_pred = bbbp_molbert_test['pred']\n",
    "bbbp_molbert_probs = bbbp_molbert_test['prob']\n",
    "\n",
    "# Calculating metrics\n",
    "bbbp_metrics_results = {}\n",
    "\n",
    "for model_name, actual, pred, probs in [(\"Chemberta2\", bbbp_chemberta_actual, bbbp_chemberta_pred, bbbp_chemberta_probs['softmax_class_1_prob']),\n",
    "                                         (\"Molformer\", bbbp_molformer_actual, bbbp_molformer_pred, bbbp_molformer_probs['Prob_Class_1']),\n",
    "                                         (\"Molbert\", bbbp_molbert_actual, bbbp_molbert_pred, bbbp_molbert_probs)]:\n",
    "    bbbp_metrics_results[model_name] = {\n",
    "        \"Accuracy\": accuracy_score(actual, pred),\n",
    "        \"F1 Score\": f1_score(actual, pred),\n",
    "        \"ROC-AUC\": roc_auc_score(actual, probs),\n",
    "        \"PR-AUC\": average_precision_score(actual, probs)\n",
    "    }\n",
    "\n",
    "bbbp_metrics_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing smiles in molformer_valid2: {'n1c(csc1\\\\[NH]=C(\\\\N)N)c1ccccc1', 'c1c(c(ncc1)CSCCN\\\\C(=[NH]\\\\C#N)NCC)Br', 's1cc(nc1\\\\[NH]=C(\\\\N)N)C', 's1cc(CSCCN\\\\C(NC)=[NH]\\\\C#N)nc1\\\\[NH]=C(\\\\N)N', 'c1(nc(NC(N)=[NH2])sc1)CSCCNC(=[NH]C#N)NC'}\n",
      "Missing smiles in molbert_valid2: {'c1(nc(NC(N)=[NH2])sc1)CSCCNC(=[NH]C#N)NC', 'n1c(csc1\\\\[NH]=C(\\\\N)N)c1ccccc1', '[Na+].Cc1sc(SCC2=C(N3[C@H](SC2)[C@H](NC(=O)Cn4cnnn4)C3=O)C([O-])=O)nn1', '[Na+].CC1(C)S[C@@H]2[C@H](NC(=O)[C@H](NC(=O)C3=CC=C(NC3=O)c4ccc(cc4)[S](=O)(=O)N(CCO)CCO)c5ccc(O)cc5)C(=O)N2[C@H]1C([O-])=O', 'c1c(c(ncc1)CSCCN\\\\C(=[NH]\\\\C#N)NCC)Br', 's1cc(CSCCN\\\\C(NC)=[NH]\\\\C#N)nc1\\\\[NH]=C(\\\\N)N', '[Na+].CO\\\\N=C(C(=O)N[C@@H]1[C@@H]2SCC(=C(N2C1=O)C([O-])=O)COC(C)=O)\\\\c3csc(N)n3', '[Na+].Cn1nnnc1SCC2=C(N3[C@H](SC2)[C@H](NC(=O)CSC(F)(F)F)C3=O)C([O-])=O', 's1cc(nc1\\\\[NH]=C(\\\\N)N)C'}\n",
      "These indices will be removed from the valid2 set: ['n1c(csc1\\\\[NH]=C(\\\\N)N)c1ccccc1', '[Na+].Cc1sc(SCC2=C(N3[C@H](SC2)[C@H](NC(=O)Cn4cnnn4)C3=O)C([O-])=O)nn1', '[Na+].CC1(C)S[C@@H]2[C@H](NC(=O)[C@H](NC(=O)C3=CC=C(NC3=O)c4ccc(cc4)[S](=O)(=O)N(CCO)CCO)c5ccc(O)cc5)C(=O)N2[C@H]1C([O-])=O', 'c1c(c(ncc1)CSCCN\\\\C(=[NH]\\\\C#N)NCC)Br', 's1cc(nc1\\\\[NH]=C(\\\\N)N)C', 's1cc(CSCCN\\\\C(NC)=[NH]\\\\C#N)nc1\\\\[NH]=C(\\\\N)N', '[Na+].CO\\\\N=C(C(=O)N[C@@H]1[C@@H]2SCC(=C(N2C1=O)C([O-])=O)COC(C)=O)\\\\c3csc(N)n3', '[Na+].Cn1nnnc1SCC2=C(N3[C@H](SC2)[C@H](NC(=O)CSC(F)(F)F)C3=O)C([O-])=O', 'c1(nc(NC(N)=[NH2])sc1)CSCCNC(=[NH]C#N)NC']\n"
     ]
    }
   ],
   "source": [
    "# Identify the 'smiles' values in chemberta2_valid2 that are not in molbert_valid2\n",
    "missing_smiles_molformer_valid2 = set(bbbp_chemberta2_valid2['smiles']) - set(bbbp_molformer_valid2['smiles'])\n",
    "print(f\"Missing smiles in molformer_valid2: {missing_smiles_molformer_valid2}\")\n",
    "\n",
    "# Identify the 'smiles' values in chemberta2_valid2 that are not in molbert_valid2\n",
    "missing_smiles_molbert_valid2 = set(bbbp_chemberta2_valid2['smiles']) - set(bbbp_molbert_valid2['smiles'])\n",
    "print(f\"Missing smiles in molbert_valid2: {missing_smiles_molbert_valid2}\")\n",
    "\n",
    "# Combine the invalid indices from molformer_valid2 with the missing indices from molbert_valid2\n",
    "combined_invalid_smiles_valid2 = list(set(missing_smiles_molformer_valid2).union(set(missing_smiles_molbert_valid2)))\n",
    "\n",
    "print(f\"These indices will be removed from the valid2 set: {combined_invalid_smiles_valid2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(401, 8)\n",
      "(401, 6)\n",
      "(401, 4)\n",
      "(401, 386)\n",
      "(401, 769)\n",
      "(401, 769)\n"
     ]
    }
   ],
   "source": [
    "# Function to remove invalid SMILES\n",
    "def remove_invalid_smiles(df, invalid_smiles_list):\n",
    "    return df[~df['smiles'].isin(invalid_smiles_list)]\n",
    "\n",
    "# Remove invalid SMILES from each dataframe\n",
    "bbbp_chemberta2_valid2 = remove_invalid_smiles(bbbp_chemberta2_valid2, combined_invalid_smiles_valid2)\n",
    "bbbp_molformer_valid2 = remove_invalid_smiles(bbbp_molformer_valid2, combined_invalid_smiles_valid2)\n",
    "bbbp_molbert_valid2 = remove_invalid_smiles(bbbp_molbert_valid2, combined_invalid_smiles_valid2)\n",
    "bbbp_chemberta2_features_valid2 = remove_invalid_smiles(bbbp_chemberta2_features_valid2, combined_invalid_smiles_valid2)\n",
    "bbbp_molformer_features_valid2 = remove_invalid_smiles(bbbp_molformer_features_valid2, combined_invalid_smiles_valid2)\n",
    "bbbp_molbert_features_valid2 = remove_invalid_smiles(bbbp_molbert_features_valid2, combined_invalid_smiles_valid2)\n",
    "\n",
    "# Print the shapes of the dataframes after removal\n",
    "print(bbbp_chemberta2_valid2.shape)\n",
    "print(bbbp_molformer_valid2.shape)\n",
    "print(bbbp_molbert_valid2.shape)\n",
    "print(bbbp_chemberta2_features_valid2.shape)\n",
    "print(bbbp_molformer_features_valid2.shape)\n",
    "print(bbbp_molbert_features_valid2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbbp_y_ensemble_valid2 = bbbp_chemberta2_valid2['p_np']\n",
    "\n",
    "# Convert the ensemble target to a Series if not already done\n",
    "bbbp_y_ensemble_valid2_s = pd.Series(bbbp_y_ensemble_valid2).reset_index(drop=True)\n",
    "\n",
    "# Create dataframes for each model's class 1 probability\n",
    "bbbp_chemberta2_prob = pd.DataFrame({'chemberta2': bbbp_chemberta2_valid2['softmax_class_1_prob']})\n",
    "bbbp_chemberta2_prob.reset_index(drop=True, inplace=True)\n",
    "\n",
    "bbbp_molformer_prob = pd.DataFrame({'molformer': bbbp_molformer_valid2['Prob_Class_1']})\n",
    "bbbp_molformer_prob.reset_index(drop=True, inplace=True)\n",
    "\n",
    "bbbp_molbert_prob = pd.DataFrame({'molbert': bbbp_molbert_valid2['prob']})\n",
    "bbbp_molbert_prob.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# do the same for features bbbp_chemberta2_features_valid2.iloc[:, 2:]\n",
    "bbbp_chemberta2_features = pd.DataFrame(bbbp_chemberta2_features_valid2.iloc[:, 2:])\n",
    "bbbp_chemberta2_features.reset_index(drop=True, inplace=True)\n",
    "\n",
    "bbbp_molformer_features = pd.DataFrame(bbbp_molformer_features_valid2.iloc[:, 1:])\n",
    "bbbp_molformer_features.reset_index(drop=True, inplace=True)\n",
    "\n",
    "bbbp_molbert_features = pd.DataFrame(bbbp_molbert_features_valid2.iloc[:, 1:])\n",
    "bbbp_molbert_features.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# bbbp_features = pd.concat([bbbp_chemberta2_features, bbbp_molformer_features, bbbp_molbert_features], axis=1)\n",
    "\n",
    "# Combine probabilities into one dataframe\n",
    "train_bbbp_prob = pd.concat([bbbp_chemberta2_prob, bbbp_molformer_prob, bbbp_molbert_prob], axis=1)\n",
    "\n",
    "# Function to calculate BCE for each row with epsilon to avoid log(0)\n",
    "def calculate_bce_rowwise(y_true, y_pred, epsilon=1e-12):\n",
    "    # Clip y_pred to ensure it's between epsilon and 1-epsilon\n",
    "    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
    "    return -(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
    "\n",
    "# Calculate row-wise BCE for each model\n",
    "bce_chemberta = calculate_bce_rowwise(bbbp_y_ensemble_valid2_s, bbbp_chemberta2_prob['chemberta2'])\n",
    "bce_molformer = calculate_bce_rowwise(bbbp_y_ensemble_valid2_s, bbbp_molformer_prob['molformer'])\n",
    "bce_molbert = calculate_bce_rowwise(bbbp_y_ensemble_valid2_s, bbbp_molbert_prob['molbert'])\n",
    "\n",
    "# Create a dataframe for row-wise BCE losses\n",
    "bce_loss_df = pd.DataFrame({\n",
    "    'bce_chemberta': bce_chemberta,\n",
    "    'bce_molformer': bce_molformer,\n",
    "    'bce_molbert': bce_molbert\n",
    "})\n",
    "\n",
    "# Final ensemble X matrix: Combine row-wise BCE losses, predictions, and features\n",
    "bbbp_X_ensemble_valid2 = pd.concat([bce_loss_df, train_bbbp_prob], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing for chemberta dataset...\n",
      " 44%|████▍     | 22/50 [02:14<02:51,  6.12s/trial, best loss: 0.28087251382773964]\n",
      "Optimizing for molformer dataset...\n",
      " 46%|████▌     | 23/50 [04:47<05:37, 12.49s/trial, best loss: 3.5584923373347563]\n",
      "Optimizing for molbert dataset...\n",
      " 32%|███▏      | 16/50 [02:51<06:04, 10.72s/trial, best loss: 1.5532111240224733]\n",
      "Models trained for chemberta, molformer, and molbert datasets.\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.early_stop import no_progress_loss\n",
    "import numpy as np\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "np.random.seed(0)\n",
    "\n",
    "# Combine probabilities with their respective feature sets\n",
    "chemberta_X = pd.concat([bbbp_chemberta2_prob, bbbp_chemberta2_features], axis=1)\n",
    "molformer_X = pd.concat([bbbp_molformer_prob, bbbp_molformer_features], axis=1)\n",
    "molbert_X = pd.concat([bbbp_molbert_prob, bbbp_molbert_features], axis=1)\n",
    "\n",
    "# Standardize each dataset\n",
    "scaler_chemberta = StandardScaler().fit(chemberta_X)\n",
    "scaler_molformer = StandardScaler().fit(molformer_X)\n",
    "scaler_molbert = StandardScaler().fit(molbert_X)\n",
    "\n",
    "chemberta_X_scaled = scaler_chemberta.transform(chemberta_X)\n",
    "molformer_X_scaled = scaler_molformer.transform(molformer_X)\n",
    "molbert_X_scaled = scaler_molbert.transform(molbert_X)\n",
    "\n",
    "# Define the binary cross-entropy loss values as target variables (y)\n",
    "chemberta_y_bce = bce_chemberta  # Row-wise BCE loss calculated earlier\n",
    "molformer_y_bce = bce_molformer  # Row-wise BCE loss calculated earlier\n",
    "molbert_y_bce = bce_molbert      # Row-wise BCE loss calculated earlier\n",
    "\n",
    "# Define RMSE scorer\n",
    "def rmse_scorer(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# Define the hyperparameter space for regression using continuous distributions\n",
    "xgb_hyperopt_space = {\n",
    "    'n_estimators': hp.quniform('n_estimators', 50, 200, 50),\n",
    "    'max_depth': hp.quniform('max_depth', 3, 7, 2),\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.001, 0.3),\n",
    "    'subsample': hp.uniform('subsample', 0.5, 1.0),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1.0)\n",
    "}\n",
    "\n",
    "# Objective function for hyperopt with XGBRegressor\n",
    "def objective(params, X_train, y_train):\n",
    "    # Convert float outputs of hp.quniform to int for certain parameters\n",
    "    params['n_estimators'] = int(params['n_estimators'])\n",
    "    params['max_depth'] = int(params['max_depth'])\n",
    "    \n",
    "    # Initialize XGBRegressor with the given parameters\n",
    "    model = xgb.XGBRegressor(**params, random_state=0)\n",
    "    \n",
    "    # RMSE as the scoring metric\n",
    "    rmse = make_scorer(rmse_scorer, greater_is_better=False)\n",
    "    score = cross_val_score(model, X_train, y_train, scoring=rmse, cv=5)\n",
    "    \n",
    "    # Minimize the negative RMSE score\n",
    "    return {'loss': -score.mean(), 'status': STATUS_OK}\n",
    "\n",
    "# Function to optimize and train the model for each dataset\n",
    "def optimize_and_train(X_train, y_train):\n",
    "    # Run the Bayesian optimization\n",
    "    trials = Trials()\n",
    "    best_params = fmin(fn=lambda params: objective(params, X_train, y_train), \n",
    "                       space=xgb_hyperopt_space, \n",
    "                       algo=tpe.suggest, \n",
    "                       max_evals=50, \n",
    "                       trials=trials,\n",
    "                       rstate=np.random.default_rng(0),  # Seed for reproducibility in hyperopt\n",
    "                       early_stop_fn=no_progress_loss(10))\n",
    "\n",
    "    # Convert the best hyperparameters to the correct data types\n",
    "    best_params['n_estimators'] = int(best_params['n_estimators'])\n",
    "    best_params['max_depth'] = int(best_params['max_depth'])\n",
    "\n",
    "    # Initialize and train the XGBoost model with the best parameters\n",
    "    model = xgb.XGBRegressor(**best_params, random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Optimizing and training for chemberta dataset\n",
    "print(\"Optimizing for chemberta dataset...\")\n",
    "best_model_chemberta = optimize_and_train(chemberta_X_scaled, chemberta_y_bce)\n",
    "\n",
    "# Optimizing and training for molformer dataset\n",
    "print(\"Optimizing for molformer dataset...\")\n",
    "best_model_molformer = optimize_and_train(molformer_X_scaled, molformer_y_bce)\n",
    "\n",
    "# Optimizing and training for molbert dataset\n",
    "print(\"Optimizing for molbert dataset...\")\n",
    "best_model_molbert = optimize_and_train(molbert_X_scaled, molbert_y_bce)\n",
    "\n",
    "# Print a confirmation message\n",
    "print(\"Models trained for chemberta, molformer, and molbert datasets.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing smiles in molformer_test: {'n1c(csc1\\\\[NH]=C(\\\\N)N)c1cccc(c1)NC(C)=O'}\n",
      "Missing smiles in molbert_test: {'n1c(csc1\\\\[NH]=C(\\\\N)N)c1cccc(c1)NC(C)=O'}\n",
      "These indices will be removed from the test set: ['n1c(csc1\\\\[NH]=C(\\\\N)N)c1cccc(c1)NC(C)=O']\n"
     ]
    }
   ],
   "source": [
    "# identify missing in test\n",
    "missing_smiles_molformer_test = set(bbbp_chemberta2_test['smiles']) - set(bbbp_molformer_test['smiles'])\n",
    "print(f\"Missing smiles in molformer_test: {missing_smiles_molformer_test}\")\n",
    "\n",
    "missing_smiles_molbert_test = set(bbbp_chemberta2_test['smiles']) - set(bbbp_molbert_test['smiles'])\n",
    "print(f\"Missing smiles in molbert_test: {missing_smiles_molbert_test}\")\n",
    "\n",
    "# Combine the invalid smiles from molformer_test with the missing smiles from molbert_test\n",
    "combined_invalid_smiles_test = list(set(missing_smiles_molformer_test).union(set(missing_smiles_molbert_test)))\n",
    "print(f\"These indices will be removed from the test set: {combined_invalid_smiles_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(204, 8)\n",
      "(204, 6)\n",
      "(204, 4)\n",
      "(204, 386)\n",
      "(204, 769)\n",
      "(204, 769)\n"
     ]
    }
   ],
   "source": [
    "# Remove invalid SMILES from each dataframe\n",
    "bbbp_chemberta2_test = remove_invalid_smiles(bbbp_chemberta2_test, combined_invalid_smiles_test)\n",
    "bbbp_molformer_test = remove_invalid_smiles(bbbp_molformer_test, combined_invalid_smiles_test)\n",
    "bbbp_molbert_test = remove_invalid_smiles(bbbp_molbert_test, combined_invalid_smiles_test)\n",
    "bbbp_chemberta2_features_test = remove_invalid_smiles(bbbp_chemberta2_features_test, combined_invalid_smiles_test)\n",
    "bbbp_molformer_features_test = remove_invalid_smiles(bbbp_molformer_features_test, combined_invalid_smiles_test)\n",
    "bbbp_molbert_features_test = remove_invalid_smiles(bbbp_molbert_features_test, combined_invalid_smiles_test)\n",
    "\n",
    "# Print the shapes of the dataframes after removal\n",
    "print(bbbp_chemberta2_test.shape)\n",
    "print(bbbp_molformer_test.shape)\n",
    "print(bbbp_molbert_test.shape)\n",
    "print(bbbp_chemberta2_features_test.shape)\n",
    "print(bbbp_molformer_features_test.shape)\n",
    "print(bbbp_molbert_features_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# Test data for each model\n",
    "bbbp_chemberta2_prob_test = pd.DataFrame({'chemberta2': bbbp_chemberta2_test['softmax_class_1_prob']})\n",
    "bbbp_chemberta2_prob_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "bbbp_molformer_prob_test = pd.DataFrame({'molformer': bbbp_molformer_test['Prob_Class_1']})\n",
    "bbbp_molformer_prob_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "bbbp_molbert_prob_test = pd.DataFrame({'molbert': bbbp_molbert_test['prob']})\n",
    "bbbp_molbert_prob_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "bbbp_chemberta2_features_t = pd.DataFrame(bbbp_chemberta2_features_test.iloc[:, 2:])\n",
    "bbbp_chemberta2_features_t.reset_index(drop=True, inplace=True)\n",
    "\n",
    "bbbp_molformer_features_t  = pd.DataFrame(bbbp_molformer_features_test.iloc[:, 1:])\n",
    "bbbp_molformer_features_t.reset_index(drop=True, inplace=True)\n",
    "\n",
    "bbbp_molbert_features_t = pd.DataFrame(bbbp_molbert_features_test.iloc[:, 1:])\n",
    "bbbp_molbert_features_t.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Combine probabilities with the respective feature sets for the test set\n",
    "chemberta_X_test = pd.concat([bbbp_chemberta2_prob_test, bbbp_chemberta2_features_t], axis=1)\n",
    "molformer_X_test = pd.concat([bbbp_molformer_prob_test, bbbp_molformer_features_t], axis=1)\n",
    "molbert_X_test = pd.concat([bbbp_molbert_prob_test, bbbp_molbert_features_t], axis=1)\n",
    "\n",
    "# Standardize the test set based on the previously fitted scalers\n",
    "chemberta_X_test_scaled = scaler_chemberta.transform(chemberta_X_test)\n",
    "molformer_X_test_scaled = scaler_molformer.transform(molformer_X_test)\n",
    "molbert_X_test_scaled = scaler_molbert.transform(molbert_X_test)\n",
    "\n",
    "# Predict using the best models from valid2\n",
    "chemberta_pred_test = best_model_chemberta.predict(chemberta_X_test_scaled)\n",
    "molformer_pred_test = best_model_molformer.predict(molformer_X_test_scaled)\n",
    "molbert_pred_test = best_model_molbert.predict(molbert_X_test_scaled)\n",
    "\n",
    "# Convert the predictions (numpy arrays) to pandas Series\n",
    "chemberta_pred_test_series = pd.Series(chemberta_pred_test, name='bce_chemberta')\n",
    "molformer_pred_test_series = pd.Series(molformer_pred_test, name='bce_molformer')\n",
    "molbert_pred_test_series = pd.Series(molbert_pred_test, name='bce_molbert')\n",
    "\n",
    "# Now concatenate the series with the test set probabilities\n",
    "bbbp_X_ensemble_test = pd.concat([\n",
    "    chemberta_pred_test_series,                     # BCE for Chemberta\n",
    "    molformer_pred_test_series,                     # BCE for Molformer\n",
    "    molbert_pred_test_series,                       # BCE for Molbert\n",
    "    bbbp_chemberta2_prob_test['chemberta2'],        # Chemberta test probabilities\n",
    "    bbbp_molformer_prob_test['molformer'],          # Molformer test probabilities\n",
    "    bbbp_molbert_prob_test['molbert']               # Molbert test probabilities\n",
    "], axis=1)\n",
    "\n",
    "bbbp_X_ensemble_test.columns = ['bce_chemberta', 'bce_molformer', 'bce_molbert', 'chemberta2', 'molformer', 'molbert']\n",
    "\n",
    "# optional for evaluation\n",
    "bbbp_y_ensemble_test = bbbp_chemberta2_test['p_np']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use standard scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "bbbp_X_ensemble_valid2_scaled = scaler.fit_transform(bbbp_X_ensemble_valid2)\n",
    "bbbp_X_ensemble_test_scaled = scaler.transform(bbbp_X_ensemble_test)\n",
    "\n",
    "# transform back to dataframe\n",
    "bbbp_X_ensemble_valid2_scaled = pd.DataFrame(bbbp_X_ensemble_valid2_scaled, columns=bbbp_X_ensemble_valid2.columns)\n",
    "bbbp_X_ensemble_test_scaled = pd.DataFrame(bbbp_X_ensemble_test_scaled, columns=bbbp_X_ensemble_test.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(401, 6)\n",
      "(204, 6)\n"
     ]
    }
   ],
   "source": [
    "bbbp_X_ensemble_valid2_selected = bbbp_X_ensemble_valid2_scaled\n",
    "bbbp_X_ensemble_test_selected = bbbp_X_ensemble_test_scaled\n",
    "\n",
    "# check shapes\n",
    "print(bbbp_X_ensemble_valid2_selected.shape)\n",
    "print(bbbp_X_ensemble_test_selected.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [00:01<00:07,  5.29trial/s, best loss: -0.9839181286549709]\n",
      "Best hyperparameters: {'colsample_bytree': 0.9526919134012697, 'learning_rate': 0.25068293229696836, 'max_depth': 4.0, 'n_estimators': 100.0, 'subsample': 0.8411318103731124}\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score, make_scorer\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.early_stop import no_progress_loss\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "np.random.seed(0)\n",
    "\n",
    "# Define the hyperparameter space using continuous distributions\n",
    "bbbp_xgb_hyperopt_space = {\n",
    "    'n_estimators': hp.quniform('n_estimators', 50, 200, 50),\n",
    "    'max_depth': hp.quniform('max_depth', 3, 7, 2),\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.001, 0.3),\n",
    "    'subsample': hp.uniform('subsample', 0.5, 1.0),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1.0)\n",
    "}\n",
    "\n",
    "# Convert float outputs of hp.quniform to int for certain parameters\n",
    "def objective(params):\n",
    "    params['n_estimators'] = int(params['n_estimators'])\n",
    "    params['max_depth'] = int(params['max_depth'])\n",
    "    \n",
    "    model = xgb.XGBClassifier(**params, random_state=0)\n",
    "    \n",
    "    # Cross-validated AUC score as the objective\n",
    "    roc_auc = make_scorer(roc_auc_score, response_method=None)\n",
    "    score = cross_val_score(model, bbbp_X_ensemble_valid2_selected, bbbp_y_ensemble_valid2, scoring=roc_auc, cv=5)\n",
    "    \n",
    "    # Minimize the negative ROC AUC score\n",
    "    return {'loss': -score.mean(), 'status': STATUS_OK}\n",
    "\n",
    "# Run the Bayesian optimization\n",
    "trials = Trials()\n",
    "bbbp_xgb_best_params = fmin(fn=objective, \n",
    "                          space=bbbp_xgb_hyperopt_space, \n",
    "                          algo=tpe.suggest, \n",
    "                          max_evals=50, \n",
    "                          trials=trials,\n",
    "                          rstate=np.random.default_rng(0),  # Seed for hyperopt\n",
    "                          early_stop_fn=no_progress_loss(10))\n",
    "\n",
    "print(\"Best hyperparameters:\", bbbp_xgb_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.8970588235294118,\n",
       " 'F1 Score': 0.9357798165137615,\n",
       " 'ROC-AUC': 0.9499048826886494,\n",
       " 'PR-AUC': 0.9871922319956341}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert parameters obtained from Hyperopt to the correct data type\n",
    "bbbp_xgb_best_params['n_estimators'] = int(bbbp_xgb_best_params['n_estimators'])\n",
    "bbbp_xgb_best_params['max_depth'] = int(bbbp_xgb_best_params['max_depth'])\n",
    "\n",
    "# Initialize and train the XGBoost model with the best parameters\n",
    "bbbp_xgb_model = xgb.XGBClassifier(**bbbp_xgb_best_params, random_state=0)\n",
    "bbbp_xgb_model.fit(bbbp_X_ensemble_valid2_selected, bbbp_y_ensemble_valid2)\n",
    "\n",
    "# Predict the test set\n",
    "bbbp_xgb_best_pred = bbbp_xgb_model.predict(bbbp_X_ensemble_test_selected)\n",
    "bbbp_xgb_best_probs = bbbp_xgb_model.predict_proba(bbbp_X_ensemble_test_selected)\n",
    "\n",
    "# Calculate the metrics\n",
    "bbbp_xgb_best_metrics = {\n",
    "    \"Accuracy\": accuracy_score(bbbp_y_ensemble_test, bbbp_xgb_best_pred),\n",
    "    \"F1 Score\": f1_score(bbbp_y_ensemble_test, bbbp_xgb_best_pred),\n",
    "    \"ROC-AUC\": roc_auc_score(bbbp_y_ensemble_test, bbbp_xgb_best_probs[:, 1]),\n",
    "    \"PR-AUC\": average_precision_score(bbbp_y_ensemble_test, bbbp_xgb_best_probs[:, 1])\n",
    "}\n",
    "\n",
    "bbbp_xgb_best_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report all the metrics for bbbp\n",
    "bbbp_metrics_results[\"XGBoost\"] = bbbp_xgb_best_metrics\n",
    "\n",
    "bbbp_metrics_df = pd.DataFrame(bbbp_metrics_results).T\n",
    "\n",
    "# keep 3 digits after the decimal point\n",
    "bbbp_metrics_df = bbbp_metrics_df.round(3)\n",
    "\n",
    "# export as csv\n",
    "bbbp_metrics_df.to_csv('./split3_bbbp_metrics_xgb.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fusion-env",
   "language": "python",
   "name": "fusion-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
