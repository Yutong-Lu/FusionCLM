{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, precision_recall_curve, average_precision_score, mean_squared_error, r2_score, mean_absolute_error\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# preds\n",
    "\n",
    "# Load the training set of meta-model\n",
    "bace_chemberta2_valid2 = pd.read_csv('./chemberta2/results/bace/chemberta2_valid2_bace_1_predictions.csv')\n",
    "bace_molformer_valid2 = pd.read_csv('./molformer/results/bace/molformer_valid2_bace_1_epoch49.csv')\n",
    "bace_molbert_valid2 = pd.read_csv('./molbert/results/bace/molbert_valid2_bace_1.csv')\n",
    "\n",
    "# Load the test data for each model\n",
    "bace_chemberta2_test = pd.read_csv('./chemberta2/results/bace/chemberta2_test_bace_1_predictions.csv')\n",
    "bace_molformer_test = pd.read_csv('./molformer/results/bace/molformer_test_bace_1_epoch49.csv')\n",
    "bace_molbert_test = pd.read_csv('./molbert/results/bace/molbert_test_bace_1.csv')\n",
    "\n",
    "# features\n",
    "\n",
    "# Load the features from chemberta\n",
    "bace_chemberta2_features_valid2 = pd.read_csv('./chemberta2/features/bace/chemberta2_valid2_bace_1_features.csv')\n",
    "bace_chemberta2_features_test = pd.read_csv('./chemberta2/features/bace/chemberta2_test_bace_1_features.csv')\n",
    "\n",
    "# Load the features from molformer\n",
    "bace_molformer_features_valid2 = pd.read_csv('./molformer/features/bace/molformer_valid2_bace_1_features.csv')\n",
    "bace_molformer_features_test = pd.read_csv('./molformer/features/bace/molformer_test_bace_1_features.csv')\n",
    "\n",
    "# Load the features from molbert\n",
    "bace_molbert_features_valid2 = pd.read_csv('./molbert/features/bace/molbert_valid2_bace_1_features.csv')\n",
    "bace_molbert_features_test = pd.read_csv('./molbert/features/bace/molbert_test_bace_1_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For BACE (Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Chemberta2': {'Accuracy': 0.6535947712418301,\n",
       "  'F1 Score': 0.6442953020134228,\n",
       "  'ROC-AUC': 0.7465949820788532,\n",
       "  'PR-AUC': 0.8058944338111258},\n",
       " 'Molformer': {'Accuracy': 0.6797385620915033,\n",
       "  'F1 Score': 0.6797385620915032,\n",
       "  'ROC-AUC': 0.8521505376344086,\n",
       "  'PR-AUC': 0.8774798970672688},\n",
       " 'Molbert': {'Accuracy': 0.7189542483660131,\n",
       "  'F1 Score': 0.7361963190184049,\n",
       "  'ROC-AUC': 0.775089605734767,\n",
       "  'PR-AUC': 0.8548501462313669}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, average_precision_score\n",
    "\n",
    "# Preparing the actual and predicted values\n",
    "# Chemberta2\n",
    "bace_chemberta_actual = bace_chemberta2_test['Class']\n",
    "bace_chemberta_pred = bace_chemberta2_test['y_pred']\n",
    "bace_chemberta_probs = bace_chemberta2_test[['softmax_class_0_prob', 'softmax_class_1_prob']]\n",
    "\n",
    "# Molformer\n",
    "bace_molformer_actual = bace_molformer_test['Actual']\n",
    "bace_molformer_pred = (bace_molformer_test['Prob_Class_1'] > 0.5).astype(int)\n",
    "bace_molformer_probs = bace_molformer_test[['Prob_Class_0', 'Prob_Class_1']]\n",
    "\n",
    "# Molbert\n",
    "bace_molbert_actual = bace_molbert_test['target']\n",
    "bace_molbert_pred = bace_molbert_test['pred']\n",
    "bace_molbert_probs = bace_molbert_test['prob']\n",
    "\n",
    "# Calculating metrics\n",
    "bace_metrics_results = {}\n",
    "\n",
    "for model_name, actual, pred, probs in [(\"Chemberta2\", bace_chemberta_actual, bace_chemberta_pred, bace_chemberta_probs['softmax_class_1_prob']),\n",
    "                                         (\"Molformer\", bace_molformer_actual, bace_molformer_pred, bace_molformer_probs['Prob_Class_1']),\n",
    "                                         (\"Molbert\", bace_molbert_actual, bace_molbert_pred, bace_molbert_probs)]:\n",
    "    bace_metrics_results[model_name] = {\n",
    "        \"Accuracy\": accuracy_score(actual, pred),\n",
    "        \"F1 Score\": f1_score(actual, pred),\n",
    "        \"ROC-AUC\": roc_auc_score(actual, probs),\n",
    "        \"PR-AUC\": average_precision_score(actual, probs)\n",
    "    }\n",
    "\n",
    "bace_metrics_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(305, 8)\n",
      "(305, 5)\n",
      "(305, 4)\n",
      "(305, 386)\n",
      "(305, 769)\n",
      "(305, 769)\n"
     ]
    }
   ],
   "source": [
    "# check shapes\n",
    "print(bace_chemberta2_valid2.shape)\n",
    "print(bace_molformer_valid2.shape)\n",
    "print(bace_molbert_valid2.shape)\n",
    "print(bace_chemberta2_features_valid2.shape)\n",
    "print(bace_molformer_features_valid2.shape)\n",
    "print(bace_molbert_features_valid2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new dataframe with one column of bace_chemberta2_valid2['softmax_class_1_prob']\n",
    "bace_chemberta2_prob = pd.DataFrame({'chemberta2': bace_chemberta2_valid2['softmax_class_1_prob']})\n",
    "bace_chemberta2_prob.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# create a new dataframe with one column of bace_molformer_valid2['Prob_Class_1']\n",
    "bace_molformer_prob = pd.DataFrame({'molformer': bace_molformer_valid2['Prob_Class_1']})\n",
    "bace_molformer_prob.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# create a new dataframe with one column of bace_molbert_valid2['Probabilities']\n",
    "bace_molbert_prob = pd.DataFrame({'molbert': bace_molbert_valid2['prob']})\n",
    "bace_molbert_prob.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# concatenate the three dataframes\n",
    "bace_prob = pd.concat([bace_chemberta2_prob, bace_molformer_prob, bace_molbert_prob], axis=1)\n",
    "\n",
    "# do the same for features bace_chemberta2_features_valid2.iloc[:, 2:]\n",
    "bace_chemberta2_features = pd.DataFrame(bace_chemberta2_features_valid2.iloc[:, 2:])\n",
    "bace_chemberta2_features.reset_index(drop=True, inplace=True)\n",
    "bace_molformer_features = pd.DataFrame(bace_molformer_features_valid2.iloc[:, 1:])\n",
    "bace_molformer_features.reset_index(drop=True, inplace=True)\n",
    "bace_molbert_features = pd.DataFrame(bace_molbert_features_valid2.iloc[:, 1:])\n",
    "bace_molbert_features.reset_index(drop=True, inplace=True)\n",
    "\n",
    "bace_features = pd.concat([bace_chemberta2_features, bace_molformer_features, bace_molbert_features], axis=1)\n",
    "\n",
    "# combine the features and probabilities\n",
    "bace_X_ensemble_valid2 = pd.concat([bace_prob, bace_features], axis=1)\n",
    "\n",
    "bace_y_ensemble_valid2 = bace_chemberta2_valid2['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the same for test probs and features\n",
    "bace_chemberta2_prob = pd.DataFrame({'chemberta2': bace_chemberta2_test['softmax_class_1_prob']})\n",
    "bace_chemberta2_prob.reset_index(drop=True, inplace=True)\n",
    "bace_molformer_prob = pd.DataFrame({'molformer': bace_molformer_test['Prob_Class_1']})\n",
    "bace_molformer_prob.reset_index(drop=True, inplace=True)\n",
    "bace_molbert_prob = pd.DataFrame({'molbert': bace_molbert_test['prob']})\n",
    "bace_molbert_prob.reset_index(drop=True, inplace=True)\n",
    "bace_prob = pd.concat([bace_chemberta2_prob, bace_molformer_prob, bace_molbert_prob], axis=1)\n",
    "\n",
    "bace_chemberta2_features = pd.DataFrame(bace_chemberta2_features_test.iloc[:, 2:])\n",
    "bace_chemberta2_features.reset_index(drop=True, inplace=True)\n",
    "bace_molformer_features = pd.DataFrame(bace_molformer_features_test.iloc[:, 1:])\n",
    "bace_molformer_features.reset_index(drop=True, inplace=True)\n",
    "bace_molbert_features = pd.DataFrame(bace_molbert_features_test.iloc[:, 1:])\n",
    "bace_molbert_features.reset_index(drop=True, inplace=True)\n",
    "bace_features = pd.concat([bace_chemberta2_features, bace_molformer_features, bace_molbert_features], axis=1)\n",
    "\n",
    "bace_X_ensemble_test = pd.concat([bace_prob, bace_features], axis=1)\n",
    "\n",
    "bace_y_ensemble_test = bace_chemberta2_test['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use standard scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "bace_X_ensemble_valid2_scaled = scaler.fit_transform(bace_X_ensemble_valid2)\n",
    "bace_X_ensemble_test_scaled = scaler.transform(bace_X_ensemble_test)\n",
    "\n",
    "# transform back to dataframe\n",
    "bace_X_ensemble_valid2_scaled = pd.DataFrame(bace_X_ensemble_valid2_scaled, columns=bace_X_ensemble_valid2.columns)\n",
    "bace_X_ensemble_test_scaled = pd.DataFrame(bace_X_ensemble_test_scaled, columns=bace_X_ensemble_test.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.7124183006535948,\n",
       " 'F1 Score': 0.725,\n",
       " 'ROC-AUC': 0.8261648745519713,\n",
       " 'PR-AUC': 0.8541481619100135}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from group_lasso import LogisticGroupLasso\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, average_precision_score\n",
    "\n",
    "# Example data loading - Ensure your dataset is loaded and scaled\n",
    "# bace_X_ensemble_valid2_scaled, bace_y_ensemble_valid2 = load_your_data()\n",
    "\n",
    "# Define the groups for features\n",
    "n_features = bace_X_ensemble_valid2_scaled.shape[1]\n",
    "groups = np.zeros(n_features, dtype=int)\n",
    "groups[:3] = 1  # First three features as one group\n",
    "groups[3:] = 2  # Rest of the features as another group\n",
    "\n",
    "# Define the range of group_reg values to try\n",
    "group_reg_values = np.logspace(-3, 1, 5)  # Example range from 0.001 to 10\n",
    "\n",
    "# Setup cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "# Setup the GridSearchCV with LogisticGroupLasso\n",
    "model = LogisticGroupLasso(\n",
    "    groups=groups,\n",
    "    l1_reg=0,  # No L1 regularization\n",
    "    scale_reg='none',  # No automatic scaling\n",
    "    supress_warning=True,\n",
    "    tol=1e-2,\n",
    "    random_state=0,\n",
    ")\n",
    "\n",
    "param_grid = {'group_reg': group_reg_values}\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=cv, scoring='roc_auc')\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(bace_X_ensemble_valid2_scaled, bace_y_ensemble_valid2)\n",
    "\n",
    "# Best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predictions and probabilities on a test set\n",
    "# Assuming bace_X_ensemble_test_scaled and bace_y_ensemble_test are available\n",
    "bace_group_lasso_pred = best_model.predict(bace_X_ensemble_test_scaled)\n",
    "bace_group_lasso_probs = best_model.predict_proba(bace_X_ensemble_test_scaled)[:, 1]\n",
    "\n",
    "# Evaluate the best model\n",
    "bace_two_groups_lasso_metrics = {\n",
    "    \"Accuracy\": accuracy_score(bace_y_ensemble_test, bace_group_lasso_pred),\n",
    "    \"F1 Score\": f1_score(bace_y_ensemble_test, bace_group_lasso_pred),\n",
    "    \"ROC-AUC\": roc_auc_score(bace_y_ensemble_test, bace_group_lasso_probs),\n",
    "    \"PR-AUC\": average_precision_score(bace_y_ensemble_test, bace_group_lasso_probs)\n",
    "}\n",
    "\n",
    "bace_two_groups_lasso_metrics\n",
    "\n",
    "# # Print best model results\n",
    "# print(\"Best Group Reg:\", grid_search.best_params_['group_reg'])\n",
    "# print(\"Metrics:\", bace_two_groups_lasso_metrics)\n",
    "\n",
    "# # Print the coefficients of the best model\n",
    "# print(\"Coefficients:\", best_model.coef_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best group_reg: 0.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.7058823529411765,\n",
       " 'F1 Score': 0.7096774193548387,\n",
       " 'ROC-AUC': 0.8286738351254481,\n",
       " 'PR-AUC': 0.8426376943530206}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from group_lasso import LogisticGroupLasso\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, average_precision_score\n",
    "\n",
    "# Assume data is already loaded into bace_X_ensemble_valid2_scaled and bace_y_ensemble_valid2\n",
    "# Define the groups for each feature\n",
    "n_features = bace_X_ensemble_valid2_scaled.shape[1]\n",
    "groups = np.zeros(n_features, dtype=int)\n",
    "groups[:3] = 1  # First three features as one group\n",
    "groups[3:3+384] = 2  # Next 384 features as another group\n",
    "groups[3+384:3+384+768] = 3  # Next 768 features as third group\n",
    "groups[3+384+768:] = 4  # Remaining features as fourth group\n",
    "\n",
    "# Setup cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "param_grid = {'group_reg': np.logspace(-3, 1, 5)}  # Define a range of group_reg values\n",
    "\n",
    "# Initialize the LogisticGroupLasso model within GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=LogisticGroupLasso(\n",
    "        groups=groups,\n",
    "        l1_reg=0,\n",
    "        scale_reg='none',\n",
    "        supress_warning=True,\n",
    "        tol=1e-2,\n",
    "        random_state=0,\n",
    "    ),\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring='roc_auc'\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(bace_X_ensemble_valid2_scaled, bace_y_ensemble_valid2)\n",
    "\n",
    "# Best model and parameters\n",
    "best_model = grid_search.best_estimator_\n",
    "print(\"Best group_reg:\", grid_search.best_params_['group_reg'])\n",
    "\n",
    "# Predict and evaluate using the best model\n",
    "bace_group_lasso_pred = best_model.predict(bace_X_ensemble_test_scaled)\n",
    "bace_group_lasso_probs = best_model.predict_proba(bace_X_ensemble_test_scaled)[:, 1]\n",
    "\n",
    "# Calculate metrics\n",
    "bace_four_groups_lasso_metrics = {\n",
    "    \"Accuracy\": accuracy_score(bace_y_ensemble_test, bace_group_lasso_pred),\n",
    "    \"F1 Score\": f1_score(bace_y_ensemble_test, bace_group_lasso_pred),\n",
    "    \"ROC-AUC\": roc_auc_score(bace_y_ensemble_test, bace_group_lasso_probs),\n",
    "    \"PR-AUC\": average_precision_score(bace_y_ensemble_test, bace_group_lasso_probs)\n",
    "}\n",
    "\n",
    "bace_four_groups_lasso_metrics\n",
    "\n",
    "# Print coefficients for interpretation\n",
    "# coefficients = best_model.coef_\n",
    "# for i in range(1, 5):  # Display coefficients grouped by their groups\n",
    "#     group_coefs = coefficients[groups == i]\n",
    "#     print(f\"Group {i} Coefficients:\")\n",
    "#     print(group_coefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(305, 1923)\n",
      "(153, 1923)\n"
     ]
    }
   ],
   "source": [
    "bace_X_ensemble_valid2_selected = bace_X_ensemble_valid2_scaled\n",
    "bace_X_ensemble_test_selected = bace_X_ensemble_test_scaled\n",
    "# check shapes\n",
    "print(bace_X_ensemble_valid2_selected.shape)\n",
    "print(bace_X_ensemble_test_selected.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.6274509803921569,\n",
       " 'F1 Score': 0.5839416058394161,\n",
       " 'ROC-AUC': 0.860752688172043,\n",
       " 'PR-AUC': 0.8866411394096438}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and train the SVM model\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "bace_svm_model = SVC(probability=True)\n",
    "bace_svm_model.fit(bace_X_ensemble_valid2_selected, bace_y_ensemble_valid2)\n",
    "\n",
    "# Predict the test set\n",
    "bace_svm_pred = bace_svm_model.predict(bace_X_ensemble_test_selected)\n",
    "bace_svm_probs = bace_svm_model.predict_proba(bace_X_ensemble_test_selected)\n",
    "\n",
    "# Calculate the metrics\n",
    "bace_svm_metrics = {\n",
    "    'Accuracy': accuracy_score(bace_y_ensemble_test, bace_svm_pred),\n",
    "    'F1 Score': f1_score(bace_y_ensemble_test, bace_svm_pred),\n",
    "    'ROC-AUC': roc_auc_score(bace_y_ensemble_test, bace_svm_probs[:, 1]),\n",
    "    \"PR-AUC\": average_precision_score(bace_y_ensemble_test, bace_svm_probs[:, 1])\n",
    "}\n",
    "\n",
    "bace_svm_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.6339869281045751,\n",
       " 'F1 Score': 0.6,\n",
       " 'ROC-AUC': 0.8420250896057349,\n",
       " 'PR-AUC': 0.8729096193143699}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initailize and use a 5-fold cross-validation to tune the hyperparameters of a random forest model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "bace_rf_model = RandomForestClassifier(random_state=0)\n",
    "\n",
    "bace_rf_model.fit(bace_X_ensemble_valid2_selected, bace_y_ensemble_valid2)\n",
    "\n",
    "# Predict the test set\n",
    "bace_rf_best_pred = bace_rf_model.predict(bace_X_ensemble_test_selected)\n",
    "bace_rf_best_probs = bace_rf_model.predict_proba(bace_X_ensemble_test_selected)\n",
    "\n",
    "# Calculate the metrics\n",
    "bace_rf_best_metrics = {\n",
    "    \"Accuracy\": accuracy_score(bace_y_ensemble_test, bace_rf_best_pred),\n",
    "    \"F1 Score\": f1_score(bace_y_ensemble_test, bace_rf_best_pred),\n",
    "    \"ROC-AUC\": roc_auc_score(bace_y_ensemble_test, bace_rf_best_probs[:, 1]),\n",
    "    \"PR-AUC\": average_precision_score(bace_y_ensemble_test, bace_rf_best_probs[:, 1])\n",
    "}\n",
    "\n",
    "bace_rf_best_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [00:57<03:50,  5.76s/trial, best loss: -0.9388131868131868]\n",
      "Best hyperparameters: {'colsample_bytree': 0.6253001900637998, 'learning_rate': 0.005847905873763658, 'max_depth': 4.0, 'n_estimators': 100.0, 'subsample': 0.8127114352855627}\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score, make_scorer\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.early_stop import no_progress_loss\n",
    "\n",
    "# Define the hyperparameter space using continuous distributions\n",
    "bace_xgb_hyperopt_space = {\n",
    "    'n_estimators': hp.quniform('n_estimators', 50, 200, 50),\n",
    "    'max_depth': hp.quniform('max_depth', 3, 7, 2),\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.001, 0.3),\n",
    "    'subsample': hp.uniform('subsample', 0.5, 1.0),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1.0)\n",
    "}\n",
    "\n",
    "# Convert float outputs of hp.quniform to int for certain parameters\n",
    "def objective(params):\n",
    "    params['n_estimators'] = int(params['n_estimators'])\n",
    "    params['max_depth'] = int(params['max_depth'])\n",
    "    \n",
    "    model = xgb.XGBClassifier(**params, random_state=0)\n",
    "    \n",
    "    # Create a scorer that calculates the roc_auc score using predicted probabilities\n",
    "    roc_auc = make_scorer(roc_auc_score, needs_proba=True)\n",
    "    score = cross_val_score(model, bace_X_ensemble_valid2_selected, bace_y_ensemble_valid2, scoring=roc_auc, cv=5)\n",
    "    \n",
    "    # Minimize the negative ROC AUC score\n",
    "    return {'loss': -score.mean(), 'status': STATUS_OK}\n",
    "\n",
    "# Run the Bayesian optimization\n",
    "trials = Trials()\n",
    "bace_xgb_best_params = fmin(fn=objective, \n",
    "                            space=bace_xgb_hyperopt_space, \n",
    "                            algo=tpe.suggest, \n",
    "                            max_evals=50, \n",
    "                            trials=trials,\n",
    "                            early_stop_fn=no_progress_loss(10))\n",
    "\n",
    "print(\"Best hyperparameters:\", bace_xgb_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.7058823529411765,\n",
       " 'F1 Score': 0.713375796178344,\n",
       " 'ROC-AUC': 0.839426523297491,\n",
       " 'PR-AUC': 0.8754713161742003}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert parameters obtained from Hyperopt to the correct data type\n",
    "bace_xgb_best_params['n_estimators'] = int(bace_xgb_best_params['n_estimators'])\n",
    "bace_xgb_best_params['max_depth'] = int(bace_xgb_best_params['max_depth'])\n",
    "\n",
    "# Initialize and train the XGBoost model with the best parameters\n",
    "bace_xgb_model = xgb.XGBClassifier(**bace_xgb_best_params, random_state=0)\n",
    "bace_xgb_model.fit(bace_X_ensemble_valid2_selected, bace_y_ensemble_valid2)\n",
    "\n",
    "# Predict the test set\n",
    "bace_xgb_best_pred = bace_xgb_model.predict(bace_X_ensemble_test_selected)\n",
    "bace_xgb_best_probs = bace_xgb_model.predict_proba(bace_X_ensemble_test_selected)\n",
    "\n",
    "# Calculate the metrics\n",
    "bace_xgb_best_metrics = {\n",
    "    \"Accuracy\": accuracy_score(bace_y_ensemble_test, bace_xgb_best_pred),\n",
    "    \"F1 Score\": f1_score(bace_y_ensemble_test, bace_xgb_best_pred),\n",
    "    \"ROC-AUC\": roc_auc_score(bace_y_ensemble_test, bace_xgb_best_probs[:, 1]),\n",
    "    \"PR-AUC\": average_precision_score(bace_y_ensemble_test, bace_xgb_best_probs[:, 1])\n",
    "}\n",
    "\n",
    "bace_xgb_best_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 19/50 [01:30<02:27,  4.74s/trial, best loss: -0.9070756217466742]\n",
      "Best hyperparameters: {'dropout_rate': 0.19633897351920887, 'learning_rate': 0.00041510185129241473, 'num_layers': 1.0, 'num_neurons': 217.0}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.early_stop import no_progress_loss\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Define the neural network model\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, num_layers, num_neurons, dropout_rate):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        layers = [nn.Linear(input_size, num_neurons), nn.ReLU(), nn.Dropout(dropout_rate)]\n",
    "        \n",
    "        for _ in range(num_layers - 1):\n",
    "            layers += [nn.Linear(num_neurons, num_neurons), nn.ReLU(), nn.Dropout(dropout_rate)]\n",
    "        \n",
    "        layers += [nn.Linear(num_neurons, 1), nn.Sigmoid()]\n",
    "        \n",
    "        self.layers = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "# Objective function for Bayesian optimization\n",
    "def objective(params):\n",
    "    kf = KFold(n_splits=5)\n",
    "    roc_aucs = []\n",
    "\n",
    "    for train_index, val_index in kf.split(X):\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "        train_dataset = TensorDataset(torch.tensor(X_train.values.astype(np.float32)), \n",
    "                                      torch.tensor(y_train.values.astype(np.float32)).unsqueeze(1))\n",
    "        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "        model = SimpleNN(input_size=X_train.shape[1], num_layers=int(params['num_layers']), \n",
    "                         num_neurons=int(params['num_neurons']), dropout_rate=params['dropout_rate'])\n",
    "        criterion = nn.BCELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=params['learning_rate'])\n",
    "\n",
    "        model.train()\n",
    "        for epoch in range(100):\n",
    "            for inputs, targets in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            X_val_tensor = torch.tensor(X_val.values.astype(np.float32))\n",
    "            y_val_tensor = torch.tensor(y_val.values.astype(np.float32)).unsqueeze(-1)\n",
    "            outputs = model(X_val_tensor)\n",
    "            roc_auc = roc_auc_score(y_val_tensor.numpy(), outputs.numpy())\n",
    "            roc_aucs.append(roc_auc)\n",
    "\n",
    "    avg_roc_auc = np.mean(roc_aucs)\n",
    "    return {'loss': -avg_roc_auc, 'status': STATUS_OK}  # Maximize ROC AUC by minimizing the negative ROC AUC\n",
    "\n",
    "# Hyperparameter space\n",
    "space = {\n",
    "    'num_layers': hp.quniform('num_layers', 1, 5, 1),\n",
    "    'num_neurons': hp.quniform('num_neurons', 16, 256, 1),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.0001), np.log(0.01)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.0, 0.5)\n",
    "}\n",
    "\n",
    "X = bace_X_ensemble_valid2_selected\n",
    "y = bace_y_ensemble_valid2\n",
    "\n",
    "# Run Bayesian optimization\n",
    "trials = Trials()\n",
    "bace_nn_best_params = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=50,\n",
    "            trials=trials,\n",
    "            early_stop_fn=no_progress_loss(10))\n",
    "\n",
    "print(\"Best hyperparameters:\", bace_nn_best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.6797385620915033,\n",
       " 'F1 Score': 0.6754966887417218,\n",
       " 'ROC-AUC': 0.8525089605734767,\n",
       " 'PR-AUC': 0.8828610080606898}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Define the neural network model again\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, num_layers, num_neurons, dropout_rate):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        layers = [nn.Linear(input_size, num_neurons), nn.ReLU(), nn.Dropout(dropout_rate)]\n",
    "        \n",
    "        for _ in range(num_layers - 1):\n",
    "            layers += [nn.Linear(num_neurons, num_neurons), nn.ReLU(), nn.Dropout(dropout_rate)]\n",
    "        \n",
    "        layers += [nn.Linear(num_neurons, 1), nn.Sigmoid()]\n",
    "        \n",
    "        self.layers = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "# Convert parameters to the correct format if necessary\n",
    "bace_nn_best_params = {\n",
    "    'num_layers': int(bace_nn_best_params['num_layers']),  # Extracted from Bayesian optimization results\n",
    "    'num_neurons': int(bace_nn_best_params['num_neurons']),  # Extracted from Bayesian optimization results\n",
    "    'dropout_rate': bace_nn_best_params['dropout_rate'],  # Extracted from Bayesian optimization results\n",
    "    'learning_rate': bace_nn_best_params['learning_rate']  # Extracted from Bayesian optimization results\n",
    "}\n",
    "\n",
    "# Prepare datasets\n",
    "X_train_tensor = torch.tensor(bace_X_ensemble_valid2_selected.values.astype(np.float32))\n",
    "y_train_tensor = torch.tensor(bace_y_ensemble_valid2.values.astype(np.float32)).unsqueeze(1)\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "X_test_tensor = torch.tensor(bace_X_ensemble_test_selected.values.astype(np.float32))\n",
    "y_test_tensor = torch.tensor(bace_y_ensemble_test.values.astype(np.float32)).unsqueeze(1)\n",
    "\n",
    "# Initialize the model\n",
    "model = SimpleNN(input_size=bace_X_ensemble_valid2_selected.shape[1], num_layers=bace_nn_best_params['num_layers'], \n",
    "                 num_neurons=bace_nn_best_params['num_neurons'], dropout_rate=bace_nn_best_params['dropout_rate'])\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=bace_nn_best_params['learning_rate'])\n",
    "\n",
    "# Training loop\n",
    "model.train()\n",
    "for epoch in range(100):  # Number of epochs can be adjusted\n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Evaluation on test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_test_tensor)\n",
    "    predictions = (outputs > 0.5).float()\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test_tensor.numpy(), predictions.numpy())\n",
    "    f1 = f1_score(y_test_tensor.numpy(), predictions.numpy())\n",
    "    roc_auc = roc_auc_score(y_test_tensor.numpy(), outputs.numpy())\n",
    "    pr_auc = average_precision_score(y_test_tensor.numpy(), outputs.numpy())\n",
    "\n",
    "    bace_nn_metrics = {\n",
    "        'Accuracy': accuracy,\n",
    "        'F1 Score': f1,\n",
    "        'ROC-AUC': roc_auc,\n",
    "        'PR-AUC': pr_auc\n",
    "    }\n",
    "\n",
    "bace_nn_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report all the metrics for ct\n",
    "bace_metrics_results[\"Two Groups Lasso\"] = bace_two_groups_lasso_metrics\n",
    "bace_metrics_results[\"Four Groups Lasso\"] = bace_four_groups_lasso_metrics\n",
    "bace_metrics_results[\"SVM\"] = bace_svm_metrics\n",
    "bace_metrics_results[\"Random Forest\"] = bace_rf_best_metrics\n",
    "bace_metrics_results[\"XGBoost\"] = bace_xgb_best_metrics\n",
    "bace_metrics_results[\"Neural Network\"] = bace_nn_metrics\n",
    "\n",
    "bace_metrics_df = pd.DataFrame(bace_metrics_results).T\n",
    "\n",
    "# keep 3 digits after the decimal point\n",
    "bace_metrics_df = bace_metrics_df.round(3)\n",
    "\n",
    "# export as csv\n",
    "bace_metrics_df.to_csv('./split1_bace_metrics_grouplasso.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fusion-env",
   "language": "python",
   "name": "fusion-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
