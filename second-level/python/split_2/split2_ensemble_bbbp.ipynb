{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, precision_recall_curve, average_precision_score, mean_squared_error, r2_score, mean_absolute_error\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# preds\n",
    "\n",
    "# Load the training set of meta-model\n",
    "bbbp_chemberta2_valid2 = pd.read_csv('./chemberta2/results/bbbp/chemberta2_valid2_bbbp_2_predictions.csv')\n",
    "bbbp_molformer_valid2 = pd.read_csv('./molformer/results/bbbp/molformer_valid2_bbbp_2_epoch29.csv')\n",
    "bbbp_molbert_valid2 = pd.read_csv('./molbert/results/bbbp/molbert_valid2_bbbp_2.csv')\n",
    "\n",
    "# Load the test data for each model\n",
    "bbbp_chemberta2_test = pd.read_csv('./chemberta2/results/bbbp/chemberta2_test_bbbp_2_predictions.csv')\n",
    "bbbp_molformer_test = pd.read_csv('./molformer/results/bbbp/molformer_test_bbbp_2_epoch29.csv')\n",
    "bbbp_molbert_test = pd.read_csv('./molbert/results/bbbp/molbert_test_bbbp_2.csv')\n",
    "\n",
    "# features\n",
    "\n",
    "# Load the features from chemberta\n",
    "bbbp_chemberta2_features_valid2 = pd.read_csv('./chemberta2/features/bbbp/chemberta2_valid2_bbbp_2_features.csv')\n",
    "bbbp_chemberta2_features_test = pd.read_csv('./chemberta2/features/bbbp/chemberta2_test_bbbp_2_features.csv')\n",
    "\n",
    "# Load the features from molformer\n",
    "bbbp_molformer_features_valid2 = pd.read_csv('./molformer/features/bbbp/molformer_valid2_bbbp_2_features.csv')\n",
    "bbbp_molformer_features_test = pd.read_csv('./molformer/features/bbbp/molformer_test_bbbp_2_features.csv')\n",
    "\n",
    "# Load the features from molbert\n",
    "bbbp_molbert_features_valid2 = pd.read_csv('./molbert/features/bbbp/molbert_valid2_bbbp_2_features.csv')\n",
    "bbbp_molbert_features_test = pd.read_csv('./molbert/features/bbbp/molbert_test_bbbp_2_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For BBBP (Classification)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Chemberta2': {'Accuracy': 0.8634146341463415,\n",
       "  'F1 Score': 0.9072847682119205,\n",
       "  'ROC-AUC': 0.9566584632212196,\n",
       "  'PR-AUC': 0.9881838964094798},\n",
       " 'Molformer': {'Accuracy': 0.9264705882352942,\n",
       "  'F1 Score': 0.9538461538461539,\n",
       "  'ROC-AUC': 0.9208172812328014,\n",
       "  'PR-AUC': 0.9642320592298499},\n",
       " 'Molbert': {'Accuracy': 0.9411764705882353,\n",
       "  'F1 Score': 0.9625,\n",
       "  'ROC-AUC': 0.9640891579526691,\n",
       "  'PR-AUC': 0.9894812187118154}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, average_precision_score\n",
    "\n",
    "# Preparing the actual and predicted values\n",
    "# Chemberta2\n",
    "bbbp_chemberta_actual = bbbp_chemberta2_test['p_np']\n",
    "bbbp_chemberta_pred = bbbp_chemberta2_test['y_pred']\n",
    "bbbp_chemberta_probs = bbbp_chemberta2_test[['softmax_class_0_prob', 'softmax_class_1_prob']]\n",
    "\n",
    "# Molformer\n",
    "bbbp_molformer_actual = bbbp_molformer_test['Actual']\n",
    "bbbp_molformer_pred = (bbbp_molformer_test['Prob_Class_1'] > 0.5).astype(int)\n",
    "bbbp_molformer_probs = bbbp_molformer_test[['Prob_Class_0', 'Prob_Class_1']]\n",
    "\n",
    "# Molbert\n",
    "bbbp_molbert_actual = bbbp_molbert_test['target']\n",
    "bbbp_molbert_pred = bbbp_molbert_test['pred']\n",
    "bbbp_molbert_probs = bbbp_molbert_test['prob']\n",
    "\n",
    "# Calculating metrics\n",
    "bbbp_metrics_results = {}\n",
    "\n",
    "for model_name, actual, pred, probs in [(\"Chemberta2\", bbbp_chemberta_actual, bbbp_chemberta_pred, bbbp_chemberta_probs['softmax_class_1_prob']),\n",
    "                                         (\"Molformer\", bbbp_molformer_actual, bbbp_molformer_pred, bbbp_molformer_probs['Prob_Class_1']),\n",
    "                                         (\"Molbert\", bbbp_molbert_actual, bbbp_molbert_pred, bbbp_molbert_probs)]:\n",
    "    bbbp_metrics_results[model_name] = {\n",
    "        \"Accuracy\": accuracy_score(actual, pred),\n",
    "        \"F1 Score\": f1_score(actual, pred),\n",
    "        \"ROC-AUC\": roc_auc_score(actual, probs),\n",
    "        \"PR-AUC\": average_precision_score(actual, probs)\n",
    "    }\n",
    "\n",
    "bbbp_metrics_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing smiles in molformer_valid2: {'c1(nc(NC(N)=[NH2])sc1)CSCCNC(=[NH]C#N)NC', 's1cc(CSCCN\\\\C(NC)=[NH]\\\\C#N)nc1\\\\[NH]=C(\\\\N)N', 'c1c(c(ncc1)CSCCN\\\\C(=[NH]\\\\C#N)NCC)Br'}\n",
      "Number of missing smiles in molformer_valid2: 3\n",
      "Missing smiles in molbert_valid2: {'[Na+].[Na+].CC1(C)S[C@@H]2[C@H](NC(=O)[C@H](N[S]([O-])(=O)=O)c3ccccc3)C(=O)N2[C@H]1C([O-])=O', 's1cc(CSCCN\\\\C(NC)=[NH]\\\\C#N)nc1\\\\[NH]=C(\\\\N)N', '[Na+].[O-][S](=O)(=O)CCS', '[Na+].[Na+].[Na+].[O-]C(=O)[P]([O-])([O-])=O', '[Na+].CCOc1ccc2ccccc2c1C(=O)N[C@H]3[C@H]4SC(C)(C)[C@@H](N4C3=O)C([O-])=O', '[Na].CO[C@]1(NC(=O)CSC(F)(F)F)[C@H]2OCC(=C(N2C1=O)C(O)=O)CSc3nnnn3CCO', 'c1(nc(NC(N)=[NH2])sc1)CSCCNC(=[NH]C#N)NC', '[Na+].COCC1=C(N2[C@H](SC1)[C@H](NC(=O)C(=N/OC)\\\\c3csc(N)n3)C2=O)C([O-])=O', 'c1c(c(ncc1)CSCCN\\\\C(=[NH]\\\\C#N)NCC)Br', '[Na+].CC(=O)Nc1c(I)c(NC(C)=O)c(I)c(C([O-])=O)c1I'}\n",
      "Number of missing smiles in molbert_valid2: 10\n",
      "These smiles will be removed from the valid2 set: ['s1cc(CSCCN\\\\C(NC)=[NH]\\\\C#N)nc1\\\\[NH]=C(\\\\N)N', '[Na+].[Na+].CC1(C)S[C@@H]2[C@H](NC(=O)[C@H](N[S]([O-])(=O)=O)c3ccccc3)C(=O)N2[C@H]1C([O-])=O', '[Na+].[O-][S](=O)(=O)CCS', '[Na+].[Na+].[Na+].[O-]C(=O)[P]([O-])([O-])=O', '[Na+].CCOc1ccc2ccccc2c1C(=O)N[C@H]3[C@H]4SC(C)(C)[C@@H](N4C3=O)C([O-])=O', '[Na].CO[C@]1(NC(=O)CSC(F)(F)F)[C@H]2OCC(=C(N2C1=O)C(O)=O)CSc3nnnn3CCO', 'c1(nc(NC(N)=[NH2])sc1)CSCCNC(=[NH]C#N)NC', '[Na+].COCC1=C(N2[C@H](SC1)[C@H](NC(=O)C(=N/OC)\\\\c3csc(N)n3)C2=O)C([O-])=O', 'c1c(c(ncc1)CSCCN\\\\C(=[NH]\\\\C#N)NCC)Br', '[Na+].CC(=O)Nc1c(I)c(NC(C)=O)c(I)c(C([O-])=O)c1I']\n"
     ]
    }
   ],
   "source": [
    "# Identify the 'smiles' values in chemberta2_valid2 that are not in molformer_valid2\n",
    "missing_smiles_molformer_valid2 = set(bbbp_chemberta2_valid2['smiles']) - set(bbbp_molformer_valid2['smiles'])\n",
    "print(f\"Missing smiles in molformer_valid2: {missing_smiles_molformer_valid2}\")\n",
    "print(f\"Number of missing smiles in molformer_valid2: {len(missing_smiles_molformer_valid2)}\")\n",
    "\n",
    "# Identify the 'smiles' values in chemberta2_valid2 that are not in molbert_valid2\n",
    "missing_smiles_molbert_valid2 = set(bbbp_chemberta2_valid2['smiles']) - set(bbbp_molbert_valid2['smiles'])\n",
    "print(f\"Missing smiles in molbert_valid2: {missing_smiles_molbert_valid2}\")\n",
    "print(f\"Number of missing smiles in molbert_valid2: {len(missing_smiles_molbert_valid2)}\")\n",
    "\n",
    "# Combine the invalid smiles from molformer_valid2 with the missing smiles from molbert_valid2\n",
    "combined_invalid_smiles_valid2 = list(set(missing_smiles_molformer_valid2).union(set(missing_smiles_molbert_valid2)))\n",
    "\n",
    "print(f\"These smiles will be removed from the valid2 set: {combined_invalid_smiles_valid2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 8)\n",
      "(400, 6)\n",
      "(400, 4)\n",
      "(400, 386)\n",
      "(400, 769)\n",
      "(400, 769)\n"
     ]
    }
   ],
   "source": [
    "# Drop the rows containing the combined invalid smiles from all relevant DataFrames\n",
    "bbbp_chemberta2_valid2 = bbbp_chemberta2_valid2[~bbbp_chemberta2_valid2['smiles'].isin(combined_invalid_smiles_valid2)]\n",
    "bbbp_molformer_valid2 = bbbp_molformer_valid2[~bbbp_molformer_valid2['smiles'].isin(combined_invalid_smiles_valid2)]\n",
    "bbbp_chemberta2_features_valid2 = bbbp_chemberta2_features_valid2[~bbbp_chemberta2_features_valid2['smiles'].isin(combined_invalid_smiles_valid2)]\n",
    "bbbp_molformer_features_valid2 = bbbp_molformer_features_valid2[~bbbp_molformer_features_valid2['smiles'].isin(combined_invalid_smiles_valid2)]\n",
    "bbbp_molbert_features_valid2 = bbbp_molbert_features_valid2[~bbbp_molbert_features_valid2['smiles'].isin(combined_invalid_smiles_valid2)]\n",
    "\n",
    "# Check shapes\n",
    "print(bbbp_chemberta2_valid2.shape)\n",
    "print(bbbp_molformer_valid2.shape)\n",
    "print(bbbp_molbert_valid2.shape)\n",
    "print(bbbp_chemberta2_features_valid2.shape)\n",
    "print(bbbp_molformer_features_valid2.shape)\n",
    "print(bbbp_molbert_features_valid2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing smiles in molformer_test: {'Cc1nc(sc1)\\\\[NH]=C(\\\\N)N'}\n",
      "Missing smiles in molbert_test: {'Cc1nc(sc1)\\\\[NH]=C(\\\\N)N'}\n",
      "These smiles will be removed from the test set: ['Cc1nc(sc1)\\\\[NH]=C(\\\\N)N']\n"
     ]
    }
   ],
   "source": [
    "# Identify the 'smiles' values in chemberta2_test that are not in molformer_test\n",
    "missing_smiles_molformer_test = set(bbbp_chemberta2_test['smiles']) - set(bbbp_molformer_test['smiles'])\n",
    "print(f\"Missing smiles in molformer_test: {missing_smiles_molformer_test}\")\n",
    "\n",
    "# Identify the 'smiles' values in chemberta2_test that are not in molbert_test\n",
    "missing_smiles_molbert_test = set(bbbp_chemberta2_test['smiles']) - set(bbbp_molbert_test['smiles'])\n",
    "print(f\"Missing smiles in molbert_test: {missing_smiles_molbert_test}\")\n",
    "\n",
    "# Combine the invalid smiles from molformer_test with the missing smiles from molbert_test\n",
    "combined_invalid_smiles_test = list(set(missing_smiles_molformer_test).union(set(missing_smiles_molbert_test)))\n",
    "\n",
    "print(f\"These smiles will be removed from the test set: {combined_invalid_smiles_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(204, 8)\n",
      "(204, 6)\n",
      "(204, 4)\n",
      "(204, 386)\n",
      "(204, 769)\n",
      "(204, 769)\n"
     ]
    }
   ],
   "source": [
    "# Drop the rows containing the combined invalid smiles from all relevant DataFrames\n",
    "bbbp_chemberta2_test = bbbp_chemberta2_test[~bbbp_chemberta2_test['smiles'].isin(combined_invalid_smiles_test)]\n",
    "bbbp_molformer_test = bbbp_molformer_test[~bbbp_molformer_test['smiles'].isin(combined_invalid_smiles_test)]\n",
    "bbbp_molbert_test = bbbp_molbert_test[~bbbp_molbert_test['smiles'].isin(combined_invalid_smiles_test)]\n",
    "bbbp_chemberta2_features_test = bbbp_chemberta2_features_test[~bbbp_chemberta2_features_test['smiles'].isin(combined_invalid_smiles_test)]\n",
    "bbbp_molformer_features_test = bbbp_molformer_features_test[~bbbp_molformer_features_test['smiles'].isin(combined_invalid_smiles_test)]\n",
    "bbbp_molbert_features_test = bbbp_molbert_features_test[~bbbp_molbert_features_test['smiles'].isin(combined_invalid_smiles_test)]\n",
    "\n",
    "# Check shapes\n",
    "print(bbbp_chemberta2_test.shape)\n",
    "print(bbbp_molformer_test.shape)\n",
    "print(bbbp_molbert_test.shape)\n",
    "print(bbbp_chemberta2_features_test.shape)\n",
    "print(bbbp_molformer_features_test.shape)\n",
    "print(bbbp_molbert_features_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new dataframe with one column of bbbp_chemberta2_valid2['softmax_class_1_prob']\n",
    "bbbp_chemberta2_prob = pd.DataFrame({'chemberta2': bbbp_chemberta2_valid2['softmax_class_1_prob']})\n",
    "bbbp_chemberta2_prob.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# create a new dataframe with one column of bbbp_molformer_valid2['Prob_Class_1']\n",
    "bbbp_molformer_prob = pd.DataFrame({'molformer': bbbp_molformer_valid2['Prob_Class_1']})\n",
    "bbbp_molformer_prob.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# create a new dataframe with one column of bbbp_molbert_valid2['Probabilities']\n",
    "bbbp_molbert_prob = pd.DataFrame({'molbert': bbbp_molbert_valid2['prob']})\n",
    "bbbp_molbert_prob.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# concatenate the three dataframes\n",
    "bbbp_prob = pd.concat([bbbp_chemberta2_prob, bbbp_molformer_prob, bbbp_molbert_prob], axis=1)\n",
    "\n",
    "# do the same for features bbbp_chemberta2_features_valid2.iloc[:, 2:]\n",
    "bbbp_chemberta2_features = pd.DataFrame(bbbp_chemberta2_features_valid2.iloc[:, 2:])\n",
    "bbbp_chemberta2_features.reset_index(drop=True, inplace=True)\n",
    "bbbp_molformer_features = pd.DataFrame(bbbp_molformer_features_valid2.iloc[:, 1:])\n",
    "bbbp_molformer_features.reset_index(drop=True, inplace=True)\n",
    "bbbp_molbert_features = pd.DataFrame(bbbp_molbert_features_valid2.iloc[:, 1:])\n",
    "bbbp_molbert_features.reset_index(drop=True, inplace=True)\n",
    "\n",
    "bbbp_features = pd.concat([bbbp_chemberta2_features, bbbp_molformer_features, bbbp_molbert_features], axis=1)\n",
    "\n",
    "# combine the features and probabilities\n",
    "bbbp_X_ensemble_valid2 = pd.concat([bbbp_prob, bbbp_features], axis=1)\n",
    "\n",
    "bbbp_y_ensemble_valid2 = bbbp_chemberta2_valid2['p_np']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the same for test probs and features\n",
    "bbbp_chemberta2_prob = pd.DataFrame({'chemberta2': bbbp_chemberta2_test['softmax_class_1_prob']})\n",
    "bbbp_chemberta2_prob.reset_index(drop=True, inplace=True)\n",
    "bbbp_molformer_prob = pd.DataFrame({'molformer': bbbp_molformer_test['Prob_Class_1']})\n",
    "bbbp_molformer_prob.reset_index(drop=True, inplace=True)\n",
    "bbbp_molbert_prob = pd.DataFrame({'molbert': bbbp_molbert_test['prob']})\n",
    "bbbp_molbert_prob.reset_index(drop=True, inplace=True)\n",
    "bbbp_prob = pd.concat([bbbp_chemberta2_prob, bbbp_molformer_prob, bbbp_molbert_prob], axis=1)\n",
    "\n",
    "bbbp_chemberta2_features = pd.DataFrame(bbbp_chemberta2_features_test.iloc[:, 2:])\n",
    "bbbp_chemberta2_features.reset_index(drop=True, inplace=True)\n",
    "bbbp_molformer_features = pd.DataFrame(bbbp_molformer_features_test.iloc[:, 1:])\n",
    "bbbp_molformer_features.reset_index(drop=True, inplace=True)\n",
    "bbbp_molbert_features = pd.DataFrame(bbbp_molbert_features_test.iloc[:, 1:])\n",
    "bbbp_molbert_features.reset_index(drop=True, inplace=True)\n",
    "bbbp_features = pd.concat([bbbp_chemberta2_features, bbbp_molformer_features, bbbp_molbert_features], axis=1)\n",
    "\n",
    "bbbp_X_ensemble_test = pd.concat([bbbp_prob, bbbp_features], axis=1)\n",
    "\n",
    "# remove the rows with missing values and record indices so it can be removed from the target\n",
    "missing_indices = bbbp_X_ensemble_test.index[bbbp_X_ensemble_test.isnull().any(axis=1)].tolist()\n",
    "bbbp_X_ensemble_test = bbbp_X_ensemble_test.drop(missing_indices)\n",
    "bbbp_y_ensemble_test = bbbp_chemberta2_test['p_np'].drop(missing_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use standard scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "bbbp_X_ensemble_valid2_scaled = scaler.fit_transform(bbbp_X_ensemble_valid2)\n",
    "bbbp_X_ensemble_test_scaled = scaler.transform(bbbp_X_ensemble_test)\n",
    "\n",
    "# transform back to dataframe\n",
    "bbbp_X_ensemble_valid2_scaled = pd.DataFrame(bbbp_X_ensemble_valid2_scaled, columns=bbbp_X_ensemble_valid2.columns)\n",
    "bbbp_X_ensemble_test_scaled = pd.DataFrame(bbbp_X_ensemble_test_scaled, columns=bbbp_X_ensemble_test.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use min-max scaling\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "# bbbp_X_ensemble_valid2_scaled = scaler.fit_transform(bbbp_X_ensemble_valid2)\n",
    "# bbbp_X_ensemble_valid2_scaled = pd.DataFrame(bbbp_X_ensemble_valid2_scaled, columns=bbbp_X_ensemble_valid2.columns)\n",
    "\n",
    "# bbbp_X_ensemble_test_scaled = scaler.transform(bbbp_X_ensemble_test)\n",
    "# bbbp_X_ensemble_test_scaled = pd.DataFrame(bbbp_X_ensemble_test_scaled, columns=bbbp_X_ensemble_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, average_precision_score\n",
    "\n",
    "# # Define the model with ridge penalty (l2)\n",
    "# ridge_model = LogisticRegression(penalty='l2', solver='lbfgs', max_iter=1000, random_state=0)\n",
    "\n",
    "# # Prepare a range of alpha values to test (or C values, which are the inverse of alpha)\n",
    "# alphas = [0.0001, 0.001, 0.01, 0.1, 1, 10]  # Fewer points, covering a broad range\n",
    "\n",
    "# # Convert alphas to Cs for the parameter grid (since C is the inverse of alpha)\n",
    "# Cs = [1/alpha for alpha in alphas]\n",
    "# params = {'C': Cs}\n",
    "# grid_search = GridSearchCV(ridge_model, param_grid=params, cv=5, scoring='roc_auc')\n",
    "\n",
    "# # Fit the grid search to the data\n",
    "# grid_search.fit(bbbp_X_ensemble_valid2, bbbp_y_ensemble_valid2)\n",
    "\n",
    "# # Best model after grid search\n",
    "# bbbp_best_ridge_model = grid_search.best_estimator_\n",
    "\n",
    "# # Predict the test set\n",
    "# bbbp_ridge_pred = bbbp_best_ridge_model.predict(bbbp_X_ensemble_test)\n",
    "# bbbp_ridge_probs = bbbp_best_ridge_model.predict_proba(bbbp_X_ensemble_test)[:, 1]\n",
    "\n",
    "# # Calculate the metrics\n",
    "# bbbp_ridge_metrics = {\n",
    "#     \"Accuracy\": accuracy_score(bbbp_y_ensemble_test, bbbp_ridge_pred),\n",
    "#     \"F1 Score\": f1_score(bbbp_y_ensemble_test, bbbp_ridge_pred),\n",
    "#     \"ROC-AUC\": roc_auc_score(bbbp_y_ensemble_test, bbbp_ridge_probs),\n",
    "#     \"PR-AUC\": average_precision_score(bbbp_y_ensemble_test, bbbp_ridge_probs)\n",
    "# }\n",
    "\n",
    "# bbbp_ridge_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.9264705882352942,\n",
       " 'F1 Score': 0.9517684887459807,\n",
       " 'ROC-AUC': 0.9649146945514585,\n",
       " 'PR-AUC': 0.9908427330876456}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use lasso regression to train the ensemble model\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "# cross validation for strength of regularization\n",
    "lasso_cv = LogisticRegressionCV(cv=5, penalty='l1', solver='liblinear', max_iter=5000, random_state=0, scoring='roc_auc')\n",
    "\n",
    "# Fit the model\n",
    "lasso_cv.fit(bbbp_X_ensemble_valid2_scaled, bbbp_y_ensemble_valid2)\n",
    "\n",
    "# Predict the test set\n",
    "bbbp_lasso_pred = lasso_cv.predict(bbbp_X_ensemble_test_scaled)\n",
    "bbbp_lasso_probs = lasso_cv.predict_proba(bbbp_X_ensemble_test_scaled)[:, 1]\n",
    "\n",
    "# Calculate the metrics\n",
    "bbbp_lasso_metrics = {\n",
    "    \"Accuracy\": accuracy_score(bbbp_y_ensemble_test, bbbp_lasso_pred),\n",
    "    \"F1 Score\": f1_score(bbbp_y_ensemble_test, bbbp_lasso_pred),\n",
    "    \"ROC-AUC\": roc_auc_score(bbbp_y_ensemble_test, bbbp_lasso_probs),\n",
    "    \"PR-AUC\": average_precision_score(bbbp_y_ensemble_test, bbbp_lasso_probs)\n",
    "}\n",
    "\n",
    "bbbp_lasso_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features: ['chemberta2', 'molformer', 'molbert', 'chemberta2_feature_19', 'chemberta2_feature_44', 'chemberta2_feature_99', 'chemberta2_feature_106', 'chemberta2_feature_113', 'chemberta2_feature_136', 'chemberta2_feature_171', 'chemberta2_feature_289', 'chemberta2_feature_364', 'molformer_feature_17', 'molformer_feature_24', 'molformer_feature_33', 'molformer_feature_68', 'molformer_feature_212', 'molformer_feature_215', 'molformer_feature_218', 'molformer_feature_246', 'molformer_feature_258', 'molformer_feature_303', 'molformer_feature_304', 'molformer_feature_361', 'molformer_feature_363', 'molformer_feature_375', 'molformer_feature_515', 'molformer_feature_520', 'molformer_feature_581', 'molformer_feature_599', 'molformer_feature_635', 'molformer_feature_641', 'molformer_feature_702', 'molformer_feature_717', 'molformer_feature_740', 'molformer_feature_747', 'molbert_features_5', 'molbert_features_39', 'molbert_features_122', 'molbert_features_166', 'molbert_features_188', 'molbert_features_198', 'molbert_features_289', 'molbert_features_298', 'molbert_features_302', 'molbert_features_317', 'molbert_features_326', 'molbert_features_330', 'molbert_features_353', 'molbert_features_422', 'molbert_features_437', 'molbert_features_489', 'molbert_features_569', 'molbert_features_593', 'molbert_features_621', 'molbert_features_643', 'molbert_features_652', 'molbert_features_693', 'molbert_features_699']\n",
      "59\n"
     ]
    }
   ],
   "source": [
    "coefs = pd.Series(lasso_cv.coef_[0], index=bbbp_X_ensemble_valid2.columns)\n",
    "\n",
    "# Filter to get the selected features\n",
    "selected_features = coefs[coefs != 0].index.tolist()\n",
    "\n",
    "# Check if 'chemberta2', 'molformer', 'molbert' are in the selected features, if not, add them\n",
    "for model in ['chemberta2', 'molformer', 'molbert']:\n",
    "    if model not in selected_features:\n",
    "        selected_features.append(model)\n",
    "\n",
    "print(\"Selected Features:\", selected_features)\n",
    "# check how many features are selected\n",
    "print(len(selected_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.3333333333333333, 'l1_ratio': 0.5}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.9019607843137255,\n",
       " 'F1 Score': 0.9358974358974359,\n",
       " 'ROC-AUC': 0.9620253164556962,\n",
       " 'PR-AUC': 0.9901440512499865}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, average_precision_score\n",
    "\n",
    "# Define the model with elasticnet penalty\n",
    "elastic_net_model = LogisticRegression(penalty='elasticnet', solver='saga', max_iter=5000, random_state=0)\n",
    "\n",
    "# Use fewer discrete values for alpha and l1_ratio\n",
    "alphas = [0.01, 0.1, 1, 3]  # Reduced number of points focusing on lower and mid-range\n",
    "l1_ratios = [0.1, 0.5, 0.9]  # Reduced to three points, emphasizing edges and midpoint\n",
    "\n",
    "# Convert alphas to Cs for the parameter grid (since C is the inverse of alpha)\n",
    "Cs = [1/alpha for alpha in alphas]\n",
    "\n",
    "# Create a more concise grid search using 5-fold cross-validation\n",
    "params = {\n",
    "    'C': Cs,\n",
    "    'l1_ratio': l1_ratios\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(elastic_net_model, param_grid=params, cv=5, scoring='roc_auc')\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(bbbp_X_ensemble_valid2_scaled, bbbp_y_ensemble_valid2)\n",
    "\n",
    "# Best model after grid search\n",
    "bbbp_best_elastic_model = grid_search.best_estimator_\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# Predict the test set\n",
    "bbbp_elastic_pred = bbbp_best_elastic_model.predict(bbbp_X_ensemble_test_scaled)\n",
    "bbbp_elastic_probs = bbbp_best_elastic_model.predict_proba(bbbp_X_ensemble_test_scaled)[:, 1]\n",
    "\n",
    "# Calculate the metrics\n",
    "bbbp_elastic_metrics = {\n",
    "    \"Accuracy\": accuracy_score(bbbp_y_ensemble_test, bbbp_elastic_pred),\n",
    "    \"F1 Score\": f1_score(bbbp_y_ensemble_test, bbbp_elastic_pred),\n",
    "    \"ROC-AUC\": roc_auc_score(bbbp_y_ensemble_test, bbbp_elastic_probs),\n",
    "    \"PR-AUC\": average_precision_score(bbbp_y_ensemble_test, bbbp_elastic_probs)\n",
    "}\n",
    "\n",
    "bbbp_elastic_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features: ['chemberta2', 'molformer', 'molbert', 'chemberta2_feature_19', 'chemberta2_feature_33', 'chemberta2_feature_44', 'chemberta2_feature_73', 'chemberta2_feature_91', 'chemberta2_feature_99', 'chemberta2_feature_106', 'chemberta2_feature_113', 'chemberta2_feature_136', 'chemberta2_feature_157', 'chemberta2_feature_160', 'chemberta2_feature_171', 'chemberta2_feature_173', 'chemberta2_feature_178', 'chemberta2_feature_218', 'chemberta2_feature_243', 'chemberta2_feature_252', 'chemberta2_feature_253', 'chemberta2_feature_256', 'chemberta2_feature_267', 'chemberta2_feature_289', 'chemberta2_feature_307', 'chemberta2_feature_313', 'chemberta2_feature_320', 'chemberta2_feature_353', 'chemberta2_feature_357', 'chemberta2_feature_364', 'chemberta2_feature_379', 'molformer_feature_17', 'molformer_feature_24', 'molformer_feature_32', 'molformer_feature_33', 'molformer_feature_52', 'molformer_feature_68', 'molformer_feature_74', 'molformer_feature_95', 'molformer_feature_100', 'molformer_feature_110', 'molformer_feature_120', 'molformer_feature_131', 'molformer_feature_167', 'molformer_feature_174', 'molformer_feature_181', 'molformer_feature_202', 'molformer_feature_212', 'molformer_feature_215', 'molformer_feature_218', 'molformer_feature_229', 'molformer_feature_246', 'molformer_feature_258', 'molformer_feature_269', 'molformer_feature_275', 'molformer_feature_279', 'molformer_feature_280', 'molformer_feature_283', 'molformer_feature_286', 'molformer_feature_303', 'molformer_feature_304', 'molformer_feature_306', 'molformer_feature_312', 'molformer_feature_317', 'molformer_feature_331', 'molformer_feature_340', 'molformer_feature_361', 'molformer_feature_362', 'molformer_feature_363', 'molformer_feature_375', 'molformer_feature_413', 'molformer_feature_429', 'molformer_feature_440', 'molformer_feature_445', 'molformer_feature_446', 'molformer_feature_453', 'molformer_feature_466', 'molformer_feature_479', 'molformer_feature_482', 'molformer_feature_487', 'molformer_feature_512', 'molformer_feature_515', 'molformer_feature_516', 'molformer_feature_520', 'molformer_feature_530', 'molformer_feature_561', 'molformer_feature_570', 'molformer_feature_574', 'molformer_feature_581', 'molformer_feature_595', 'molformer_feature_599', 'molformer_feature_623', 'molformer_feature_631', 'molformer_feature_635', 'molformer_feature_641', 'molformer_feature_679', 'molformer_feature_684', 'molformer_feature_693', 'molformer_feature_702', 'molformer_feature_717', 'molformer_feature_733', 'molformer_feature_740', 'molformer_feature_747', 'molformer_feature_760', 'molbert_features_5', 'molbert_features_35', 'molbert_features_39', 'molbert_features_43', 'molbert_features_53', 'molbert_features_76', 'molbert_features_81', 'molbert_features_89', 'molbert_features_122', 'molbert_features_126', 'molbert_features_131', 'molbert_features_157', 'molbert_features_164', 'molbert_features_166', 'molbert_features_174', 'molbert_features_179', 'molbert_features_188', 'molbert_features_198', 'molbert_features_218', 'molbert_features_232', 'molbert_features_243', 'molbert_features_261', 'molbert_features_269', 'molbert_features_275', 'molbert_features_277', 'molbert_features_283', 'molbert_features_289', 'molbert_features_290', 'molbert_features_298', 'molbert_features_299', 'molbert_features_302', 'molbert_features_311', 'molbert_features_317', 'molbert_features_318', 'molbert_features_319', 'molbert_features_321', 'molbert_features_326', 'molbert_features_330', 'molbert_features_341', 'molbert_features_353', 'molbert_features_358', 'molbert_features_371', 'molbert_features_373', 'molbert_features_381', 'molbert_features_386', 'molbert_features_422', 'molbert_features_428', 'molbert_features_437', 'molbert_features_456', 'molbert_features_467', 'molbert_features_476', 'molbert_features_489', 'molbert_features_496', 'molbert_features_540', 'molbert_features_543', 'molbert_features_569', 'molbert_features_575', 'molbert_features_593', 'molbert_features_617', 'molbert_features_620', 'molbert_features_621', 'molbert_features_628', 'molbert_features_643', 'molbert_features_649', 'molbert_features_652', 'molbert_features_660', 'molbert_features_674', 'molbert_features_693', 'molbert_features_699', 'molbert_features_755', 'molbert_features_768']\n",
      "175\n"
     ]
    }
   ],
   "source": [
    "# Access the coefficients from elastic net\n",
    "coefs = pd.Series(bbbp_best_elastic_model.coef_[0], index=bbbp_X_ensemble_valid2.columns)\n",
    "\n",
    "# Filter to get the selected features\n",
    "selected_features = coefs[coefs != 0].index.tolist()\n",
    "\n",
    "# Check if 'chemberta2', 'molformer', 'molbert' are in the selected features, if not, add them\n",
    "for model in ['chemberta2', 'molformer', 'molbert']:\n",
    "    if model not in selected_features:\n",
    "        selected_features.append(model)\n",
    "\n",
    "print(\"Selected Features:\", selected_features)\n",
    "print(len(selected_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features: ['chemberta2', 'molformer', 'molbert', 'chemberta2_feature_19', 'chemberta2_feature_44', 'chemberta2_feature_99', 'chemberta2_feature_106', 'chemberta2_feature_113', 'chemberta2_feature_136', 'chemberta2_feature_171', 'chemberta2_feature_289', 'chemberta2_feature_364', 'molformer_feature_17', 'molformer_feature_24', 'molformer_feature_33', 'molformer_feature_68', 'molformer_feature_212', 'molformer_feature_215', 'molformer_feature_218', 'molformer_feature_246', 'molformer_feature_258', 'molformer_feature_303', 'molformer_feature_304', 'molformer_feature_361', 'molformer_feature_363', 'molformer_feature_375', 'molformer_feature_515', 'molformer_feature_520', 'molformer_feature_581', 'molformer_feature_599', 'molformer_feature_635', 'molformer_feature_641', 'molformer_feature_702', 'molformer_feature_717', 'molformer_feature_740', 'molformer_feature_747', 'molbert_features_5', 'molbert_features_39', 'molbert_features_122', 'molbert_features_166', 'molbert_features_188', 'molbert_features_198', 'molbert_features_289', 'molbert_features_298', 'molbert_features_302', 'molbert_features_317', 'molbert_features_326', 'molbert_features_330', 'molbert_features_353', 'molbert_features_422', 'molbert_features_437', 'molbert_features_489', 'molbert_features_569', 'molbert_features_593', 'molbert_features_621', 'molbert_features_643', 'molbert_features_652', 'molbert_features_693', 'molbert_features_699']\n",
      "Filtered Dataset Shape: (400, 59)\n"
     ]
    }
   ],
   "source": [
    "# Access the coefficients from lasso\n",
    "coefs = pd.Series(lasso_cv.coef_[0], index=bbbp_X_ensemble_valid2.columns)\n",
    "\n",
    "# Filter to get the selected features\n",
    "selected_features = coefs[coefs != 0].index.tolist()\n",
    "\n",
    "# Check if 'chemberta2', 'molformer', 'molbert' are in the selected features, if not, add them\n",
    "for model in ['chemberta2', 'molformer', 'molbert']:\n",
    "    if model not in selected_features:\n",
    "        selected_features.append(model)\n",
    "\n",
    "# Filter the original DataFrame to keep only selected features\n",
    "bbbp_X_ensemble_valid2_selected = bbbp_X_ensemble_valid2_scaled[selected_features]\n",
    "bbbp_X_ensemble_test_selected = bbbp_X_ensemble_test_scaled[selected_features]\n",
    "\n",
    "print(\"Selected Features:\", selected_features)\n",
    "print(\"Filtered Dataset Shape:\", bbbp_X_ensemble_valid2_selected.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Access the coefficients from elastic net\n",
    "# coefs = pd.Series(bbbp_best_elastic_model.coef_[0], index=bbbp_X_ensemble_valid2.columns)\n",
    "\n",
    "# # Filter to get the selected features\n",
    "# selected_features = coefs[coefs != 0].index.tolist()\n",
    "\n",
    "# # Check if 'chemberta2', 'molformer', 'molbert' are in the selected features, if not, add them\n",
    "# for model in ['chemberta2', 'molformer', 'molbert']:\n",
    "#     if model not in selected_features:\n",
    "#         selected_features.append(model)\n",
    "\n",
    "# # Filter the original DataFrame to keep only selected features\n",
    "# bbbp_X_ensemble_valid2_selected = bbbp_X_ensemble_valid2_scaled[selected_features]\n",
    "# bbbp_X_ensemble_test_selected = bbbp_X_ensemble_test_scaled[selected_features]\n",
    "\n",
    "# print(\"Selected Features:\", selected_features)\n",
    "# print(\"Filtered Dataset Shape:\", bbbp_X_ensemble_valid2_selected.shape)\n",
    "\n",
    "# # Now bbbp_X_ensemble_valid2_selected contains only the features selected by LassoCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 59)\n",
      "(204, 59)\n"
     ]
    }
   ],
   "source": [
    "# bbbp_X_ensemble_valid2_selected = bbbp_X_ensemble_valid2\n",
    "# bbbp_X_ensemble_test_selected = bbbp_X_ensemble_test\n",
    "# check shapes\n",
    "print(bbbp_X_ensemble_valid2_selected.shape)\n",
    "print(bbbp_X_ensemble_test_selected.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.9019607843137255,\n",
       " 'F1 Score': 0.9363057324840764,\n",
       " 'ROC-AUC': 0.9609246009906439,\n",
       " 'PR-AUC': 0.9892741705516901}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and train the SVM model\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "bbbp_svm_model = SVC(probability=True)\n",
    "bbbp_svm_model.fit(bbbp_X_ensemble_valid2_selected, bbbp_y_ensemble_valid2)\n",
    "\n",
    "# Predict the test set\n",
    "bbbp_svm_pred = bbbp_svm_model.predict(bbbp_X_ensemble_test_selected)\n",
    "bbbp_svm_probs = bbbp_svm_model.predict_proba(bbbp_X_ensemble_test_selected)\n",
    "\n",
    "# Calculate the metrics\n",
    "bbbp_svm_metrics = {\n",
    "    'Accuracy': accuracy_score(bbbp_y_ensemble_test, bbbp_svm_pred),\n",
    "    'F1 Score': f1_score(bbbp_y_ensemble_test, bbbp_svm_pred),\n",
    "    'ROC-AUC': roc_auc_score(bbbp_y_ensemble_test, bbbp_svm_probs[:, 1]),\n",
    "    \"PR-AUC\": average_precision_score(bbbp_y_ensemble_test, bbbp_svm_probs[:, 1])\n",
    "}\n",
    "\n",
    "bbbp_svm_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.9117647058823529,\n",
       " 'F1 Score': 0.94375,\n",
       " 'ROC-AUC': 0.9720693450742983,\n",
       " 'PR-AUC': 0.9921209230696455}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initailize and use a 5-fold cross-validation to tune the hyperparameters of a random forest model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "bbbp_rf_model = RandomForestClassifier(random_state=0)\n",
    "\n",
    "bbbp_rf_model.fit(bbbp_X_ensemble_valid2_selected, bbbp_y_ensemble_valid2)\n",
    "\n",
    "# Predict the test set\n",
    "bbbp_rf_best_pred = bbbp_rf_model.predict(bbbp_X_ensemble_test_selected)\n",
    "bbbp_rf_best_probs = bbbp_rf_model.predict_proba(bbbp_X_ensemble_test_selected)\n",
    "\n",
    "# Calculate the metrics\n",
    "bbbp_rf_best_metrics = {\n",
    "    \"Accuracy\": accuracy_score(bbbp_y_ensemble_test, bbbp_rf_best_pred),\n",
    "    \"F1 Score\": f1_score(bbbp_y_ensemble_test, bbbp_rf_best_pred),\n",
    "    \"ROC-AUC\": roc_auc_score(bbbp_y_ensemble_test, bbbp_rf_best_probs[:, 1]),\n",
    "    \"PR-AUC\": average_precision_score(bbbp_y_ensemble_test, bbbp_rf_best_probs[:, 1])\n",
    "}\n",
    "\n",
    "bbbp_rf_best_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30/50 [00:09<00:06,  3.02trial/s, best loss: -0.9899469370146677]\n",
      "Best hyperparameters: {'colsample_bytree': 0.7222226852436076, 'learning_rate': 0.19574434291548556, 'max_depth': 4.0, 'n_estimators': 100.0, 'subsample': 0.5980216688037872}\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score, make_scorer\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.early_stop import no_progress_loss\n",
    "\n",
    "# Define the hyperparameter space using continuous distributions\n",
    "bbbp_xgb_hyperopt_space = {\n",
    "    'n_estimators': hp.quniform('n_estimators', 50, 200, 50),\n",
    "    'max_depth': hp.quniform('max_depth', 3, 7, 2),\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.001, 0.3),\n",
    "    'subsample': hp.uniform('subsample', 0.5, 1.0),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1.0)\n",
    "}\n",
    "\n",
    "# Convert float outputs of hp.quniform to int for certain parameters\n",
    "def objective(params):\n",
    "    params['n_estimators'] = int(params['n_estimators'])\n",
    "    params['max_depth'] = int(params['max_depth'])\n",
    "    \n",
    "    model = xgb.XGBClassifier(**params, random_state=0)\n",
    "    \n",
    "    # Cross-validated AUC score as the objective\n",
    "    roc_auc = make_scorer(roc_auc_score, response_method='predict_proba')\n",
    "    score = cross_val_score(model, bbbp_X_ensemble_valid2_selected, bbbp_y_ensemble_valid2, scoring=roc_auc, cv=5)\n",
    "    \n",
    "    # Minimize the negative ROC AUC score\n",
    "    return {'loss': -score.mean(), 'status': STATUS_OK}\n",
    "\n",
    "# Run the Bayesian optimization\n",
    "trials = Trials()\n",
    "bbbp_xgb_best_params = fmin(fn=objective, \n",
    "                          space=bbbp_xgb_hyperopt_space, \n",
    "                          algo=tpe.suggest, \n",
    "                          max_evals=50, \n",
    "                          trials=trials,\n",
    "                          early_stop_fn=no_progress_loss(10))\n",
    "\n",
    "print(\"Best hyperparameters:\", bbbp_xgb_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.8872549019607843,\n",
       " 'F1 Score': 0.926984126984127,\n",
       " 'ROC-AUC': 0.963538800220143,\n",
       " 'PR-AUC': 0.9900559392114979}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert parameters obtained from Hyperopt to the correct data type\n",
    "bbbp_xgb_best_params['n_estimators'] = int(bbbp_xgb_best_params['n_estimators'])\n",
    "bbbp_xgb_best_params['max_depth'] = int(bbbp_xgb_best_params['max_depth'])\n",
    "\n",
    "# Initialize and train the XGBoost model with the best parameters\n",
    "bbbp_xgb_model = xgb.XGBClassifier(**bbbp_xgb_best_params, random_state=0)\n",
    "bbbp_xgb_model.fit(bbbp_X_ensemble_valid2_selected, bbbp_y_ensemble_valid2)\n",
    "\n",
    "# Predict the test set\n",
    "bbbp_xgb_best_pred = bbbp_xgb_model.predict(bbbp_X_ensemble_test_selected)\n",
    "bbbp_xgb_best_probs = bbbp_xgb_model.predict_proba(bbbp_X_ensemble_test_selected)\n",
    "\n",
    "# Calculate the metrics\n",
    "bbbp_xgb_best_metrics = {\n",
    "    \"Accuracy\": accuracy_score(bbbp_y_ensemble_test, bbbp_xgb_best_pred),\n",
    "    \"F1 Score\": f1_score(bbbp_y_ensemble_test, bbbp_xgb_best_pred),\n",
    "    \"ROC-AUC\": roc_auc_score(bbbp_y_ensemble_test, bbbp_xgb_best_probs[:, 1]),\n",
    "    \"PR-AUC\": average_precision_score(bbbp_y_ensemble_test, bbbp_xgb_best_probs[:, 1])\n",
    "}\n",
    "\n",
    "bbbp_xgb_best_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 18/50 [02:45<04:55,  9.22s/trial, best loss: -1.0]              \n",
      "Best hyperparameters: {'dropout_rate': 0.38064365030171243, 'learning_rate': 0.00026436430584798594, 'num_layers': 3.0, 'num_neurons': 136.0}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.early_stop import no_progress_loss\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Define the neural network model\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, num_layers, num_neurons, dropout_rate):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        layers = [nn.Linear(input_size, num_neurons), nn.ReLU(), nn.Dropout(dropout_rate)]\n",
    "        \n",
    "        for _ in range(num_layers - 1):\n",
    "            layers += [nn.Linear(num_neurons, num_neurons), nn.ReLU(), nn.Dropout(dropout_rate)]\n",
    "        \n",
    "        layers += [nn.Linear(num_neurons, 1), nn.Sigmoid()]\n",
    "        \n",
    "        self.layers = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "# Objective function for Bayesian optimization\n",
    "def objective(params):\n",
    "    kf = KFold(n_splits=5)\n",
    "    roc_aucs = []\n",
    "\n",
    "    for train_index, val_index in kf.split(X):\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "        train_dataset = TensorDataset(torch.tensor(X_train.values.astype(np.float32)), \n",
    "                                      torch.tensor(y_train.values.astype(np.float32)).unsqueeze(1))\n",
    "        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "        model = SimpleNN(input_size=X_train.shape[1], num_layers=int(params['num_layers']), \n",
    "                         num_neurons=int(params['num_neurons']), dropout_rate=params['dropout_rate'])\n",
    "        criterion = nn.BCELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=params['learning_rate'])\n",
    "\n",
    "        model.train()\n",
    "        for epoch in range(100):\n",
    "            for inputs, targets in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            X_val_tensor = torch.tensor(X_val.values.astype(np.float32))\n",
    "            y_val_tensor = torch.tensor(y_val.values.astype(np.float32)).unsqueeze(-1)\n",
    "            outputs = model(X_val_tensor)\n",
    "            roc_auc = roc_auc_score(y_val_tensor.numpy(), outputs.numpy())\n",
    "            roc_aucs.append(roc_auc)\n",
    "\n",
    "    avg_roc_auc = np.mean(roc_aucs)\n",
    "    return {'loss': -avg_roc_auc, 'status': STATUS_OK}  # Maximize ROC AUC by minimizing the negative ROC AUC\n",
    "\n",
    "# Hyperparameter space\n",
    "space = {\n",
    "    'num_layers': hp.quniform('num_layers', 1, 5, 1),\n",
    "    'num_neurons': hp.quniform('num_neurons', 16, 256, 1),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.0001), np.log(0.01)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.0, 0.5)\n",
    "}\n",
    "\n",
    "X = bbbp_X_ensemble_valid2_selected\n",
    "y = bbbp_y_ensemble_valid2\n",
    "\n",
    "# Run Bayesian optimization\n",
    "trials = Trials()\n",
    "bbbp_nn_best_params = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=50,\n",
    "            trials=trials,\n",
    "            early_stop_fn=no_progress_loss(10))\n",
    "\n",
    "print(\"Best hyperparameters:\", bbbp_nn_best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.9117647058823529,\n",
       " 'F1 Score': 0.9419354838709677,\n",
       " 'ROC-AUC': 0.9528068244358834,\n",
       " 'PR-AUC': 0.9871658740546747}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Define the neural network model again\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, num_layers, num_neurons, dropout_rate):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        layers = [nn.Linear(input_size, num_neurons), nn.ReLU(), nn.Dropout(dropout_rate)]\n",
    "        \n",
    "        for _ in range(num_layers - 1):\n",
    "            layers += [nn.Linear(num_neurons, num_neurons), nn.ReLU(), nn.Dropout(dropout_rate)]\n",
    "        \n",
    "        layers += [nn.Linear(num_neurons, 1), nn.Sigmoid()]\n",
    "        \n",
    "        self.layers = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "# Convert parameters to the correct format if necessary\n",
    "bbbp_nn_best_params = {\n",
    "    'num_layers': int(bbbp_nn_best_params['num_layers']),  # Extracted from Bayesian optimization results\n",
    "    'num_neurons': int(bbbp_nn_best_params['num_neurons']),  # Extracted from Bayesian optimization results\n",
    "    'dropout_rate': bbbp_nn_best_params['dropout_rate'],  # Extracted from Bayesian optimization results\n",
    "    'learning_rate': bbbp_nn_best_params['learning_rate']  # Extracted from Bayesian optimization results\n",
    "}\n",
    "\n",
    "# Prepare datasets\n",
    "X_train_tensor = torch.tensor(bbbp_X_ensemble_valid2_selected.values.astype(np.float32))\n",
    "y_train_tensor = torch.tensor(bbbp_y_ensemble_valid2.values.astype(np.float32)).unsqueeze(1)\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "X_test_tensor = torch.tensor(bbbp_X_ensemble_test_selected.values.astype(np.float32))\n",
    "y_test_tensor = torch.tensor(bbbp_y_ensemble_test.values.astype(np.float32)).unsqueeze(1)\n",
    "\n",
    "# Initialize the model\n",
    "model = SimpleNN(input_size=bbbp_X_ensemble_valid2_selected.shape[1], num_layers=bbbp_nn_best_params['num_layers'], \n",
    "                 num_neurons=bbbp_nn_best_params['num_neurons'], dropout_rate=bbbp_nn_best_params['dropout_rate'])\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=bbbp_nn_best_params['learning_rate'])\n",
    "\n",
    "# Training loop\n",
    "model.train()\n",
    "for epoch in range(100):  # Number of epochs can be adjusted\n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Evaluation on test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_test_tensor)\n",
    "    predictions = (outputs > 0.5).float()\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test_tensor.numpy(), predictions.numpy())\n",
    "    f1 = f1_score(y_test_tensor.numpy(), predictions.numpy())\n",
    "    roc_auc = roc_auc_score(y_test_tensor.numpy(), outputs.numpy())\n",
    "    pr_auc = average_precision_score(y_test_tensor.numpy(), outputs.numpy())\n",
    "\n",
    "    bbbp_nn_metrics = {\n",
    "        'Accuracy': accuracy,\n",
    "        'F1 Score': f1,\n",
    "        'ROC-AUC': roc_auc,\n",
    "        'PR-AUC': pr_auc\n",
    "    }\n",
    "\n",
    "bbbp_nn_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report all the metrics for ct\n",
    "bbbp_metrics_results[\"Elastic Net\"] = bbbp_elastic_metrics\n",
    "bbbp_metrics_results[\"LASSO\"] = bbbp_lasso_metrics\n",
    "# bbbp_metrics_results[\"Ridge\"] = bbbp_ridge_metrics\n",
    "bbbp_metrics_results[\"SVM\"] = bbbp_svm_metrics\n",
    "bbbp_metrics_results[\"Random Forest\"] = bbbp_rf_best_metrics\n",
    "bbbp_metrics_results[\"XGBoost\"] = bbbp_xgb_best_metrics\n",
    "bbbp_metrics_results[\"Neural Network\"] = bbbp_nn_metrics\n",
    "\n",
    "bbbp_metrics_df = pd.DataFrame(bbbp_metrics_results).T\n",
    "\n",
    "# keep 3 digits after the decimal point\n",
    "bbbp_metrics_df = bbbp_metrics_df.round(3)\n",
    "\n",
    "# export as csv\n",
    "bbbp_metrics_df.to_csv('./split2_bbbp_metrics_lassoFeatures.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.9_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
