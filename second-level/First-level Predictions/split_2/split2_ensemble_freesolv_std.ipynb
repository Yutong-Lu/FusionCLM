{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, precision_recall_curve, average_precision_score, mean_squared_error, r2_score, mean_absolute_error\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# preds\n",
    "\n",
    "# Load the training set of meta-model\n",
    "freesolv_chemberta2_valid2 = pd.read_csv('./chemberta2/results/freesolv/chemberta2_valid2_freesolv_2_predictions.csv')\n",
    "freesolv_molformer_valid2 = pd.read_csv('./molformer/results/freesolv/molformer_valid2_freesolv_2_99.csv')\n",
    "freesolv_molbert_valid2 = pd.read_csv('./molbert/results/freesolv/molbert_valid2_freesolv_2.csv')\n",
    "\n",
    "# Load the test data for each model\n",
    "freesolv_chemberta2_test = pd.read_csv('./chemberta2/results/freesolv/chemberta2_test_freesolv_2_predictions.csv')\n",
    "freesolv_molformer_test = pd.read_csv('./molformer/results/freesolv/molformer_test_freesolv_2_99.csv')\n",
    "freesolv_molbert_test = pd.read_csv('./molbert/results/freesolv/molbert_test_freesolv_2.csv')\n",
    "\n",
    "train_mean = -3.9326753246753245\n",
    "train_sd = 3.9386618472414696\n",
    "\n",
    "# features\n",
    "\n",
    "# Load the features from chemberta\n",
    "freesolv_chemberta2_features_valid2 = pd.read_csv('./chemberta2/features/freesolv/chemberta2_valid2_freesolv_2_features.csv')\n",
    "freesolv_chemberta2_features_test = pd.read_csv('./chemberta2/features/freesolv/chemberta2_test_freesolv_2_features.csv')\n",
    "\n",
    "# Load the features from molformer\n",
    "freesolv_molformer_features_valid2 = pd.read_csv('./molformer/features/freesolv/molformer_valid2_freesolv_2_features.csv')\n",
    "freesolv_molformer_features_test = pd.read_csv('./molformer/features/freesolv/molformer_test_freesolv_2_features.csv')\n",
    "\n",
    "# Load the features from molbert\n",
    "freesolv_molbert_features_valid2 = pd.read_csv('./molbert/features/freesolv/molbert_valid2_freesolv_2_features.csv')\n",
    "freesolv_molbert_features_test = pd.read_csv('./molbert/features/freesolv/molbert_test_freesolv_2_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For freesolv (regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the actual and predicted values\n",
    "# Chemberta2\n",
    "freesolv_chemberta_actual = freesolv_chemberta2_test['target'] \n",
    "freesolv_chemberta_pred = freesolv_chemberta2_test['pred_raw']\n",
    "\n",
    "# Molformer\n",
    "freesolv_molformer_actual = freesolv_molformer_test['target']\n",
    "freesolv_molformer_pred = freesolv_molformer_test['pred_raw']\n",
    "\n",
    "# molbert\n",
    "freesolv_molbert_actual = freesolv_molbert_test['target_raw']\n",
    "freesolv_molbert_pred = freesolv_molbert_test['pred_raw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Chemberta2': {'MAE': 0.8000800537213537,\n",
       "  'RMSE': 1.2734474000180689,\n",
       "  'R2 Score': 0.8797259973876177,\n",
       "  'Correlation': 0.9453058246807778},\n",
       " 'Molformer': {'MAE': 0.7382831341538462,\n",
       "  'RMSE': 1.3460187487220627,\n",
       "  'R2 Score': 0.8656270163381711,\n",
       "  'Correlation': 0.9314852770560673},\n",
       " 'Molbert': {'MAE': 0.854951475116923,\n",
       "  'RMSE': 1.3825074018587171,\n",
       "  'R2 Score': 0.8582429482003655,\n",
       "  'Correlation': 0.9297793139573085}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating metrics\n",
    "freesolv_metrics_results = {}\n",
    "\n",
    "for model_name, actual, pred in [(\"Chemberta2\", freesolv_chemberta_actual, freesolv_chemberta_pred),\n",
    "                                 (\"Molformer\", freesolv_molformer_actual, freesolv_molformer_pred),\n",
    "                                 (\"Molbert\", freesolv_molbert_actual, freesolv_molbert_pred)]:\n",
    "    freesolv_metrics_results[model_name] = {\n",
    "        \"MAE\": mean_absolute_error(actual, pred),\n",
    "        \"RMSE\": np.sqrt(mean_squared_error(actual, pred)),\n",
    "        \"R2 Score\": r2_score(actual, pred),\n",
    "        \"Correlation\": pearsonr(actual, pred)[0]  # Only record the correlation coefficient\n",
    "    }\n",
    "\n",
    "freesolv_metrics_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardized valid2 labels\n",
    "freesolv_y_ensemble_valid2 = (freesolv_chemberta2_valid2['target'] - train_mean)/train_sd\n",
    "\n",
    "# Create the features for the ensemble from the prediction probabilities of being in class 1\n",
    "freesolv_X_ensemble_valid2 = pd.concat([\n",
    "    freesolv_chemberta2_valid2['pred_z'],\n",
    "    freesolv_molformer_valid2['pred_z'], \n",
    "    freesolv_molbert_valid2['pred_z'],\n",
    "    # add features from training set\n",
    "    freesolv_chemberta2_features_valid2.iloc[:, 2:],\n",
    "    freesolv_molformer_features_valid2.iloc[:, 1:],\n",
    "    freesolv_molbert_features_valid2.iloc[:, 1:]\n",
    "], axis=1)\n",
    "\n",
    "# change feature names of the ensemble so that they are unique\n",
    "freesolv_X_ensemble_valid2.columns = ['chemberta', 'molformer', 'molbert'] + list(freesolv_chemberta2_features_valid2.columns[2:]) + list(freesolv_molformer_features_valid2.columns[1:]) + list(freesolv_molbert_features_valid2.columns[1:])\n",
    "\n",
    "# standardized test labels\n",
    "freesolv_y_ensemble_test_std = (freesolv_chemberta2_test['target']  - train_mean)/train_sd\n",
    "\n",
    "freesolv_X_ensemble_test = pd.concat([\n",
    "    freesolv_chemberta2_test['pred_z'],\n",
    "    freesolv_molformer_test['pred_z'],  \n",
    "    freesolv_molbert_test['pred_z'],\n",
    "    # add features from test set\n",
    "    freesolv_chemberta2_features_test.iloc[:, 2:],\n",
    "    freesolv_molformer_features_test.iloc[:, 1:],\n",
    "    freesolv_molbert_features_test.iloc[:, 1:]\n",
    "], axis=1)\n",
    "\n",
    "# change feature names of the ensemble so that they are unique\n",
    "freesolv_X_ensemble_test.columns = ['chemberta', 'molformer', 'molbert'] + list(freesolv_chemberta2_features_test.columns[2:]) + list(freesolv_molformer_features_test.columns[1:]) + list(freesolv_molbert_features_test.columns[1:])\n",
    "\n",
    "# true test labels\n",
    "freesolv_y_ensemble_test = freesolv_chemberta2_test['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "freesolv_X_ensemble_valid2_scaled = scaler.fit_transform(freesolv_X_ensemble_valid2)\n",
    "freesolv_X_ensemble_test_scaled = scaler.transform(freesolv_X_ensemble_test)\n",
    "\n",
    "freesolv_X_ensemble_valid2_scaled = pd.DataFrame(freesolv_X_ensemble_valid2_scaled, columns=freesolv_X_ensemble_valid2.columns)\n",
    "freesolv_X_ensemble_test_scaled = pd.DataFrame(freesolv_X_ensemble_test_scaled, columns=freesolv_X_ensemble_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export freesolv_X_ensemble_valid2 and freesolv_y_ensemble_valid2 to csv\n",
    "freesolv_X_ensemble_valid2_scaled.to_csv('./processed_data/freesolv_X_ensemble_valid2_scaled_rawpreds.csv', index=False)\n",
    "freesolv_X_ensemble_test_scaled.to_csv('./processed_data/freesolv_X_ensemble_test_scaled_rawpreds.csv', index=False)\n",
    "\n",
    "# export freesolv_X_ensemble_test and freesolv_y_ensemble_test to csv\n",
    "freesolv_y_ensemble_valid2.to_csv('./processed_data/freesolv_y_ensemble_valid2.csv', index=False)\n",
    "freesolv_y_ensemble_test.to_csv('./processed_data/freesolv_y_ensemble_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MAE': 0.6947811987679593,\n",
       " 'RMSE': 1.168512854086777,\n",
       " 'R2 Score': 0.898730951293949,\n",
       " 'Correlation': 0.9480980838733333}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lasso model\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Initialize the LassoCV model\n",
    "lasso_cv = LassoCV(cv=5, max_iter = 5000, random_state=0)\n",
    "\n",
    "# Fit the model\n",
    "lasso_cv.fit(freesolv_X_ensemble_valid2_scaled, freesolv_y_ensemble_valid2)\n",
    "\n",
    "# Predict the test set\n",
    "freesolv_lasso_pred = lasso_cv.predict(freesolv_X_ensemble_test_scaled) * train_sd + train_mean\n",
    "\n",
    "# Calculate the metrics\n",
    "freesolv_lasso_metrics = {\n",
    "    \"MAE\": mean_absolute_error(freesolv_y_ensemble_test, freesolv_lasso_pred),\n",
    "    \"RMSE\": np.sqrt(mean_squared_error(freesolv_y_ensemble_test, freesolv_lasso_pred)),\n",
    "    \"R2 Score\": r2_score(freesolv_y_ensemble_test, freesolv_lasso_pred),\n",
    "    \"Correlation\": pearsonr(freesolv_y_ensemble_test, freesolv_lasso_pred)[0]\n",
    "}\n",
    "\n",
    "freesolv_lasso_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features: ['chemberta', 'molformer', 'molbert', 'chemberta2_feature_87', 'chemberta2_feature_92', 'chemberta2_feature_179', 'molformer_feature_499', 'molformer_feature_633', 'molformer_feature_655', 'molformer_feature_694', 'molformer_feature_734', 'molbert_features_18', 'molbert_features_58', 'molbert_features_87', 'molbert_features_93', 'molbert_features_147', 'molbert_features_173', 'molbert_features_267', 'molbert_features_268', 'molbert_features_288', 'molbert_features_581', 'molbert_features_642', 'molbert_features_689', 'molbert_features_740']\n"
     ]
    }
   ],
   "source": [
    "# use lasso to select features\n",
    "coefs = pd.Series(lasso_cv.coef_, index=freesolv_X_ensemble_valid2.columns)\n",
    "\n",
    "selected_features = coefs[coefs != 0].index.tolist()\n",
    "\n",
    "print(\"Selected Features:\", selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha: 1e-10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'MAE': 3.8547403050141966,\n",
       " 'RMSE': 13.52597442727167,\n",
       " 'R2 Score': -12.568969492431195,\n",
       " 'Correlation': 0.5208269199264985}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from skglm import GroupLasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# two groups: one for the prediction probabilities and one for the features\n",
    "\n",
    "# Define the groups for each feature\n",
    "n_features = freesolv_X_ensemble_valid2_scaled.shape[1]\n",
    "\n",
    "groups = [\n",
    "    list(range(0, 3)),  # Group 0 with feature indices 0, 1, 2\n",
    "    list(range(3, n_features))  # Group 1 with all remaining features\n",
    "]\n",
    "\n",
    "# Initialize the GroupLasso model\n",
    "group_lasso_model = GroupLasso(\n",
    "    groups=groups,\n",
    "    alpha=1e-10,\n",
    "    p0=10,\n",
    "    verbose=0,\n",
    "    tol=0.0001,\n",
    "    positive=False,\n",
    "    fit_intercept=True,\n",
    "    warm_start=False,\n",
    ")\n",
    "\n",
    "# # Fit the model\n",
    "# group_lasso_model.fit(freesolv_X_ensemble_valid2_scaled, freesolv_y_ensemble_valid2)\n",
    "\n",
    "# # Predict the test set\n",
    "# freesolv_pred = group_lasso_model.predict(freesolv_X_ensemble_test_scaled) * train_sd + train_mean\n",
    "\n",
    "# Setup cross-validation to find the best alpha\n",
    "param_grid = {'alpha': np.logspace(-10, 1, 5)}\n",
    "\n",
    "cv = GridSearchCV(\n",
    "    estimator=group_lasso_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV\n",
    "cv.fit(freesolv_X_ensemble_valid2_scaled, freesolv_y_ensemble_valid2)\n",
    "\n",
    "# Best model and parameters\n",
    "best_model = cv.best_estimator_\n",
    "print(\"Best alpha:\", cv.best_params_['alpha'])\n",
    "\n",
    "# Predict using the best model\n",
    "freesolv_pred = best_model.predict(freesolv_X_ensemble_test_scaled) * train_sd + train_mean\n",
    "\n",
    "# Calculate the evaluation metrics\n",
    "freesolv_two_groups_lasso_best_metrics = {\n",
    "    \"MAE\": mean_absolute_error(freesolv_y_ensemble_test, freesolv_pred),\n",
    "    \"RMSE\": np.sqrt(mean_squared_error(freesolv_y_ensemble_test, freesolv_pred)),\n",
    "    \"R2 Score\": r2_score(freesolv_y_ensemble_test, freesolv_pred),\n",
    "    \"Correlation\": pearsonr(freesolv_y_ensemble_test, freesolv_pred)[0]  # Only record the correlation coefficient\n",
    "}\n",
    "\n",
    "# Print the calculated metrics\n",
    "freesolv_two_groups_lasso_best_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.28</td>\n",
       "      <td>-2.541142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.99</td>\n",
       "      <td>-2.456767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-4.84</td>\n",
       "      <td>-4.727217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-6.44</td>\n",
       "      <td>-7.297855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.88</td>\n",
       "      <td>-5.721687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>2.30</td>\n",
       "      <td>1.251319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>-0.48</td>\n",
       "      <td>0.045307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0.321837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>-9.28</td>\n",
       "      <td>-5.835861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>-1.29</td>\n",
       "      <td>-0.666730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    true      pred\n",
       "0  -2.28 -2.541142\n",
       "1  -1.99 -2.456767\n",
       "2  -4.84 -4.727217\n",
       "3  -6.44 -7.297855\n",
       "4  -3.88 -5.721687\n",
       "..   ...       ...\n",
       "60  2.30  1.251319\n",
       "61 -0.48  0.045307\n",
       "62  0.18  0.321837\n",
       "63 -9.28 -5.835861\n",
       "64 -1.29 -0.666730\n",
       "\n",
       "[65 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the true and predicted values side by side\n",
    "freesolv_pred_true = pd.DataFrame({\n",
    "    \"true\": freesolv_y_ensemble_test,\n",
    "    \"pred\": freesolv_pred\n",
    "})\n",
    "\n",
    "freesolv_pred_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha: 1e-10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'MAE': 3.634845223370996,\n",
       " 'RMSE': 12.294548734603968,\n",
       " 'R2 Score': -10.210756704784641,\n",
       " 'Correlation': 0.5566933579795108}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# four groups: predictions, features from chemberta, features from molformer, features from molbert\n",
    "\n",
    "# Define the groups for each feature\n",
    "n_features = freesolv_X_ensemble_valid2_scaled.shape[1]\n",
    "groups = [\n",
    "    list(range(0, 3)),  # Group 0 with feature indices 0, 1, 2\n",
    "    list(range(3, 3 + 384)),  # Group 1 with next 384 features\n",
    "    list(range(3 + 384, 3 + 384 + 768)),  # Group 2 with next 768 features\n",
    "    list(range(3 + 384 + 768, n_features))  # Group 3 with all remaining features\n",
    "]\n",
    "\n",
    "# Initialize the GroupLasso model\n",
    "group_lasso_model = GroupLasso(\n",
    "    groups=groups,\n",
    "    alpha=1.0,\n",
    "    p0=10,\n",
    "    verbose=0,\n",
    "    tol=0.0001,\n",
    "    positive=False,\n",
    "    fit_intercept=True,\n",
    "    warm_start=False,\n",
    ")\n",
    "\n",
    "\n",
    "# Setup cross-validation to find the best alpha\n",
    "param_grid = {'alpha': np.logspace(-10, 1, 5)}\n",
    "\n",
    "cv = GridSearchCV(\n",
    "    estimator=group_lasso_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV\n",
    "cv.fit(freesolv_X_ensemble_valid2_scaled, freesolv_y_ensemble_valid2)\n",
    "\n",
    "# Best model and parameters\n",
    "best_model = cv.best_estimator_\n",
    "print(\"Best alpha:\", cv.best_params_['alpha'])\n",
    "\n",
    "# Predict using the best model\n",
    "freesolv_pred = best_model.predict(freesolv_X_ensemble_test_scaled) * train_sd + train_mean\n",
    "\n",
    "# Calculate the evaluation metrics\n",
    "freesolv_four_groups_lasso_best_metrics = {\n",
    "    \"MAE\": mean_absolute_error(freesolv_y_ensemble_test, freesolv_pred),\n",
    "    \"RMSE\": np.sqrt(mean_squared_error(freesolv_y_ensemble_test, freesolv_pred)),\n",
    "    \"R2 Score\": r2_score(freesolv_y_ensemble_test, freesolv_pred),\n",
    "    \"Correlation\": pearsonr(freesolv_y_ensemble_test, freesolv_pred)[0]  # Only record the correlation coefficient\n",
    "}\n",
    "\n",
    "# Print the calculated metrics\n",
    "freesolv_four_groups_lasso_best_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    -2.28\n",
       "1    -1.99\n",
       "2    -4.84\n",
       "3    -6.44\n",
       "4    -3.88\n",
       "      ... \n",
       "60    2.30\n",
       "61   -0.48\n",
       "62    0.18\n",
       "63   -9.28\n",
       "64   -1.29\n",
       "Name: target, Length: 65, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freesolv_y_ensemble_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.28</td>\n",
       "      <td>-2.541980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.99</td>\n",
       "      <td>-2.509169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-4.84</td>\n",
       "      <td>-4.693454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-6.44</td>\n",
       "      <td>-7.343145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.88</td>\n",
       "      <td>-5.700561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>2.30</td>\n",
       "      <td>1.193500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>-0.48</td>\n",
       "      <td>0.039399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0.294528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>-9.28</td>\n",
       "      <td>-5.876054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>-1.29</td>\n",
       "      <td>-0.672147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    target      pred\n",
       "0    -2.28 -2.541980\n",
       "1    -1.99 -2.509169\n",
       "2    -4.84 -4.693454\n",
       "3    -6.44 -7.343145\n",
       "4    -3.88 -5.700561\n",
       "..     ...       ...\n",
       "60    2.30  1.193500\n",
       "61   -0.48  0.039399\n",
       "62    0.18  0.294528\n",
       "63   -9.28 -5.876054\n",
       "64   -1.29 -0.672147\n",
       "\n",
       "[65 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# put the test and pred side by side\n",
    "freesolv_ensemble_results = pd.DataFrame({\n",
    "    \"target\": freesolv_y_ensemble_test,\n",
    "    \"pred\": freesolv_pred\n",
    "})\n",
    "freesolv_ensemble_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.1, 'l1_ratio': 0.5}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'MAE': 0.717930920761282,\n",
       " 'RMSE': 1.1850912637748987,\n",
       " 'R2 Score': 0.8958370346003615,\n",
       " 'Correlation': 0.947207323824447}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# elastic net\n",
    "# Define the model with elasticnet penalty for regression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "elastic_net_model = ElasticNet(random_state=0, max_iter=5000)\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "# Use fewer discrete values for alpha and l1_ratio\n",
    "alphas = [0.01, 0.1, 1, 3]  # Reduced number of points focusing on lower and mid-range\n",
    "l1_ratios = [0.1, 0.5, 0.9]  # Reduced to three points, emphasizing edges and midpoint\n",
    "\n",
    "params = {\n",
    "    'alpha': alphas,  # Convert alpha back to C\n",
    "    'l1_ratio': l1_ratios\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(elastic_net_model, param_grid=params, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(freesolv_X_ensemble_valid2_scaled, freesolv_y_ensemble_valid2)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "freesolv_best_elastic_params = grid_search.best_params_\n",
    "print(freesolv_best_elastic_params)\n",
    "\n",
    "# Initialize and train the best ElasticNet model\n",
    "freesolv_best_elastic_model = ElasticNet(alpha=freesolv_best_elastic_params['alpha'], l1_ratio=freesolv_best_elastic_params['l1_ratio'], random_state=0, max_iter=5000)\n",
    "freesolv_best_elastic_model.fit(freesolv_X_ensemble_valid2_scaled, freesolv_y_ensemble_valid2)\n",
    "\n",
    "# Predict the test set\n",
    "freesolv_elastic_pred = freesolv_best_elastic_model.predict(freesolv_X_ensemble_test_scaled) * train_sd + train_mean\n",
    "\n",
    "# Calculate the metrics\n",
    "freesolv_elastic_metrics = {\n",
    "    \"MAE\": mean_absolute_error(freesolv_y_ensemble_test, freesolv_elastic_pred),\n",
    "    \"RMSE\": np.sqrt(mean_squared_error(freesolv_y_ensemble_test, freesolv_elastic_pred)),\n",
    "    \"R2 Score\": r2_score(freesolv_y_ensemble_test, freesolv_elastic_pred),\n",
    "    \"Correlation\": pearsonr(freesolv_y_ensemble_test, freesolv_elastic_pred)[0]\n",
    "}\n",
    "\n",
    "freesolv_elastic_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features: ['chemberta', 'molformer', 'molbert', 'chemberta2_feature_82', 'chemberta2_feature_87', 'chemberta2_feature_92', 'chemberta2_feature_179', 'chemberta2_feature_183', 'molformer_feature_499', 'molformer_feature_633', 'molformer_feature_655', 'molformer_feature_694', 'molbert_features_18', 'molbert_features_58', 'molbert_features_93', 'molbert_features_147', 'molbert_features_267', 'molbert_features_268', 'molbert_features_288', 'molbert_features_559', 'molbert_features_581', 'molbert_features_642', 'molbert_features_689', 'molbert_features_708']\n"
     ]
    }
   ],
   "source": [
    "# use elastic net to select features\n",
    "coefs = pd.Series(freesolv_best_elastic_model.coef_, index=freesolv_X_ensemble_valid2.columns)\n",
    "\n",
    "selected_features = coefs[coefs != 0].index.tolist()\n",
    "\n",
    "print(\"Selected Features:\", selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(129, 24)\n",
      "(65, 24)\n"
     ]
    }
   ],
   "source": [
    "freesolv_X_ensemble_valid2_selected = freesolv_X_ensemble_valid2_scaled[selected_features]\n",
    "freesolv_X_ensemble_test_selected = freesolv_X_ensemble_test_scaled[selected_features]\n",
    "\n",
    "# check shapes\n",
    "print(freesolv_X_ensemble_valid2_selected.shape)\n",
    "print(freesolv_X_ensemble_test_selected.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MAE': 1.1966621320289677,\n",
       " 'RMSE': 2.1577800359446266,\n",
       " 'R2 Score': 0.6546781305992417,\n",
       " 'Correlation': 0.8102804684953412}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and train the SVR model\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "freesolv_svr_model = SVR()\n",
    "freesolv_svr_model.fit(freesolv_X_ensemble_valid2_selected, freesolv_y_ensemble_valid2)\n",
    "\n",
    "# Predict the test set\n",
    "freesolv_svr_pred = freesolv_svr_model.predict(freesolv_X_ensemble_test_selected) * train_sd + train_mean\n",
    "\n",
    "# Calculate the metrics\n",
    "freesolv_svr_metrics = {\n",
    "    \"MAE\": mean_absolute_error(freesolv_y_ensemble_test, freesolv_svr_pred ),\n",
    "    \"RMSE\": np.sqrt(mean_squared_error(freesolv_y_ensemble_test, freesolv_svr_pred )),\n",
    "    \"R2 Score\": r2_score(freesolv_y_ensemble_test, freesolv_svr_pred ),\n",
    "    \"Correlation\": pearsonr(freesolv_y_ensemble_test, freesolv_svr_pred )[0]  # Only record the correlation coefficient\n",
    "}\n",
    "\n",
    "freesolv_svr_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MAE': 0.8387938461538459,\n",
       " 'RMSE': 1.5149272854852442,\n",
       " 'R2 Score': 0.8297867682221338,\n",
       " 'Correlation': 0.9116677109792434}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initailize and use a 5-fold cross-validation to tune the hyperparameters of a random forest model for regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "freesolv_rf_model = RandomForestRegressor(random_state=0)\n",
    "\n",
    "freesolv_rf_model.fit(freesolv_X_ensemble_valid2_selected, freesolv_y_ensemble_valid2)\n",
    "\n",
    "# Predict the test set\n",
    "freesolv_rf_best_pred = freesolv_rf_model.predict(freesolv_X_ensemble_test_selected) * train_sd + train_mean\n",
    "\n",
    "# Calculate the metrics\n",
    "freesolv_rf_best_metrics = {\n",
    "    \"MAE\": mean_absolute_error(freesolv_y_ensemble_test, freesolv_rf_best_pred),\n",
    "    \"RMSE\": np.sqrt(mean_squared_error(freesolv_y_ensemble_test, freesolv_rf_best_pred)),\n",
    "    \"R2 Score\": r2_score(freesolv_y_ensemble_test, freesolv_rf_best_pred),\n",
    "    \"Correlation\": pearsonr(freesolv_y_ensemble_test, freesolv_rf_best_pred)[0]  # Only record the correlation coefficient\n",
    "}\n",
    "\n",
    "freesolv_rf_best_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 21%|██        | 21/100 [00:03<00:14,  5.32trial/s, best loss: 0.3357787933768178] \n",
      "Best hyperparameters: {'colsample_bytree': 0.5603690896798423, 'learning_rate': 0.17035028068241181, 'max_depth': 4.0, 'n_estimators': 50.0, 'subsample': 0.5818529989625509}\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "import numpy as np\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.early_stop import no_progress_loss\n",
    "\n",
    "# Define the hyperparameter space using continuous distributions\n",
    "freesolv_xgb_hyperopt_space = {\n",
    "    'n_estimators': hp.quniform('n_estimators', 50, 200, 50),\n",
    "    'max_depth': hp.quniform('max_depth', 3, 7, 2),\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.001, 0.3),\n",
    "    'subsample': hp.uniform('subsample', 0.5, 1.0),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1.0)\n",
    "}\n",
    "\n",
    "# Correctly define the RMSE scorer function\n",
    "def rmse_scorer(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# Convert float outputs of hp.quniform to int for certain parameters\n",
    "def objective(params):\n",
    "    params['n_estimators'] = int(params['n_estimators'])\n",
    "    params['max_depth'] = int(params['max_depth'])\n",
    "    model = xgb.XGBRegressor(**params, random_state=0)\n",
    "    \n",
    "    # Cross-validated RMSE as the objective\n",
    "    score = cross_val_score(model, freesolv_X_ensemble_valid2_selected, freesolv_y_ensemble_valid2, \n",
    "                            scoring=make_scorer(rmse_scorer, greater_is_better=False), cv=5)\n",
    "    \n",
    "    # Minimize the positive RMSE (already negative from scoring)\n",
    "    return {'loss': -score.mean(), 'status': STATUS_OK}\n",
    "\n",
    "# Run the Bayesian optimization\n",
    "trials = Trials()\n",
    "freesolv_xgb_best_params = fmin(fn=objective, \n",
    "                            space=freesolv_xgb_hyperopt_space, \n",
    "                            algo=tpe.suggest, \n",
    "                            max_evals=100, \n",
    "                            trials=trials,\n",
    "                            early_stop_fn=no_progress_loss(10))\n",
    "\n",
    "print(\"Best hyperparameters:\", freesolv_xgb_best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MAE': 0.7015726737976075,\n",
       " 'RMSE': 1.0880306336860968,\n",
       " 'R2 Score': 0.9122005109822555,\n",
       " 'Correlation': 0.9562234362621357}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model with the best hyperparameters\n",
    "# Convert parameters obtained from Hyperopt to the correct data type\n",
    "freesolv_xgb_best_params['n_estimators'] = int(freesolv_xgb_best_params['n_estimators'])\n",
    "freesolv_xgb_best_params['max_depth'] = int(freesolv_xgb_best_params['max_depth'])\n",
    "\n",
    "# Initialize and train the XGBoost model with the best parameters\n",
    "freesolv_xgb_model = xgb.XGBRegressor(**freesolv_xgb_best_params, random_state=0)\n",
    "freesolv_xgb_model.fit(freesolv_X_ensemble_valid2_selected, freesolv_y_ensemble_valid2)\n",
    "\n",
    "# Predict the test set\n",
    "freesolv_xgb_best_pred = freesolv_xgb_model.predict(freesolv_X_ensemble_test_selected) * train_sd + train_mean\n",
    "\n",
    "# Calculate the metrics\n",
    "freesolv_xgb_best_metrics = {\n",
    "    \"MAE\": mean_absolute_error(freesolv_y_ensemble_test, freesolv_xgb_best_pred),\n",
    "    \"RMSE\": np.sqrt(mean_squared_error(freesolv_y_ensemble_test, freesolv_xgb_best_pred)),\n",
    "    \"R2 Score\": r2_score(freesolv_y_ensemble_test, freesolv_xgb_best_pred),\n",
    "    \"Correlation\": pearsonr(freesolv_y_ensemble_test, freesolv_xgb_best_pred)[0]  # Only record the correlation coefficient\n",
    "}\n",
    "\n",
    "freesolv_xgb_best_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 13/50 [00:27<01:18,  2.13s/trial, best loss: 0.2447439730167389]\n",
      "Best hyperparameters: {'dropout_rate': 0.32382367245512, 'learning_rate': 0.00039109115900674336, 'num_layers': 2.0, 'num_neurons': 102.0}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.early_stop import no_progress_loss\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Define RMSE loss\n",
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RMSELoss, self).__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        return torch.sqrt(self.mse(y_pred, y_true))\n",
    "\n",
    "# Define the neural network model for regression\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, num_layers, num_neurons, dropout_rate):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        layers = [nn.Linear(input_size, num_neurons), nn.ReLU(), nn.Dropout(dropout_rate)]\n",
    "        \n",
    "        for _ in range(1, num_layers):\n",
    "            layers += [nn.Linear(num_neurons, num_neurons), nn.ReLU(), nn.Dropout(dropout_rate)]\n",
    "        \n",
    "        layers += [nn.Linear(num_neurons, 1)]\n",
    "        \n",
    "        self.layers = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "# Hyperparameter space with hp.quniform for integer distribution\n",
    "space = {\n",
    "    'num_layers': hp.quniform('num_layers', 1, 10, 1),  # Reduced upper limit\n",
    "    'num_neurons': hp.quniform('num_neurons', 8, 256, 1),  # Reduced upper limit and adjusted the lower limit\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.0001), np.log(0.05)),  # Adjusted upper limit\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.1, 0.5)  # Adjusted lower limit to explore higher dropout\n",
    "}\n",
    "\n",
    "# Global dataset variables assumed to be defined externally\n",
    "X = freesolv_X_ensemble_valid2_selected\n",
    "y = freesolv_y_ensemble_valid2\n",
    "\n",
    "# Objective function for Bayesian optimization\n",
    "def objective(params):\n",
    "    params['num_layers'] = int(params['num_layers'])  # Ensure num_layers is an integer\n",
    "    params['num_neurons'] = int(params['num_neurons'])  # Ensure num_neurons is an integer\n",
    "    kf = KFold(n_splits=5)\n",
    "    rmse_scores = []\n",
    "\n",
    "    for train_index, val_index in kf.split(X):\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "        # Convert DataFrame to numpy arrays before making them PyTorch tensors\n",
    "        train_dataset = TensorDataset(torch.tensor(X_train.values.astype(np.float32)), \n",
    "                                      torch.tensor(y_train.values.astype(np.float32)).unsqueeze(1))\n",
    "        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "        model = SimpleNN(input_size=X_train.shape[1], num_layers=params['num_layers'],\n",
    "                         num_neurons=params['num_neurons'], dropout_rate=params['dropout_rate'])\n",
    "        criterion = RMSELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=params['learning_rate'])\n",
    "\n",
    "        model.train()\n",
    "        for epoch in range(100):\n",
    "            for inputs, targets in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_preds = model(torch.tensor(X_val.values.astype(np.float32))).squeeze(1)\n",
    "            val_targets = torch.tensor(y_val.values.astype(np.float32))\n",
    "            rmse = np.sqrt(mean_squared_error(val_targets.numpy(), val_preds.numpy()))\n",
    "            rmse_scores.append(rmse)\n",
    "\n",
    "    avg_rmse = np.mean(rmse_scores)\n",
    "    return {'loss': avg_rmse, 'status': STATUS_OK} # Minimize RMSE\n",
    "\n",
    "# Run Bayesian optimization\n",
    "trials = Trials()\n",
    "freesolv_nn_best_params = fmin(fn=objective,\n",
    "                           space=space,\n",
    "                           algo=tpe.suggest,\n",
    "                           max_evals=50,\n",
    "                           trials=trials,\n",
    "                           early_stop_fn=no_progress_loss(10))\n",
    "\n",
    "print(\"Best hyperparameters:\", freesolv_nn_best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MAE': 0.96470976,\n",
       " 'RMSE': 1.3577014,\n",
       " 'R2 Score': 0.8632842898368835,\n",
       " 'Correlation': 0.9294056366660468}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Define the neural network model again\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, num_layers, num_neurons, dropout_rate):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        layers = [nn.Linear(input_size, num_neurons), nn.ReLU(), nn.Dropout(dropout_rate)]\n",
    "        \n",
    "        for _ in range(1, num_layers):\n",
    "            layers += [nn.Linear(num_neurons, num_neurons), nn.ReLU(), nn.Dropout(dropout_rate)]\n",
    "        \n",
    "        layers += [nn.Linear(num_neurons, 1)]\n",
    "        \n",
    "        self.layers = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "# Define a function to compute RMSE\n",
    "def compute_rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# Convert parameters to the correct format if necessary\n",
    "freesolv_nn_best_params = {\n",
    "    'num_layers':  int(freesolv_nn_best_params['num_layers']),  # Extracted from Bayesian optimization results\n",
    "    'num_neurons':  int(freesolv_nn_best_params['num_neurons']),  # Extracted from Bayesian optimization results\n",
    "    'dropout_rate': freesolv_nn_best_params['dropout_rate'],  # Extracted from Bayesian optimization results\n",
    "    'learning_rate': freesolv_nn_best_params['learning_rate']  # Extracted from Bayesian optimization results\n",
    "}\n",
    "\n",
    "# Prepare datasets\n",
    "X_train_tensor = torch.tensor(freesolv_X_ensemble_valid2_selected.values.astype(np.float32))\n",
    "y_train_tensor = torch.tensor(freesolv_y_ensemble_valid2.values.astype(np.float32)).unsqueeze(1)\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "X_test_tensor = torch.tensor(freesolv_X_ensemble_test_selected.values.astype(np.float32))\n",
    "y_test_tensor = torch.tensor(freesolv_y_ensemble_test.values.astype(np.float32)).unsqueeze(1)\n",
    "\n",
    "# Initialize the model\n",
    "model = SimpleNN(input_size=freesolv_X_ensemble_valid2_selected.shape[1], num_layers=freesolv_nn_best_params['num_layers'],\n",
    "                         num_neurons=freesolv_nn_best_params['num_neurons'], dropout_rate=freesolv_nn_best_params['dropout_rate'])\n",
    "criterion = RMSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=freesolv_nn_best_params['learning_rate'])\n",
    "\n",
    "# Training loop\n",
    "model.train()\n",
    "for epoch in range(100):  # Number of epochs can be adjusted\n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "model.eval()\n",
    "# Evaluation on training set\n",
    "with torch.no_grad():\n",
    "    train_outputs = model(X_train_tensor)\n",
    "    train_predictions = train_outputs.squeeze(1).numpy()\n",
    "\n",
    "    # Calculate metrics\n",
    "    train_mae = mean_absolute_error(y_train_tensor.numpy(), train_predictions)\n",
    "    train_rmse = compute_rmse(y_train_tensor.numpy(), train_predictions)\n",
    "    train_r2 = r2_score(y_train_tensor.numpy(), train_predictions)\n",
    "    train_correlation, _ = pearsonr(y_train_tensor.numpy().squeeze(1), train_predictions)\n",
    "\n",
    "    freesolv_nn_train_metrics = {\n",
    "        'MAE': train_mae,\n",
    "        'RMSE': train_rmse,\n",
    "        'R2 Score': train_r2,\n",
    "        'Correlation': train_correlation\n",
    "    }\n",
    "\n",
    "freesolv_nn_train_metrics\n",
    "\n",
    "# Evaluation on test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_test_tensor)\n",
    "    predictions = outputs.squeeze(1).numpy() * train_sd + train_mean\n",
    "\n",
    "    # Calculate metrics\n",
    "    mae = mean_absolute_error(y_test_tensor.numpy(), predictions)\n",
    "    rmse = compute_rmse(y_test_tensor.numpy(), predictions)\n",
    "    r2 = r2_score(y_test_tensor.numpy(), predictions)\n",
    "    correlation, _ = pearsonr(y_test_tensor.numpy().squeeze(1), predictions)\n",
    "\n",
    "    freesolv_nn_metrics = {\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'R2 Score': r2,\n",
    "        'Correlation': correlation\n",
    "    }\n",
    "\n",
    "freesolv_nn_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.28</td>\n",
       "      <td>-2.736681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.99</td>\n",
       "      <td>-1.447645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-4.84</td>\n",
       "      <td>-3.733321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-6.44</td>\n",
       "      <td>-7.074145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.88</td>\n",
       "      <td>-4.612207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>2.30</td>\n",
       "      <td>1.094055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>-0.48</td>\n",
       "      <td>0.185301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0.660280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>-9.28</td>\n",
       "      <td>-5.762722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>-1.29</td>\n",
       "      <td>-1.267784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    target      pred\n",
       "0    -2.28 -2.736681\n",
       "1    -1.99 -1.447645\n",
       "2    -4.84 -3.733321\n",
       "3    -6.44 -7.074145\n",
       "4    -3.88 -4.612207\n",
       "..     ...       ...\n",
       "60    2.30  1.094055\n",
       "61   -0.48  0.185301\n",
       "62    0.18  0.660280\n",
       "63   -9.28 -5.762722\n",
       "64   -1.29 -1.267784\n",
       "\n",
       "[65 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print pred and target side by side\n",
    "freesolv_nn_results = pd.DataFrame({\n",
    "    \"target\": freesolv_y_ensemble_test,\n",
    "    \"pred\": predictions\n",
    "})\n",
    "freesolv_nn_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a table to record all metrics for freesolv\n",
    "freesolv_metrics_results[\"LASSO\"] = freesolv_lasso_metrics\n",
    "freesolv_metrics_results[\"Group Lasso (2 groups)\"] = freesolv_two_groups_lasso_best_metrics\n",
    "freesolv_metrics_results[\"Group Lasso (4 groups)\"] = freesolv_four_groups_lasso_best_metrics\n",
    "freesolv_metrics_results[\"Elastic Net\"] = freesolv_elastic_metrics\n",
    "freesolv_metrics_results[\"SVR\"] = freesolv_svr_metrics\n",
    "freesolv_metrics_results[\"Random Forest\"] = freesolv_rf_best_metrics\n",
    "freesolv_metrics_results[\"XGBoost\"] = freesolv_xgb_best_metrics\n",
    "freesolv_metrics_results[\"Neural Network\"] = freesolv_nn_metrics\n",
    "\n",
    "freesolv_metrics_df = pd.DataFrame(freesolv_metrics_results).T\n",
    "# keep 3 digits after the decimal point\n",
    "freesolv_metrics_df = freesolv_metrics_df.round(3)\n",
    "\n",
    "# export table to csv\n",
    "freesolv_metrics_df.to_csv('./split2_freesolv_metrics_rawrpreds.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fusion-env",
   "language": "python",
   "name": "fusion-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
