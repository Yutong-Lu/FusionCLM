{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, precision_recall_curve, average_precision_score, mean_squared_error, r2_score, mean_absolute_error\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# preds\n",
    "\n",
    "# Load the training set of meta-model\n",
    "ct_chemberta2_valid2 = pd.read_csv('./chemberta2/results/clintox/chemberta2_valid2_clintox_1_predictions.csv')\n",
    "ct_molformer_valid2 = pd.read_csv('./molformer/results/clintox/molformer_valid2_clintox_1_epoch29.csv')\n",
    "ct_molbert_valid2 = pd.read_csv('./molbert/results/clintox/molbert_valid2_clintox_1.csv')\n",
    "\n",
    "# Load the test data for each model\n",
    "ct_chemberta2_test = pd.read_csv('./chemberta2/results/clintox/chemberta2_test_clintox_1_predictions.csv')\n",
    "ct_molformer_test = pd.read_csv('./molformer/results/clintox/molformer_test_clintox_1_epoch29.csv')\n",
    "ct_molbert_test = pd.read_csv('./molbert/results/clintox/molbert_test_clintox_1.csv')\n",
    "\n",
    "# features\n",
    "\n",
    "# Load the features from chemberta\n",
    "ct_chemberta2_features_valid2 = pd.read_csv('./chemberta2/features/clintox/chemberta2_valid2_clintox_1_features.csv')\n",
    "ct_chemberta2_features_test = pd.read_csv('./chemberta2/features/clintox/chemberta2_test_clintox_1_features.csv')\n",
    "\n",
    "# Load the features from molformer\n",
    "ct_molformer_features_valid2 = pd.read_csv('./molformer/features/clintox/molformer_valid2_clintox_1_features.csv')\n",
    "ct_molformer_features_test = pd.read_csv('./molformer/features/clintox/molformer_test_clintox_1_features.csv')\n",
    "\n",
    "# Load the features from molbert\n",
    "ct_molbert_features_valid2 = pd.read_csv('./molbert/features/clintox/molbert_valid2_clintox_1_features.csv')\n",
    "ct_molbert_features_test = pd.read_csv('./molbert/features/clintox/molbert_test_clintox_1_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Clintox (Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Chemberta2': {'Accuracy': 0.9798657718120806,\n",
       "  'F1 Score': 0.8421052631578947,\n",
       "  'ROC-AUC': 0.9888888888888889,\n",
       "  'PR-AUC': 0.8967813051146385},\n",
       " 'Molformer': {'Accuracy': 0.8993288590604027,\n",
       "  'F1 Score': 0.34782608695652173,\n",
       "  'ROC-AUC': 0.8412698412698414,\n",
       "  'PR-AUC': 0.44689892504271944},\n",
       " 'Molbert': {'Accuracy': 0.9261744966442953,\n",
       "  'F1 Score': 0.35294117647058826,\n",
       "  'ROC-AUC': 0.8801587301587301,\n",
       "  'PR-AUC': 0.40959504857430756}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, average_precision_score\n",
    "\n",
    "# Preparing the actual and predicted values\n",
    "# Chemberta2\n",
    "ct_chemberta_actual = ct_chemberta2_test['CT_TOX']\n",
    "ct_chemberta_pred = ct_chemberta2_test['y_pred']\n",
    "ct_chemberta_probs = ct_chemberta2_test[['softmax_class_0_prob', 'softmax_class_1_prob']]\n",
    "\n",
    "# Molformer\n",
    "ct_molformer_actual = ct_molformer_test['Actual']\n",
    "ct_molformer_pred = (ct_molformer_test['Prob_Class_1'] > 0.5).astype(int)\n",
    "ct_molformer_probs = ct_molformer_test[['Prob_Class_0', 'Prob_Class_1']]\n",
    "\n",
    "# Molbert\n",
    "ct_molbert_actual = ct_molbert_test['target']\n",
    "ct_molbert_pred = ct_molbert_test['pred']\n",
    "ct_molbert_probs = ct_molbert_test['prob']\n",
    "\n",
    "# Calculating metrics\n",
    "ct_metrics_results = {}\n",
    "\n",
    "for model_name, actual, pred, probs in [(\"Chemberta2\", ct_chemberta_actual, ct_chemberta_pred, ct_chemberta_probs['softmax_class_1_prob']),\n",
    "                                         (\"Molformer\", ct_molformer_actual, ct_molformer_pred, ct_molformer_probs['Prob_Class_1']),\n",
    "                                         (\"Molbert\", ct_molbert_actual, ct_molbert_pred, ct_molbert_probs)]:\n",
    "    ct_metrics_results[model_name] = {\n",
    "        \"Accuracy\": accuracy_score(actual, pred),\n",
    "        \"F1 Score\": f1_score(actual, pred),\n",
    "        \"ROC-AUC\": roc_auc_score(actual, probs),\n",
    "        \"PR-AUC\": average_precision_score(actual, probs)\n",
    "    }\n",
    "\n",
    "ct_metrics_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the 'smiles' values in chemberta that are not in molbert\n",
    "missing_smiles = set(ct_chemberta2_valid2['smiles']) - set(ct_molbert_valid2['smiles'])\n",
    "\n",
    "# Find the indices of these missing 'smiles' in the chemberta DataFrame\n",
    "missing_indices = ct_chemberta2_valid2.index[ct_chemberta2_valid2['smiles'].isin(missing_smiles)].tolist()\n",
    "\n",
    "# Drop the rows with these missing indices for chemberta and molformer\n",
    "ct_chemberta2_valid2 = ct_chemberta2_valid2.drop(missing_indices)\n",
    "ct_molformer_valid2 = ct_molformer_valid2.drop(missing_indices)\n",
    "ct_chemberta2_features_valid2 = ct_chemberta2_features_valid2.drop(missing_indices)\n",
    "ct_molformer_features_valid2 = ct_molformer_features_valid2.drop(missing_indices)\n",
    "ct_molbert_features_valid2 = ct_molbert_features_valid2.drop(missing_indices)\n",
    "\n",
    "# do the same for test sets\n",
    "missing_smiles = set(ct_chemberta2_test['smiles']) - set(ct_molbert_test['smiles'])\n",
    "missing_indices = ct_chemberta2_test.index[ct_chemberta2_test['smiles'].isin(missing_smiles)].tolist()\n",
    "\n",
    "ct_chemberta2_test = ct_chemberta2_test.drop(missing_indices)\n",
    "ct_molformer_test = ct_molformer_test.drop(missing_indices)\n",
    "ct_chemberta2_features_test = ct_chemberta2_features_test.drop(missing_indices)\n",
    "ct_molformer_features_test = ct_molformer_features_test.drop(missing_indices)\n",
    "ct_molbert_features_test = ct_molbert_features_test.drop(missing_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(291, 8)\n",
      "(291, 5)\n",
      "(291, 4)\n",
      "(291, 386)\n",
      "(291, 769)\n",
      "(291, 769)\n"
     ]
    }
   ],
   "source": [
    "# check shapes\n",
    "print(ct_chemberta2_valid2.shape)\n",
    "print(ct_molformer_valid2.shape)\n",
    "print(ct_molbert_valid2.shape)\n",
    "print(ct_chemberta2_features_valid2.shape)\n",
    "print(ct_molformer_features_valid2.shape)\n",
    "print(ct_molbert_features_valid2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_chemberta2_valid2.reset_index(drop=True, inplace=True)\n",
    "ct_y_ensemble_valid2 = ct_chemberta2_valid2['CT_TOX']\n",
    "\n",
    "# create a new dataframe with one column of ct_chemberta2_valid2['softmax_class_1_prob']\n",
    "ct_chemberta2_prob = pd.DataFrame({'chemberta2': ct_chemberta2_valid2['softmax_class_1_prob']})\n",
    "ct_chemberta2_prob.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# create a new dataframe with one column of ct_molformer_valid2['Prob_Class_1']\n",
    "ct_molformer_prob = pd.DataFrame({'molformer': ct_molformer_valid2['Prob_Class_1']})\n",
    "ct_molformer_prob.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# create a new dataframe with one column of ct_molbert_valid2['Probabilities']\n",
    "ct_molbert_prob = pd.DataFrame({'molbert': ct_molbert_valid2['prob']})\n",
    "ct_molbert_prob.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# concatenate the three dataframes\n",
    "ct_prob = pd.concat([ct_chemberta2_prob, ct_molformer_prob, ct_molbert_prob], axis=1)\n",
    "\n",
    "# do the same for features ct_chemberta2_features_valid2.iloc[:, 2:]\n",
    "ct_chemberta2_features = pd.DataFrame(ct_chemberta2_features_valid2.iloc[:, 2:])\n",
    "ct_chemberta2_features.reset_index(drop=True, inplace=True)\n",
    "ct_molformer_features = pd.DataFrame(ct_molformer_features_valid2.iloc[:, 1:])\n",
    "ct_molformer_features.reset_index(drop=True, inplace=True)\n",
    "ct_molbert_features = pd.DataFrame(ct_molbert_features_valid2.iloc[:, 1:])\n",
    "ct_molbert_features.reset_index(drop=True, inplace=True)\n",
    "\n",
    "ct_features = pd.concat([ct_chemberta2_features, ct_molformer_features, ct_molbert_features], axis=1)\n",
    "\n",
    "# combine the features and probabilities\n",
    "ct_X_ensemble_valid2 = pd.concat([ct_prob, ct_features], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_chemberta2_test.reset_index(drop=True, inplace=True)\n",
    "ct_y_ensemble_test = ct_chemberta2_test['CT_TOX']\n",
    "\n",
    "# do the same for test probs and features\n",
    "ct_chemberta2_prob = pd.DataFrame({'chemberta2': ct_chemberta2_test['softmax_class_1_prob']})\n",
    "ct_chemberta2_prob.reset_index(drop=True, inplace=True)\n",
    "ct_molformer_prob = pd.DataFrame({'molformer': ct_molformer_test['Prob_Class_1']})\n",
    "ct_molformer_prob.reset_index(drop=True, inplace=True)\n",
    "ct_molbert_prob = pd.DataFrame({'molbert': ct_molbert_test['prob']})\n",
    "ct_molbert_prob.reset_index(drop=True, inplace=True)\n",
    "\n",
    "ct_prob = pd.concat([ct_chemberta2_prob, ct_molformer_prob, ct_molbert_prob], axis=1)\n",
    "\n",
    "ct_chemberta2_features = pd.DataFrame(ct_chemberta2_features_test.iloc[:, 2:])\n",
    "ct_chemberta2_features.reset_index(drop=True, inplace=True)\n",
    "ct_molformer_features = pd.DataFrame(ct_molformer_features_test.iloc[:, 1:])\n",
    "ct_molformer_features.reset_index(drop=True, inplace=True)\n",
    "ct_molbert_features = pd.DataFrame(ct_molbert_features_test.iloc[:, 1:])\n",
    "ct_molbert_features.reset_index(drop=True, inplace=True)\n",
    "ct_features = pd.concat([ct_chemberta2_features, ct_molformer_features, ct_molbert_features], axis=1)\n",
    "\n",
    "ct_X_ensemble_test = pd.concat([ct_prob, ct_features], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use standard scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "ct_X_ensemble_valid2_scaled = scaler.fit_transform(ct_X_ensemble_valid2)\n",
    "ct_X_ensemble_test_scaled = scaler.transform(ct_X_ensemble_test)\n",
    "\n",
    "# transform back to dataframe\n",
    "ct_X_ensemble_valid2_scaled = pd.DataFrame(ct_X_ensemble_valid2_scaled, columns=ct_X_ensemble_valid2.columns)\n",
    "ct_X_ensemble_test_scaled = pd.DataFrame(ct_X_ensemble_test_scaled, columns=ct_X_ensemble_test.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the scaled data to csv\n",
    "ct_X_ensemble_valid2_scaled.to_csv('./processed_data/clintox_X_ensemble_valid2_scaled_rawpreds.csv', index=False)\n",
    "ct_X_ensemble_test_scaled.to_csv('./processed_data/clintox_X_ensemble_test_scaled_rawpreds.csv', index=False)\n",
    "\n",
    "# save the target values to csv\n",
    "ct_y_ensemble_valid2.to_csv('./processed_data/clintox_y_ensemble_valid2.csv', index=False)\n",
    "ct_y_ensemble_test.to_csv('./processed_data/clintox_y_ensemble_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.9798657718120806,\n",
       " 'F1 Score': 0.8421052631578947,\n",
       " 'ROC-AUC': 0.9888888888888889,\n",
       " 'PR-AUC': 0.8967813051146385}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use lasso regression to train the ensemble model\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "# cross validation for strength of regularization\n",
    "lasso_cv = LogisticRegressionCV(cv=5, penalty='l1', solver='liblinear', max_iter=5000, random_state=0, scoring='roc_auc')\n",
    "\n",
    "# Fit the model\n",
    "lasso_cv.fit(ct_X_ensemble_valid2_scaled, ct_y_ensemble_valid2)\n",
    "\n",
    "# Predict the test set\n",
    "ct_lasso_pred = lasso_cv.predict(ct_X_ensemble_test_scaled)\n",
    "ct_lasso_probs = lasso_cv.predict_proba(ct_X_ensemble_test_scaled)[:, 1]\n",
    "\n",
    "# Calculate the metrics\n",
    "ct_lasso_metrics = {\n",
    "    \"Accuracy\": accuracy_score(ct_y_ensemble_test, ct_lasso_pred),\n",
    "    \"F1 Score\": f1_score(ct_y_ensemble_test, ct_lasso_pred),\n",
    "    \"ROC-AUC\": roc_auc_score(ct_y_ensemble_test, ct_lasso_probs),\n",
    "    \"PR-AUC\": average_precision_score(ct_y_ensemble_test, ct_lasso_probs)\n",
    "}\n",
    "\n",
    "ct_lasso_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features: ['chemberta2']\n"
     ]
    }
   ],
   "source": [
    "coefs = pd.Series(lasso_cv.coef_[0], index=ct_X_ensemble_valid2.columns)\n",
    "\n",
    "# Filter to get the selected features\n",
    "selected_features = coefs[coefs != 0].index.tolist()\n",
    "\n",
    "print(\"Selected Features:\", selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lorrainelu/anaconda3/lib/python3.11/site-packages/group_lasso/_fista.py:114: ConvergenceWarning: The FISTA iterations did not converge to a sufficient minimum.\n",
      "You used subsampling then this is expected, otherwise, try increasing the number of iterations or decreasing the tolerance.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.9798657718120806,\n",
       " 'F1 Score': 0.8421052631578947,\n",
       " 'ROC-AUC': 0.976984126984127,\n",
       " 'PR-AUC': 0.9152046783625731}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from group_lasso import LogisticGroupLasso\n",
    "import numpy as np\n",
    "\n",
    "# Create an array that specifies the group for each feature\n",
    "# Assuming the number of features in your dataset:\n",
    "n_features = ct_X_ensemble_valid2_scaled.shape[1]\n",
    "groups = np.zeros(n_features, dtype=int)\n",
    "groups[:3] = 1  # First three features as one group\n",
    "groups[3:] = 2  # Rest of the features as another group\n",
    "\n",
    "# Initialize the Logistic Group Lasso model\n",
    "group_lasso = LogisticGroupLasso(\n",
    "    groups=groups,\n",
    "    group_reg=0.05,  # Regularization strength for the groups\n",
    "    l1_reg=0,        # No L1 regularization\n",
    "    scale_reg='none', # Do not automatically scale the regularization\n",
    "    supress_warning=True,\n",
    "    tol=1e-2,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "group_lasso.fit(ct_X_ensemble_valid2_scaled, ct_y_ensemble_valid2)\n",
    "\n",
    "# Predict the test set\n",
    "ct_group_lasso_pred = group_lasso.predict(ct_X_ensemble_test_scaled)\n",
    "ct_group_lasso_probs = group_lasso.predict_proba(ct_X_ensemble_test_scaled)[:, 1]\n",
    "\n",
    "ct_two_groups_lasso_metrics = {\n",
    "    \"Accuracy\": accuracy_score(ct_y_ensemble_test, ct_group_lasso_pred),\n",
    "    \"F1 Score\": f1_score(ct_y_ensemble_test, ct_group_lasso_pred),\n",
    "    \"ROC-AUC\": roc_auc_score(ct_y_ensemble_test, ct_group_lasso_probs),\n",
    "    \"PR-AUC\": average_precision_score(ct_y_ensemble_test, ct_group_lasso_probs)\n",
    "}\n",
    "\n",
    "ct_two_groups_lasso_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.9865771812080537,\n",
       " 'F1 Score': 0.8888888888888888,\n",
       " 'ROC-AUC': 0.9777777777777779,\n",
       " 'PR-AUC': 0.904320987654321}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from group_lasso import LogisticGroupLasso\n",
    "import numpy as np\n",
    "\n",
    "# Create an array that specifies the group for each feature\n",
    "# Assuming the number of features in your dataset:\n",
    "n_features = ct_X_ensemble_valid2_scaled.shape[1]\n",
    "groups = np.zeros(n_features, dtype=int)\n",
    "\n",
    "# Setting the groups according to the new specification:\n",
    "groups[:3] = 1      # First three features as one group\n",
    "groups[3:3+384] = 2 # Next 384 features as second group\n",
    "groups[3+384:3+384+768] = 3 # Next 768 features as third group\n",
    "groups[3+384+768:] = 4 # Remaining 768 features as fourth group\n",
    "\n",
    "# Initialize the Logistic Group Lasso model\n",
    "group_lasso = LogisticGroupLasso(\n",
    "    groups=groups,\n",
    "    group_reg=0.05,  # Regularization strength for the groups\n",
    "    l1_reg=0,        # No L1 regularization\n",
    "    scale_reg='none', # Do not automatically scale the regularization\n",
    "    supress_warning=True,\n",
    "    tol=1e-2,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "group_lasso.fit(ct_X_ensemble_valid2_scaled, ct_y_ensemble_valid2)\n",
    "\n",
    "# Predict the test set\n",
    "ct_group_lasso_pred = group_lasso.predict(ct_X_ensemble_test_scaled)\n",
    "ct_group_lasso_probs = group_lasso.predict_proba(ct_X_ensemble_test_scaled)[:, 1]\n",
    "\n",
    "# Calculate the metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, average_precision_score\n",
    "\n",
    "ct_four_groups_lasso_metrics = {\n",
    "    \"Accuracy\": accuracy_score(ct_y_ensemble_test, ct_group_lasso_pred),\n",
    "    \"F1 Score\": f1_score(ct_y_ensemble_test, ct_group_lasso_pred),\n",
    "    \"ROC-AUC\": roc_auc_score(ct_y_ensemble_test, ct_group_lasso_probs),\n",
    "    \"PR-AUC\": average_precision_score(ct_y_ensemble_test, ct_group_lasso_probs)\n",
    "}\n",
    "\n",
    "ct_four_groups_lasso_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(elastic_net_model, param_grid\u001b[38;5;241m=\u001b[39mparams, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroc_auc\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Fit the grid search to the data\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mct_X_ensemble_valid2_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mct_y_ensemble_valid2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Best model after grid search\u001b[39;00m\n\u001b[1;32m     27\u001b[0m ct_best_elastic_model \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1018\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1013\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1014\u001b[0m     )\n\u001b[1;32m   1016\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1018\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1572\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1570\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1571\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1572\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:964\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    957\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    958\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    959\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    960\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    961\u001b[0m         )\n\u001b[1;32m    962\u001b[0m     )\n\u001b[0;32m--> 964\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    965\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    983\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    984\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    985\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    986\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    987\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     73\u001b[0m )\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:136\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:888\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    886\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    887\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 888\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    891\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    892\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1350\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1347\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1348\u001b[0m     n_threads \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1350\u001b[0m fold_coefs_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprefer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1352\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1353\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1354\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1355\u001b[0m \u001b[43m        \u001b[49m\u001b[43mCs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mC_\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1356\u001b[0m \u001b[43m        \u001b[49m\u001b[43ml1_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ml1_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1357\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1358\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1359\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1360\u001b[0m \u001b[43m        \u001b[49m\u001b[43msolver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1361\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1362\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1363\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1364\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1365\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1366\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoef\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1367\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpenalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpenalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1368\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_squared_sum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_squared_sum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1369\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1370\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1371\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1372\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclasses_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1373\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1375\u001b[0m fold_coefs_, _, n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mfold_coefs_)\n\u001b[1;32m   1376\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(n_iter_, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint32)[:, \u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     73\u001b[0m )\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:136\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:547\u001b[0m, in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001b[0m\n\u001b[1;32m    544\u001b[0m         alpha \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m C) \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m l1_ratio)\n\u001b[1;32m    545\u001b[0m         beta \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m C) \u001b[38;5;241m*\u001b[39m l1_ratio\n\u001b[0;32m--> 547\u001b[0m     w0, n_iter_i, warm_start_sag \u001b[38;5;241m=\u001b[39m \u001b[43msag_solver\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    548\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m        \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_squared_sum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwarm_start_sag\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_saga\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msolver\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msaga\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    565\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    566\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msolver must be one of \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlbfgs\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    567\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnewton-cg\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msag\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m}, got \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m instead\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m solver\n\u001b[1;32m    568\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:324\u001b[0m, in \u001b[0;36msag_solver\u001b[0;34m(X, y, sample_weight, loss, alpha, beta, max_iter, tol, verbose, random_state, check_input, max_squared_sum, warm_start_mem, is_saga)\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mZeroDivisionError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrent sag implementation does not handle \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe case step_size * alpha_scaled == 1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m     )\n\u001b[1;32m    323\u001b[0m sag \u001b[38;5;241m=\u001b[39m sag64 \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat64 \u001b[38;5;28;01melse\u001b[39;00m sag32\n\u001b[0;32m--> 324\u001b[0m num_seen, n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[43msag\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoef_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m    \u001b[49m\u001b[43mintercept_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstep_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[43malpha_scaled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta_scaled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43msum_gradient_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgradient_memory_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseen_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_seen_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mintercept_sum_gradient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mintercept_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_saga\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_iter_ \u001b[38;5;241m==\u001b[39m max_iter:\n\u001b[1;32m    349\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    350\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe max_iter was reached which means the coef_ did not converge\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    351\u001b[0m         ConvergenceWarning,\n\u001b[1;32m    352\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, average_precision_score\n",
    "\n",
    "# Define the model with elasticnet penalty\n",
    "elastic_net_model = LogisticRegression(penalty='elasticnet', solver='saga', max_iter=5000, random_state=0)\n",
    "\n",
    "# Use fewer discrete values for alpha and l1_ratio\n",
    "alphas = [0.01, 0.1, 1, 3]  # Reduced number of points focusing on lower and mid-range\n",
    "l1_ratios = [0.1, 0.5, 0.9]  # Reduced to three points, emphasizing edges and midpoint\n",
    "\n",
    "# Convert alphas to Cs for the parameter grid (since C is the inverse of alpha)\n",
    "Cs = [1/alpha for alpha in alphas]\n",
    "\n",
    "# Create a more concise grid search using 5-fold cross-validation\n",
    "params = {\n",
    "    'C': Cs,\n",
    "    'l1_ratio': l1_ratios\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(elastic_net_model, param_grid=params, cv=5, scoring='roc_auc')\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(ct_X_ensemble_valid2_scaled, ct_y_ensemble_valid2)\n",
    "\n",
    "# Best model after grid search\n",
    "ct_best_elastic_model = grid_search.best_estimator_\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# Predict the test set\n",
    "ct_elastic_pred = ct_best_elastic_model.predict(ct_X_ensemble_test_scaled)\n",
    "ct_elastic_probs = ct_best_elastic_model.predict_proba(ct_X_ensemble_test_scaled)[:, 1]\n",
    "\n",
    "# Calculate the metrics\n",
    "ct_elastic_metrics = {\n",
    "    \"Accuracy\": accuracy_score(ct_y_ensemble_test, ct_elastic_pred),\n",
    "    \"F1 Score\": f1_score(ct_y_ensemble_test, ct_elastic_pred),\n",
    "    \"ROC-AUC\": roc_auc_score(ct_y_ensemble_test, ct_elastic_probs),\n",
    "    \"PR-AUC\": average_precision_score(ct_y_ensemble_test, ct_elastic_probs)\n",
    "}\n",
    "\n",
    "ct_elastic_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features: ['chemberta2', 'molformer', 'chemberta2_feature_22', 'chemberta2_feature_28', 'chemberta2_feature_39', 'chemberta2_feature_45', 'chemberta2_feature_50', 'chemberta2_feature_90', 'chemberta2_feature_108', 'chemberta2_feature_116', 'chemberta2_feature_153', 'chemberta2_feature_168', 'chemberta2_feature_180', 'chemberta2_feature_195', 'chemberta2_feature_199', 'chemberta2_feature_202', 'chemberta2_feature_221', 'chemberta2_feature_226', 'chemberta2_feature_275', 'chemberta2_feature_290', 'chemberta2_feature_310', 'chemberta2_feature_316', 'chemberta2_feature_325', 'chemberta2_feature_356', 'chemberta2_feature_370', 'chemberta2_feature_374', 'chemberta2_feature_379', 'molformer_feature_60', 'molformer_feature_82', 'molformer_feature_95', 'molformer_feature_117', 'molformer_feature_122', 'molformer_feature_152', 'molformer_feature_174', 'molformer_feature_236', 'molformer_feature_269', 'molformer_feature_342', 'molformer_feature_347', 'molformer_feature_380', 'molformer_feature_407', 'molformer_feature_438', 'molformer_feature_446', 'molformer_feature_447', 'molformer_feature_466', 'molformer_feature_504', 'molformer_feature_506', 'molformer_feature_558', 'molformer_feature_587', 'molformer_feature_607', 'molformer_feature_609', 'molformer_feature_612', 'molformer_feature_637', 'molformer_feature_667', 'molformer_feature_682', 'molformer_feature_719', 'molformer_feature_726', 'molformer_feature_728', 'molformer_feature_748', 'molbert_features_4', 'molbert_features_48', 'molbert_features_87', 'molbert_features_180', 'molbert_features_204', 'molbert_features_233', 'molbert_features_283', 'molbert_features_291', 'molbert_features_320', 'molbert_features_399', 'molbert_features_406', 'molbert_features_518', 'molbert_features_673']\n"
     ]
    }
   ],
   "source": [
    "# check coefficients\n",
    "coefs = pd.Series(ct_best_elastic_model.coef_[0], index=ct_X_ensemble_valid2.columns)\n",
    "\n",
    "# Filter to get the selected features\n",
    "selected_features = coefs[coefs != 0].index.tolist()\n",
    "\n",
    "print(\"Selected Features:\", selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(291, 1923)\n",
      "(149, 1923)\n"
     ]
    }
   ],
   "source": [
    "ct_X_ensemble_valid2_selected = ct_X_ensemble_valid2_scaled\n",
    "ct_X_ensemble_test_selected = ct_X_ensemble_test_scaled\n",
    "# check shapes\n",
    "print(ct_X_ensemble_valid2_selected.shape)\n",
    "print(ct_X_ensemble_test_selected.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.9731543624161074,\n",
       " 'F1 Score': 0.7142857142857143,\n",
       " 'ROC-AUC': 0.9817460317460318,\n",
       " 'PR-AUC': 0.9201388888888891}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and train the SVM model\n",
    "from sklearn.svm import SVC\n",
    "import random\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "ct_svm_model = SVC(probability=True, random_state=0)\n",
    "ct_svm_model.fit(ct_X_ensemble_valid2_selected, ct_y_ensemble_valid2)\n",
    "\n",
    "# Predict the test set\n",
    "ct_svm_pred = ct_svm_model.predict(ct_X_ensemble_test_selected)\n",
    "ct_svm_probs = ct_svm_model.predict_proba(ct_X_ensemble_test_selected)\n",
    "\n",
    "# Calculate the metrics\n",
    "ct_svm_metrics = {\n",
    "    'Accuracy': accuracy_score(ct_y_ensemble_test, ct_svm_pred),\n",
    "    'F1 Score': f1_score(ct_y_ensemble_test, ct_svm_pred),\n",
    "    'ROC-AUC': roc_auc_score(ct_y_ensemble_test, ct_svm_probs[:, 1]),\n",
    "    \"PR-AUC\": average_precision_score(ct_y_ensemble_test, ct_svm_probs[:, 1])\n",
    "}\n",
    "\n",
    "ct_svm_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.959731543624161,\n",
       " 'F1 Score': 0.5714285714285714,\n",
       " 'ROC-AUC': 0.9829365079365079,\n",
       " 'PR-AUC': 0.8140933140933142}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initailize and use a 5-fold cross-validation to tune the hyperparameters of a random forest model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "ct_rf_model = RandomForestClassifier(random_state=0)\n",
    "\n",
    "ct_rf_model.fit(ct_X_ensemble_valid2_selected, ct_y_ensemble_valid2)\n",
    "\n",
    "# Predict the test set\n",
    "ct_rf_best_pred = ct_rf_model.predict(ct_X_ensemble_test_selected)\n",
    "ct_rf_best_probs = ct_rf_model.predict_proba(ct_X_ensemble_test_selected)\n",
    "\n",
    "# Calculate the metrics\n",
    "ct_rf_best_metrics = {\n",
    "    \"Accuracy\": accuracy_score(ct_y_ensemble_test, ct_rf_best_pred),\n",
    "    \"F1 Score\": f1_score(ct_y_ensemble_test, ct_rf_best_pred),\n",
    "    \"ROC-AUC\": roc_auc_score(ct_y_ensemble_test, ct_rf_best_probs[:, 1]),\n",
    "    \"PR-AUC\": average_precision_score(ct_y_ensemble_test, ct_rf_best_probs[:, 1])\n",
    "}\n",
    "\n",
    "ct_rf_best_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 32%|      | 16/50 [00:46<01:39,  2.94s/trial, best loss: -0.9550000000000001]\n",
      "Best hyperparameters: {'colsample_bytree': 0.9612015083412822, 'learning_rate': 0.2088939071831353, 'max_depth': 6.0, 'n_estimators': 150.0, 'subsample': 0.9991756881657872}\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score, make_scorer\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.early_stop import no_progress_loss\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "# Define the hyperparameter space using continuous distributions\n",
    "ct_xgb_hyperopt_space = {\n",
    "    'n_estimators': hp.quniform('n_estimators', 50, 200, 50),\n",
    "    'max_depth': hp.quniform('max_depth', 3, 7, 2),\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.001, 0.3),\n",
    "    'subsample': hp.uniform('subsample', 0.5, 1.0),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1.0)\n",
    "}\n",
    "\n",
    "# Convert float outputs of hp.quniform to int for certain parameters\n",
    "def objective(params):\n",
    "    params['n_estimators'] = int(params['n_estimators'])\n",
    "    params['max_depth'] = int(params['max_depth'])\n",
    "    \n",
    "    model = xgb.XGBClassifier(**params, random_state=0)\n",
    "    \n",
    "    # Cross-validated AUC score as the objective\n",
    "    roc_auc = make_scorer(roc_auc_score, response_method=None)\n",
    "    score = cross_val_score(model, ct_X_ensemble_valid2_selected, ct_y_ensemble_valid2, scoring=roc_auc, cv=5)\n",
    "    \n",
    "    # Minimize the negative ROC AUC score\n",
    "    return {'loss': -score.mean(), 'status': STATUS_OK}\n",
    "\n",
    "# Run the Bayesian optimization\n",
    "trials = Trials()\n",
    "ct_xgb_best_params = fmin(fn=objective, \n",
    "                          space=ct_xgb_hyperopt_space, \n",
    "                          algo=tpe.suggest, \n",
    "                          max_evals=50, \n",
    "                          trials=trials,\n",
    "                          rstate=np.random.default_rng(0),  # Seed for hyperopt\n",
    "                          early_stop_fn=no_progress_loss(10))\n",
    "\n",
    "print(\"Best hyperparameters:\", ct_xgb_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.9530201342281879,\n",
       " 'F1 Score': 0.6956521739130435,\n",
       " 'ROC-AUC': 0.9896825396825396,\n",
       " 'PR-AUC': 0.924162257495591}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert parameters obtained from Hyperopt to the correct data type\n",
    "ct_xgb_best_params['n_estimators'] = int(ct_xgb_best_params['n_estimators'])\n",
    "ct_xgb_best_params['max_depth'] = int(ct_xgb_best_params['max_depth'])\n",
    "\n",
    "# Initialize and train the XGBoost model with the best parameters\n",
    "ct_xgb_model = xgb.XGBClassifier(**ct_xgb_best_params, random_state=0)\n",
    "ct_xgb_model.fit(ct_X_ensemble_valid2_selected, ct_y_ensemble_valid2)\n",
    "\n",
    "# Predict the test set\n",
    "ct_xgb_best_pred = ct_xgb_model.predict(ct_X_ensemble_test_selected)\n",
    "ct_xgb_best_probs = ct_xgb_model.predict_proba(ct_X_ensemble_test_selected)\n",
    "\n",
    "# Calculate the metrics\n",
    "ct_xgb_best_metrics = {\n",
    "    \"Accuracy\": accuracy_score(ct_y_ensemble_test, ct_xgb_best_pred),\n",
    "    \"F1 Score\": f1_score(ct_y_ensemble_test, ct_xgb_best_pred),\n",
    "    \"ROC-AUC\": roc_auc_score(ct_y_ensemble_test, ct_xgb_best_probs[:, 1]),\n",
    "    \"PR-AUC\": average_precision_score(ct_y_ensemble_test, ct_xgb_best_probs[:, 1])\n",
    "}\n",
    "\n",
    "ct_xgb_best_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 44%|     | 22/50 [01:56<02:28,  5.31s/trial, best loss: -0.992711038961039] \n",
      "Best hyperparameters: {'dropout_rate': 0.09430498428577411, 'learning_rate': 0.0022472351340380946, 'num_layers': 3.0, 'num_neurons': 154.0}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.early_stop import no_progress_loss\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Define the neural network model\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, num_layers, num_neurons, dropout_rate):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        layers = [nn.Linear(input_size, num_neurons), nn.ReLU(), nn.Dropout(dropout_rate)]\n",
    "        \n",
    "        for _ in range(num_layers - 1):\n",
    "            layers += [nn.Linear(num_neurons, num_neurons), nn.ReLU(), nn.Dropout(dropout_rate)]\n",
    "        \n",
    "        layers += [nn.Linear(num_neurons, 1), nn.Sigmoid()]\n",
    "        \n",
    "        self.layers = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "# Objective function for Bayesian optimization\n",
    "def objective(params):\n",
    "    kf = KFold(n_splits=5)\n",
    "    roc_aucs = []\n",
    "\n",
    "    for train_index, val_index in kf.split(X):\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "        train_dataset = TensorDataset(torch.tensor(X_train.values.astype(np.float32)), \n",
    "                                      torch.tensor(y_train.values.astype(np.float32)).unsqueeze(1))\n",
    "        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "        model = SimpleNN(input_size=X_train.shape[1], num_layers=int(params['num_layers']), \n",
    "                         num_neurons=int(params['num_neurons']), dropout_rate=params['dropout_rate'])\n",
    "        criterion = nn.BCELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=params['learning_rate'])\n",
    "\n",
    "        model.train()\n",
    "        for epoch in range(100):\n",
    "            for inputs, targets in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            X_val_tensor = torch.tensor(X_val.values.astype(np.float32))\n",
    "            y_val_tensor = torch.tensor(y_val.values.astype(np.float32)).unsqueeze(-1)\n",
    "            outputs = model(X_val_tensor)\n",
    "            roc_auc = roc_auc_score(y_val_tensor.numpy(), outputs.numpy())\n",
    "            roc_aucs.append(roc_auc)\n",
    "\n",
    "    avg_roc_auc = np.mean(roc_aucs)\n",
    "    return {'loss': -avg_roc_auc, 'status': STATUS_OK}  # Maximize ROC AUC by minimizing the negative ROC AUC\n",
    "\n",
    "# Hyperparameter space\n",
    "space = {\n",
    "    'num_layers': hp.quniform('num_layers', 1, 5, 1),\n",
    "    'num_neurons': hp.quniform('num_neurons', 16, 256, 1),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.0001), np.log(0.01)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.0, 0.5)\n",
    "}\n",
    "\n",
    "X = ct_X_ensemble_valid2_selected\n",
    "y = ct_y_ensemble_valid2\n",
    "\n",
    "# Run Bayesian optimization\n",
    "trials = Trials()\n",
    "ct_nn_best_params = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=50,\n",
    "            trials=trials,\n",
    "            rstate=np.random.default_rng(0),  # Seed for hyperopt\n",
    "            early_stop_fn=no_progress_loss(10))\n",
    "\n",
    "print(\"Best hyperparameters:\", ct_nn_best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.9798657718120806,\n",
       " 'F1 Score': 0.8421052631578947,\n",
       " 'ROC-AUC': 0.9873015873015872,\n",
       " 'PR-AUC': 0.9288888888888889}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Define the neural network model again\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, num_layers, num_neurons, dropout_rate):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        layers = [nn.Linear(input_size, num_neurons), nn.ReLU(), nn.Dropout(dropout_rate)]\n",
    "        \n",
    "        for _ in range(num_layers - 1):\n",
    "            layers += [nn.Linear(num_neurons, num_neurons), nn.ReLU(), nn.Dropout(dropout_rate)]\n",
    "        \n",
    "        layers += [nn.Linear(num_neurons, 1), nn.Sigmoid()]\n",
    "        \n",
    "        self.layers = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "# Convert parameters to the correct format if necessary\n",
    "ct_nn_best_params = {\n",
    "    'num_layers': int(ct_nn_best_params['num_layers']),  # Extracted from Bayesian optimization results\n",
    "    'num_neurons': int(ct_nn_best_params['num_neurons']),  # Extracted from Bayesian optimization results\n",
    "    'dropout_rate': ct_nn_best_params['dropout_rate'],  # Extracted from Bayesian optimization results\n",
    "    'learning_rate': ct_nn_best_params['learning_rate']  # Extracted from Bayesian optimization results\n",
    "}\n",
    "\n",
    "# Prepare datasets\n",
    "X_train_tensor = torch.tensor(ct_X_ensemble_valid2_selected.values.astype(np.float32))\n",
    "y_train_tensor = torch.tensor(ct_y_ensemble_valid2.values.astype(np.float32)).unsqueeze(1)\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "X_test_tensor = torch.tensor(ct_X_ensemble_test_selected.values.astype(np.float32))\n",
    "y_test_tensor = torch.tensor(ct_y_ensemble_test.values.astype(np.float32)).unsqueeze(1)\n",
    "\n",
    "# Initialize the model\n",
    "model = SimpleNN(input_size=ct_X_ensemble_valid2_selected.shape[1], num_layers=ct_nn_best_params['num_layers'], \n",
    "                 num_neurons=ct_nn_best_params['num_neurons'], dropout_rate=ct_nn_best_params['dropout_rate'])\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=ct_nn_best_params['learning_rate'])\n",
    "\n",
    "# Training loop\n",
    "model.train()\n",
    "for epoch in range(100):  # Number of epochs can be adjusted\n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Evaluation on test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_test_tensor)\n",
    "    predictions = (outputs > 0.5).float()\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test_tensor.numpy(), predictions.numpy())\n",
    "    f1 = f1_score(y_test_tensor.numpy(), predictions.numpy())\n",
    "    roc_auc = roc_auc_score(y_test_tensor.numpy(), outputs.numpy())\n",
    "    pr_auc = average_precision_score(y_test_tensor.numpy(), outputs.numpy())\n",
    "\n",
    "    ct_nn_metrics = {\n",
    "        'Accuracy': accuracy,\n",
    "        'F1 Score': f1,\n",
    "        'ROC-AUC': roc_auc,\n",
    "        'PR-AUC': pr_auc\n",
    "    }\n",
    "\n",
    "ct_nn_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report all the metrics for ct\n",
    "ct_metrics_results[\"LASSO\"] = ct_lasso_metrics\n",
    "ct_metrics_results[\"Group Lasso (Two Groups)\"] = ct_two_groups_lasso_metrics\n",
    "ct_metrics_results[\"Group Lasso (Four Groups)\"] = ct_four_groups_lasso_metrics\n",
    "ct_metrics_results[\"Elastic Net\"] = ct_elastic_metrics\n",
    "ct_metrics_results[\"SVM\"] = ct_svm_metrics\n",
    "ct_metrics_results[\"Random Forest\"] = ct_rf_best_metrics\n",
    "ct_metrics_results[\"XGBoost\"] = ct_xgb_best_metrics\n",
    "ct_metrics_results[\"Neural Network\"] = ct_nn_metrics\n",
    "\n",
    "ct_metrics_df = pd.DataFrame(ct_metrics_results).T\n",
    "\n",
    "# keep 3 digits after the decimal point\n",
    "ct_metrics_df = ct_metrics_df.round(3)\n",
    "\n",
    "# export as csv\n",
    "ct_metrics_df.to_csv('./split1_ct_metrics_rawpreds.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fusion-env",
   "language": "python",
   "name": "fusion-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
