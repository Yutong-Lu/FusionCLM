{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, precision_recall_curve, average_precision_score, mean_squared_error, r2_score, mean_absolute_error\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# preds\n",
    "\n",
    "# Load the training set of meta-model\n",
    "ct_chemberta2_valid2 = pd.read_csv('./chemberta2/results/clintox/chemberta2_valid2_clintox_3_predictions.csv')\n",
    "ct_molformer_valid2 = pd.read_csv('./molformer/results/clintox/molformer_valid2_clintox_3_epoch26.csv')\n",
    "ct_molbert_valid2 = pd.read_csv('./molbert/results/cilntox/molbert_valid2_clintox_3.csv')\n",
    "\n",
    "# Load the test data for each model\n",
    "ct_chemberta2_test = pd.read_csv('./chemberta2/results/clintox/chemberta2_test_clintox_3_predictions.csv')\n",
    "ct_molformer_test = pd.read_csv('./molformer/results/clintox/molformer_test_clintox_3_epoch26.csv')\n",
    "ct_molbert_test = pd.read_csv('./molbert/results/cilntox/molbert_test_clintox_3.csv')\n",
    "\n",
    "# features\n",
    "\n",
    "# Load the features from chemberta\n",
    "ct_chemberta2_features_valid2 = pd.read_csv('./chemberta2/features/clintox/chemberta2_valid2_clintox_3_features.csv')\n",
    "ct_chemberta2_features_test = pd.read_csv('./chemberta2/features/clintox/chemberta2_test_clintox_3_features.csv')\n",
    "\n",
    "# Load the features from molformer\n",
    "ct_molformer_features_valid2 = pd.read_csv('./molformer/features/clintox/molformer_valid2_clintox_3_features.csv')\n",
    "ct_molformer_features_test = pd.read_csv('./molformer/features/clintox/molformer_test_clintox_3_features.csv')\n",
    "\n",
    "# Load the features from molbert\n",
    "ct_molbert_features_valid2 = pd.read_csv('./molbert/features/clintox/molbert_valid2_clintox_3_features.csv')\n",
    "ct_molbert_features_test = pd.read_csv('./molbert/features/clintox/molbert_test_clintox_3_features.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Clintox (Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Chemberta2': {'Accuracy': 0.9731543624161074,\n",
       "  'F1 Score': 0.8,\n",
       "  'ROC-AUC': 0.9964028776978417,\n",
       "  'PR-AUC': 0.9540404040404039},\n",
       " 'Molformer': {'Accuracy': 0.9328859060402684,\n",
       "  'F1 Score': 0.375,\n",
       "  'ROC-AUC': 0.9266187050359712,\n",
       "  'PR-AUC': 0.5340980864486556},\n",
       " 'Molbert': {'Accuracy': 0.9172413793103448,\n",
       "  'F1 Score': 0.14285714285714285,\n",
       "  'ROC-AUC': 0.9133333333333333,\n",
       "  'PR-AUC': 0.46665875863902184}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, average_precision_score\n",
    "\n",
    "# Preparing the actual and predicted values\n",
    "# Chemberta2\n",
    "ct_chemberta_actual = ct_chemberta2_test['CT_TOX']\n",
    "ct_chemberta_pred = ct_chemberta2_test['y_pred']\n",
    "ct_chemberta_probs = ct_chemberta2_test[['softmax_class_0_prob', 'softmax_class_1_prob']]\n",
    "\n",
    "# Molformer\n",
    "ct_molformer_actual = ct_molformer_test['Actual']\n",
    "ct_molformer_pred = (ct_molformer_test['Prob_Class_1'] > 0.5).astype(int)\n",
    "ct_molformer_probs = ct_molformer_test[['Prob_Class_0', 'Prob_Class_1']]\n",
    "\n",
    "# Molbert\n",
    "ct_molbert_actual = ct_molbert_test['target']\n",
    "ct_molbert_pred = ct_molbert_test['pred']\n",
    "ct_molbert_probs = ct_molbert_test['prob']\n",
    "\n",
    "# Calculating metrics\n",
    "ct_metrics_results = {}\n",
    "\n",
    "for model_name, actual, pred, probs in [(\"Chemberta2\", ct_chemberta_actual, ct_chemberta_pred, ct_chemberta_probs['softmax_class_1_prob']),\n",
    "                                         (\"Molformer\", ct_molformer_actual, ct_molformer_pred, ct_molformer_probs['Prob_Class_1']),\n",
    "                                         (\"Molbert\", ct_molbert_actual, ct_molbert_pred, ct_molbert_probs)]:\n",
    "    ct_metrics_results[model_name] = {\n",
    "        \"Accuracy\": accuracy_score(actual, pred),\n",
    "        \"F1 Score\": f1_score(actual, pred),\n",
    "        \"ROC-AUC\": roc_auc_score(actual, probs),\n",
    "        \"PR-AUC\": average_precision_score(actual, probs)\n",
    "    }\n",
    "\n",
    "ct_metrics_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the 'smiles' values in chemberta that are not in molbert\n",
    "missing_smiles = set(ct_chemberta2_valid2['smiles']) - set(ct_molbert_valid2['smiles'])\n",
    "\n",
    "# Find the indices of these missing 'smiles' in the chemberta DataFrame\n",
    "missing_indices = ct_chemberta2_valid2.index[ct_chemberta2_valid2['smiles'].isin(missing_smiles)].tolist()\n",
    "\n",
    "# Drop the rows with these missing indices for chemberta and molformer\n",
    "ct_chemberta2_valid2 = ct_chemberta2_valid2.drop(missing_indices)\n",
    "ct_molformer_valid2 = ct_molformer_valid2.drop(missing_indices)\n",
    "ct_chemberta2_features_valid2 = ct_chemberta2_features_valid2.drop(missing_indices)\n",
    "ct_molformer_features_valid2 = ct_molformer_features_valid2.drop(missing_indices)\n",
    "ct_molbert_features_valid2 = ct_molbert_features_valid2.drop(missing_indices)\n",
    "\n",
    "# do the same for test sets\n",
    "missing_smiles = set(ct_chemberta2_test['smiles']) - set(ct_molbert_test['smiles'])\n",
    "missing_indices = ct_chemberta2_test.index[ct_chemberta2_test['smiles'].isin(missing_smiles)].tolist()\n",
    "\n",
    "ct_chemberta2_test = ct_chemberta2_test.drop(missing_indices)\n",
    "ct_molformer_test = ct_molformer_test.drop(missing_indices)\n",
    "ct_chemberta2_features_test = ct_chemberta2_features_test.drop(missing_indices)\n",
    "ct_molformer_features_test = ct_molformer_features_test.drop(missing_indices)\n",
    "ct_molbert_features_test = ct_molbert_features_test.drop(missing_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(295, 8)\n",
      "(295, 5)\n",
      "(295, 4)\n",
      "(295, 386)\n",
      "(295, 769)\n",
      "(295, 769)\n"
     ]
    }
   ],
   "source": [
    "# check shapes\n",
    "print(ct_chemberta2_valid2.shape)\n",
    "print(ct_molformer_valid2.shape)\n",
    "print(ct_molbert_valid2.shape)\n",
    "print(ct_chemberta2_features_valid2.shape)\n",
    "print(ct_molformer_features_valid2.shape)\n",
    "print(ct_molbert_features_valid2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_chemberta2_valid2.reset_index(drop=True, inplace=True)\n",
    "ct_y_ensemble_valid2 = ct_chemberta2_valid2['CT_TOX']\n",
    "\n",
    "# create a new dataframe with one column of ct_chemberta2_valid2['softmax_class_1_prob']\n",
    "ct_chemberta2_prob = pd.DataFrame({'chemberta2': ct_chemberta2_valid2['softmax_class_1_prob']})\n",
    "ct_chemberta2_prob.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# create a new dataframe with one column of ct_molformer_valid2['Prob_Class_1']\n",
    "ct_molformer_prob = pd.DataFrame({'molformer': ct_molformer_valid2['Prob_Class_1']})\n",
    "ct_molformer_prob.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# create a new dataframe with one column of ct_molbert_valid2['Probabilities']\n",
    "ct_molbert_prob = pd.DataFrame({'molbert': ct_molbert_valid2['prob']})\n",
    "ct_molbert_prob.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# concatenate the three dataframes\n",
    "ct_prob = pd.concat([ct_chemberta2_prob, ct_molformer_prob, ct_molbert_prob], axis=1)\n",
    "\n",
    "# do the same for features ct_chemberta2_features_valid2.iloc[:, 2:]\n",
    "ct_chemberta2_features = pd.DataFrame(ct_chemberta2_features_valid2.iloc[:, 2:])\n",
    "ct_chemberta2_features.reset_index(drop=True, inplace=True)\n",
    "ct_molformer_features = pd.DataFrame(ct_molformer_features_valid2.iloc[:, 1:])\n",
    "ct_molformer_features.reset_index(drop=True, inplace=True)\n",
    "ct_molbert_features = pd.DataFrame(ct_molbert_features_valid2.iloc[:, 1:])\n",
    "ct_molbert_features.reset_index(drop=True, inplace=True)\n",
    "\n",
    "ct_features = pd.concat([ct_chemberta2_features, ct_molformer_features, ct_molbert_features], axis=1)\n",
    "\n",
    "# combine the features and probabilities\n",
    "ct_X_ensemble_valid2 = pd.concat([ct_prob, ct_features], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_chemberta2_test.reset_index(drop=True, inplace=True)\n",
    "ct_y_ensemble_test = ct_chemberta2_test['CT_TOX']\n",
    "\n",
    "# do the same for test probs and features\n",
    "ct_chemberta2_prob = pd.DataFrame({'chemberta2': ct_chemberta2_test['softmax_class_1_prob']})\n",
    "ct_chemberta2_prob.reset_index(drop=True, inplace=True)\n",
    "ct_molformer_prob = pd.DataFrame({'molformer': ct_molformer_test['Prob_Class_1']})\n",
    "ct_molformer_prob.reset_index(drop=True, inplace=True)\n",
    "ct_molbert_prob = pd.DataFrame({'molbert': ct_molbert_test['prob']})\n",
    "ct_molbert_prob.reset_index(drop=True, inplace=True)\n",
    "\n",
    "ct_prob = pd.concat([ct_chemberta2_prob, ct_molformer_prob, ct_molbert_prob], axis=1)\n",
    "\n",
    "ct_chemberta2_features = pd.DataFrame(ct_chemberta2_features_test.iloc[:, 2:])\n",
    "ct_chemberta2_features.reset_index(drop=True, inplace=True)\n",
    "ct_molformer_features = pd.DataFrame(ct_molformer_features_test.iloc[:, 1:])\n",
    "ct_molformer_features.reset_index(drop=True, inplace=True)\n",
    "ct_molbert_features = pd.DataFrame(ct_molbert_features_test.iloc[:, 1:])\n",
    "ct_molbert_features.reset_index(drop=True, inplace=True)\n",
    "ct_features = pd.concat([ct_chemberta2_features, ct_molformer_features, ct_molbert_features], axis=1)\n",
    "\n",
    "ct_X_ensemble_test = pd.concat([ct_prob, ct_features], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use standard scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "ct_X_ensemble_valid2_scaled = scaler.fit_transform(ct_X_ensemble_valid2)\n",
    "ct_X_ensemble_test_scaled = scaler.transform(ct_X_ensemble_test)\n",
    "\n",
    "# transform back to dataframe\n",
    "ct_X_ensemble_valid2_scaled = pd.DataFrame(ct_X_ensemble_valid2_scaled, columns=ct_X_ensemble_valid2.columns)\n",
    "ct_X_ensemble_test_scaled = pd.DataFrame(ct_X_ensemble_test_scaled, columns=ct_X_ensemble_test.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the scaled data to csv\n",
    "ct_X_ensemble_valid2_scaled.to_csv('./processed_data/clintox_X_ensemble_valid2_scaled_rawpreds.csv', index=False)\n",
    "ct_X_ensemble_test_scaled.to_csv('./processed_data/clintox_X_ensemble_test_scaled_rawpreds.csv', index=False)\n",
    "\n",
    "# save the target values to csv\n",
    "ct_y_ensemble_valid2.to_csv('./processed_data/clintox_y_ensemble_valid2.csv', index=False)\n",
    "ct_y_ensemble_test.to_csv('./processed_data/clintox_y_ensemble_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.9724137931034482,\n",
       " 'F1 Score': 0.8,\n",
       " 'ROC-AUC': 0.9962962962962962,\n",
       " 'PR-AUC': 0.954040404040404}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use lasso regression to train the ensemble model\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "# cross validation for strength of regularization\n",
    "lasso_cv = LogisticRegressionCV(cv=5, penalty='l1', solver='liblinear', max_iter=5000, random_state=0, scoring='roc_auc')\n",
    "\n",
    "# Fit the model\n",
    "lasso_cv.fit(ct_X_ensemble_valid2_scaled, ct_y_ensemble_valid2)\n",
    "\n",
    "# Predict the test set\n",
    "ct_lasso_pred = lasso_cv.predict(ct_X_ensemble_test_scaled)\n",
    "ct_lasso_probs = lasso_cv.predict_proba(ct_X_ensemble_test_scaled)[:, 1]\n",
    "\n",
    "# Calculate the metrics\n",
    "ct_lasso_metrics = {\n",
    "    \"Accuracy\": accuracy_score(ct_y_ensemble_test, ct_lasso_pred),\n",
    "    \"F1 Score\": f1_score(ct_y_ensemble_test, ct_lasso_pred),\n",
    "    \"ROC-AUC\": roc_auc_score(ct_y_ensemble_test, ct_lasso_probs),\n",
    "    \"PR-AUC\": average_precision_score(ct_y_ensemble_test, ct_lasso_probs)\n",
    "}\n",
    "\n",
    "ct_lasso_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features: ['chemberta2']\n"
     ]
    }
   ],
   "source": [
    "coefs = pd.Series(lasso_cv.coef_[0], index=ct_X_ensemble_valid2.columns)\n",
    "\n",
    "# Filter to get the selected features\n",
    "selected_features = coefs[coefs != 0].index.tolist()\n",
    "\n",
    "print(\"Selected Features:\", selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.896551724137931,\n",
       " 'F1 Score': 0.5454545454545454,\n",
       " 'ROC-AUC': 0.9355555555555556,\n",
       " 'PR-AUC': 0.8588626739261948}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from group_lasso import LogisticGroupLasso\n",
    "import numpy as np\n",
    "\n",
    "# Create an array that specifies the group for each feature\n",
    "# Assuming the number of features in your dataset:\n",
    "n_features = ct_X_ensemble_valid2_scaled.shape[1]\n",
    "groups = np.zeros(n_features, dtype=int)\n",
    "groups[:3] = 1  # First three features as one group\n",
    "groups[3:] = 2  # Rest of the features as another group\n",
    "\n",
    "# Initialize the Logistic Group Lasso model\n",
    "group_lasso = LogisticGroupLasso(\n",
    "    groups=groups,\n",
    "    group_reg=0.05,  # Regularization strength for the groups\n",
    "    l1_reg=0,        # No L1 regularization\n",
    "    scale_reg='none', # Do not automatically scale the regularization\n",
    "    supress_warning=True,\n",
    "    tol=1e-2,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "group_lasso.fit(ct_X_ensemble_valid2_scaled, ct_y_ensemble_valid2)\n",
    "\n",
    "# Predict the test set\n",
    "ct_group_lasso_pred = group_lasso.predict(ct_X_ensemble_test_scaled)\n",
    "ct_group_lasso_probs = group_lasso.predict_proba(ct_X_ensemble_test_scaled)[:, 1]\n",
    "\n",
    "ct_two_groups_lasso_metrics = {\n",
    "    \"Accuracy\": accuracy_score(ct_y_ensemble_test, ct_group_lasso_pred),\n",
    "    \"F1 Score\": f1_score(ct_y_ensemble_test, ct_group_lasso_pred),\n",
    "    \"ROC-AUC\": roc_auc_score(ct_y_ensemble_test, ct_group_lasso_probs),\n",
    "    \"PR-AUC\": average_precision_score(ct_y_ensemble_test, ct_group_lasso_probs)\n",
    "}\n",
    "\n",
    "ct_two_groups_lasso_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lorrainelu/anaconda3/lib/python3.11/site-packages/group_lasso/_fista.py:114: ConvergenceWarning: The FISTA iterations did not converge to a sufficient minimum.\n",
      "You used subsampling then this is expected, otherwise, try increasing the number of iterations or decreasing the tolerance.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.9724137931034482,\n",
       " 'F1 Score': 0.8,\n",
       " 'ROC-AUC': 0.9503703703703703,\n",
       " 'PR-AUC': 0.8674339300937767}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from group_lasso import LogisticGroupLasso\n",
    "import numpy as np\n",
    "\n",
    "# Create an array that specifies the group for each feature\n",
    "# Assuming the number of features in your dataset:\n",
    "n_features = ct_X_ensemble_valid2_scaled.shape[1]\n",
    "groups = np.zeros(n_features, dtype=int)\n",
    "\n",
    "# Setting the groups according to the new specification:\n",
    "groups[:3] = 1      # First three features as one group\n",
    "groups[3:3+384] = 2 # Next 384 features as second group\n",
    "groups[3+384:3+384+768] = 3 # Next 768 features as third group\n",
    "groups[3+384+768:] = 4 # Remaining 768 features as fourth group\n",
    "\n",
    "# Initialize the Logistic Group Lasso model\n",
    "group_lasso = LogisticGroupLasso(\n",
    "    groups=groups,\n",
    "    group_reg=0.05,  # Regularization strength for the groups\n",
    "    l1_reg=0,        # No L1 regularization\n",
    "    scale_reg='none', # Do not automatically scale the regularization\n",
    "    supress_warning=True,\n",
    "    tol=1e-2,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "group_lasso.fit(ct_X_ensemble_valid2_scaled, ct_y_ensemble_valid2)\n",
    "\n",
    "# Predict the test set\n",
    "ct_group_lasso_pred = group_lasso.predict(ct_X_ensemble_test_scaled)\n",
    "ct_group_lasso_probs = group_lasso.predict_proba(ct_X_ensemble_test_scaled)[:, 1]\n",
    "\n",
    "# Calculate the metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, average_precision_score\n",
    "\n",
    "ct_four_groups_lasso_metrics = {\n",
    "    \"Accuracy\": accuracy_score(ct_y_ensemble_test, ct_group_lasso_pred),\n",
    "    \"F1 Score\": f1_score(ct_y_ensemble_test, ct_group_lasso_pred),\n",
    "    \"ROC-AUC\": roc_auc_score(ct_y_ensemble_test, ct_group_lasso_probs),\n",
    "    \"PR-AUC\": average_precision_score(ct_y_ensemble_test, ct_group_lasso_probs)\n",
    "}\n",
    "\n",
    "ct_four_groups_lasso_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lorrainelu/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/lorrainelu/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/lorrainelu/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/lorrainelu/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/lorrainelu/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/lorrainelu/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/lorrainelu/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.3333333333333333, 'l1_ratio': 0.1}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.9517241379310345,\n",
       " 'F1 Score': 0.72,\n",
       " 'ROC-AUC': 0.9733333333333334,\n",
       " 'PR-AUC': 0.8886759581881534}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, average_precision_score\n",
    "\n",
    "# Define the model with elasticnet penalty\n",
    "elastic_net_model = LogisticRegression(penalty='elasticnet', solver='saga', max_iter=5000, random_state=0)\n",
    "\n",
    "# Use fewer discrete values for alpha and l1_ratio\n",
    "alphas = [0.01, 0.1, 1, 3]  # Reduced number of points focusing on lower and mid-range\n",
    "l1_ratios = [0.1, 0.5, 0.9]  # Reduced to three points, emphasizing edges and midpoint\n",
    "\n",
    "# Convert alphas to Cs for the parameter grid (since C is the inverse of alpha)\n",
    "Cs = [1/alpha for alpha in alphas]\n",
    "\n",
    "# Create a more concise grid search using 5-fold cross-validation\n",
    "params = {\n",
    "    'C': Cs,\n",
    "    'l1_ratio': l1_ratios\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(elastic_net_model, param_grid=params, cv=5, scoring='roc_auc')\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(ct_X_ensemble_valid2_scaled, ct_y_ensemble_valid2)\n",
    "\n",
    "# Best model after grid search\n",
    "ct_best_elastic_model = grid_search.best_estimator_\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# Predict the test set\n",
    "ct_elastic_pred = ct_best_elastic_model.predict(ct_X_ensemble_test_scaled)\n",
    "ct_elastic_probs = ct_best_elastic_model.predict_proba(ct_X_ensemble_test_scaled)[:, 1]\n",
    "\n",
    "# Calculate the metrics\n",
    "ct_elastic_metrics = {\n",
    "    \"Accuracy\": accuracy_score(ct_y_ensemble_test, ct_elastic_pred),\n",
    "    \"F1 Score\": f1_score(ct_y_ensemble_test, ct_elastic_pred),\n",
    "    \"ROC-AUC\": roc_auc_score(ct_y_ensemble_test, ct_elastic_probs),\n",
    "    \"PR-AUC\": average_precision_score(ct_y_ensemble_test, ct_elastic_probs)\n",
    "}\n",
    "\n",
    "ct_elastic_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features: ['chemberta2', 'molformer', 'molbert', 'chemberta2_feature_4', 'chemberta2_feature_5', 'chemberta2_feature_9', 'chemberta2_feature_10', 'chemberta2_feature_13', 'chemberta2_feature_14', 'chemberta2_feature_16', 'chemberta2_feature_17', 'chemberta2_feature_19', 'chemberta2_feature_20', 'chemberta2_feature_22', 'chemberta2_feature_23', 'chemberta2_feature_25', 'chemberta2_feature_26', 'chemberta2_feature_28', 'chemberta2_feature_29', 'chemberta2_feature_31', 'chemberta2_feature_32', 'chemberta2_feature_34', 'chemberta2_feature_37', 'chemberta2_feature_39', 'chemberta2_feature_41', 'chemberta2_feature_43', 'chemberta2_feature_44', 'chemberta2_feature_46', 'chemberta2_feature_48', 'chemberta2_feature_49', 'chemberta2_feature_50', 'chemberta2_feature_52', 'chemberta2_feature_53', 'chemberta2_feature_54', 'chemberta2_feature_55', 'chemberta2_feature_57', 'chemberta2_feature_58', 'chemberta2_feature_64', 'chemberta2_feature_65', 'chemberta2_feature_66', 'chemberta2_feature_68', 'chemberta2_feature_69', 'chemberta2_feature_72', 'chemberta2_feature_74', 'chemberta2_feature_76', 'chemberta2_feature_78', 'chemberta2_feature_79', 'chemberta2_feature_80', 'chemberta2_feature_83', 'chemberta2_feature_84', 'chemberta2_feature_85', 'chemberta2_feature_86', 'chemberta2_feature_88', 'chemberta2_feature_90', 'chemberta2_feature_91', 'chemberta2_feature_92', 'chemberta2_feature_93', 'chemberta2_feature_94', 'chemberta2_feature_95', 'chemberta2_feature_96', 'chemberta2_feature_97', 'chemberta2_feature_98', 'chemberta2_feature_99', 'chemberta2_feature_101', 'chemberta2_feature_103', 'chemberta2_feature_104', 'chemberta2_feature_105', 'chemberta2_feature_106', 'chemberta2_feature_107', 'chemberta2_feature_108', 'chemberta2_feature_109', 'chemberta2_feature_110', 'chemberta2_feature_111', 'chemberta2_feature_114', 'chemberta2_feature_116', 'chemberta2_feature_118', 'chemberta2_feature_119', 'chemberta2_feature_123', 'chemberta2_feature_124', 'chemberta2_feature_126', 'chemberta2_feature_127', 'chemberta2_feature_128', 'chemberta2_feature_133', 'chemberta2_feature_134', 'chemberta2_feature_135', 'chemberta2_feature_136', 'chemberta2_feature_137', 'chemberta2_feature_138', 'chemberta2_feature_139', 'chemberta2_feature_140', 'chemberta2_feature_141', 'chemberta2_feature_142', 'chemberta2_feature_143', 'chemberta2_feature_145', 'chemberta2_feature_146', 'chemberta2_feature_147', 'chemberta2_feature_148', 'chemberta2_feature_149', 'chemberta2_feature_151', 'chemberta2_feature_153', 'chemberta2_feature_154', 'chemberta2_feature_158', 'chemberta2_feature_159', 'chemberta2_feature_160', 'chemberta2_feature_161', 'chemberta2_feature_163', 'chemberta2_feature_167', 'chemberta2_feature_168', 'chemberta2_feature_169', 'chemberta2_feature_170', 'chemberta2_feature_172', 'chemberta2_feature_174', 'chemberta2_feature_175', 'chemberta2_feature_179', 'chemberta2_feature_180', 'chemberta2_feature_183', 'chemberta2_feature_184', 'chemberta2_feature_185', 'chemberta2_feature_188', 'chemberta2_feature_189', 'chemberta2_feature_195', 'chemberta2_feature_196', 'chemberta2_feature_197', 'chemberta2_feature_199', 'chemberta2_feature_200', 'chemberta2_feature_204', 'chemberta2_feature_206', 'chemberta2_feature_207', 'chemberta2_feature_209', 'chemberta2_feature_210', 'chemberta2_feature_211', 'chemberta2_feature_212', 'chemberta2_feature_213', 'chemberta2_feature_216', 'chemberta2_feature_217', 'chemberta2_feature_218', 'chemberta2_feature_220', 'chemberta2_feature_222', 'chemberta2_feature_226', 'chemberta2_feature_227', 'chemberta2_feature_228', 'chemberta2_feature_230', 'chemberta2_feature_231', 'chemberta2_feature_232', 'chemberta2_feature_233', 'chemberta2_feature_234', 'chemberta2_feature_236', 'chemberta2_feature_237', 'chemberta2_feature_241', 'chemberta2_feature_242', 'chemberta2_feature_243', 'chemberta2_feature_245', 'chemberta2_feature_247', 'chemberta2_feature_251', 'chemberta2_feature_252', 'chemberta2_feature_253', 'chemberta2_feature_255', 'chemberta2_feature_256', 'chemberta2_feature_258', 'chemberta2_feature_259', 'chemberta2_feature_260', 'chemberta2_feature_261', 'chemberta2_feature_265', 'chemberta2_feature_266', 'chemberta2_feature_268', 'chemberta2_feature_269', 'chemberta2_feature_271', 'chemberta2_feature_272', 'chemberta2_feature_275', 'chemberta2_feature_279', 'chemberta2_feature_280', 'chemberta2_feature_281', 'chemberta2_feature_282', 'chemberta2_feature_283', 'chemberta2_feature_284', 'chemberta2_feature_285', 'chemberta2_feature_286', 'chemberta2_feature_290', 'chemberta2_feature_292', 'chemberta2_feature_293', 'chemberta2_feature_294', 'chemberta2_feature_295', 'chemberta2_feature_299', 'chemberta2_feature_300', 'chemberta2_feature_303', 'chemberta2_feature_304', 'chemberta2_feature_305', 'chemberta2_feature_306', 'chemberta2_feature_308', 'chemberta2_feature_309', 'chemberta2_feature_310', 'chemberta2_feature_312', 'chemberta2_feature_313', 'chemberta2_feature_314', 'chemberta2_feature_315', 'chemberta2_feature_316', 'chemberta2_feature_320', 'chemberta2_feature_321', 'chemberta2_feature_322', 'chemberta2_feature_323', 'chemberta2_feature_325', 'chemberta2_feature_326', 'chemberta2_feature_327', 'chemberta2_feature_328', 'chemberta2_feature_330', 'chemberta2_feature_332', 'chemberta2_feature_334', 'chemberta2_feature_336', 'chemberta2_feature_339', 'chemberta2_feature_342', 'chemberta2_feature_343', 'chemberta2_feature_344', 'chemberta2_feature_346', 'chemberta2_feature_347', 'chemberta2_feature_348', 'chemberta2_feature_350', 'chemberta2_feature_351', 'chemberta2_feature_353', 'chemberta2_feature_354', 'chemberta2_feature_356', 'chemberta2_feature_359', 'chemberta2_feature_360', 'chemberta2_feature_364', 'chemberta2_feature_368', 'chemberta2_feature_370', 'chemberta2_feature_374', 'chemberta2_feature_375', 'chemberta2_feature_376', 'chemberta2_feature_379', 'chemberta2_feature_382', 'chemberta2_feature_384', 'molformer_feature_2', 'molformer_feature_3', 'molformer_feature_4', 'molformer_feature_7', 'molformer_feature_8', 'molformer_feature_9', 'molformer_feature_11', 'molformer_feature_16', 'molformer_feature_17', 'molformer_feature_18', 'molformer_feature_19', 'molformer_feature_20', 'molformer_feature_21', 'molformer_feature_23', 'molformer_feature_25', 'molformer_feature_27', 'molformer_feature_28', 'molformer_feature_30', 'molformer_feature_32', 'molformer_feature_34', 'molformer_feature_35', 'molformer_feature_40', 'molformer_feature_42', 'molformer_feature_45', 'molformer_feature_47', 'molformer_feature_48', 'molformer_feature_52', 'molformer_feature_54', 'molformer_feature_58', 'molformer_feature_64', 'molformer_feature_65', 'molformer_feature_66', 'molformer_feature_67', 'molformer_feature_69', 'molformer_feature_72', 'molformer_feature_73', 'molformer_feature_74', 'molformer_feature_76', 'molformer_feature_77', 'molformer_feature_78', 'molformer_feature_79', 'molformer_feature_80', 'molformer_feature_81', 'molformer_feature_82', 'molformer_feature_83', 'molformer_feature_88', 'molformer_feature_89', 'molformer_feature_90', 'molformer_feature_92', 'molformer_feature_93', 'molformer_feature_94', 'molformer_feature_95', 'molformer_feature_96', 'molformer_feature_98', 'molformer_feature_99', 'molformer_feature_103', 'molformer_feature_104', 'molformer_feature_106', 'molformer_feature_108', 'molformer_feature_111', 'molformer_feature_112', 'molformer_feature_113', 'molformer_feature_114', 'molformer_feature_117', 'molformer_feature_118', 'molformer_feature_119', 'molformer_feature_120', 'molformer_feature_122', 'molformer_feature_126', 'molformer_feature_130', 'molformer_feature_132', 'molformer_feature_133', 'molformer_feature_136', 'molformer_feature_138', 'molformer_feature_139', 'molformer_feature_140', 'molformer_feature_141', 'molformer_feature_143', 'molformer_feature_146', 'molformer_feature_147', 'molformer_feature_148', 'molformer_feature_149', 'molformer_feature_150', 'molformer_feature_151', 'molformer_feature_152', 'molformer_feature_153', 'molformer_feature_154', 'molformer_feature_155', 'molformer_feature_158', 'molformer_feature_159', 'molformer_feature_163', 'molformer_feature_164', 'molformer_feature_165', 'molformer_feature_166', 'molformer_feature_168', 'molformer_feature_170', 'molformer_feature_172', 'molformer_feature_173', 'molformer_feature_174', 'molformer_feature_175', 'molformer_feature_177', 'molformer_feature_178', 'molformer_feature_179', 'molformer_feature_182', 'molformer_feature_184', 'molformer_feature_185', 'molformer_feature_186', 'molformer_feature_188', 'molformer_feature_193', 'molformer_feature_196', 'molformer_feature_197', 'molformer_feature_198', 'molformer_feature_201', 'molformer_feature_202', 'molformer_feature_206', 'molformer_feature_207', 'molformer_feature_208', 'molformer_feature_209', 'molformer_feature_210', 'molformer_feature_211', 'molformer_feature_212', 'molformer_feature_216', 'molformer_feature_218', 'molformer_feature_219', 'molformer_feature_220', 'molformer_feature_223', 'molformer_feature_225', 'molformer_feature_226', 'molformer_feature_228', 'molformer_feature_229', 'molformer_feature_230', 'molformer_feature_231', 'molformer_feature_232', 'molformer_feature_235', 'molformer_feature_236', 'molformer_feature_238', 'molformer_feature_239', 'molformer_feature_241', 'molformer_feature_242', 'molformer_feature_243', 'molformer_feature_244', 'molformer_feature_247', 'molformer_feature_248', 'molformer_feature_250', 'molformer_feature_252', 'molformer_feature_254', 'molformer_feature_257', 'molformer_feature_259', 'molformer_feature_263', 'molformer_feature_264', 'molformer_feature_265', 'molformer_feature_267', 'molformer_feature_268', 'molformer_feature_269', 'molformer_feature_274', 'molformer_feature_275', 'molformer_feature_277', 'molformer_feature_278', 'molformer_feature_279', 'molformer_feature_280', 'molformer_feature_282', 'molformer_feature_283', 'molformer_feature_284', 'molformer_feature_285', 'molformer_feature_286', 'molformer_feature_287', 'molformer_feature_288', 'molformer_feature_289', 'molformer_feature_290', 'molformer_feature_292', 'molformer_feature_293', 'molformer_feature_298', 'molformer_feature_299', 'molformer_feature_301', 'molformer_feature_303', 'molformer_feature_304', 'molformer_feature_305', 'molformer_feature_307', 'molformer_feature_308', 'molformer_feature_317', 'molformer_feature_319', 'molformer_feature_322', 'molformer_feature_323', 'molformer_feature_324', 'molformer_feature_327', 'molformer_feature_330', 'molformer_feature_331', 'molformer_feature_334', 'molformer_feature_335', 'molformer_feature_336', 'molformer_feature_337', 'molformer_feature_338', 'molformer_feature_342', 'molformer_feature_344', 'molformer_feature_346', 'molformer_feature_347', 'molformer_feature_348', 'molformer_feature_350', 'molformer_feature_351', 'molformer_feature_352', 'molformer_feature_355', 'molformer_feature_358', 'molformer_feature_359', 'molformer_feature_361', 'molformer_feature_362', 'molformer_feature_368', 'molformer_feature_369', 'molformer_feature_372', 'molformer_feature_373', 'molformer_feature_374', 'molformer_feature_377', 'molformer_feature_380', 'molformer_feature_386', 'molformer_feature_387', 'molformer_feature_389', 'molformer_feature_390', 'molformer_feature_393', 'molformer_feature_395', 'molformer_feature_398', 'molformer_feature_401', 'molformer_feature_404', 'molformer_feature_405', 'molformer_feature_406', 'molformer_feature_408', 'molformer_feature_409', 'molformer_feature_412', 'molformer_feature_414', 'molformer_feature_418', 'molformer_feature_419', 'molformer_feature_420', 'molformer_feature_422', 'molformer_feature_425', 'molformer_feature_427', 'molformer_feature_428', 'molformer_feature_429', 'molformer_feature_431', 'molformer_feature_434', 'molformer_feature_435', 'molformer_feature_438', 'molformer_feature_439', 'molformer_feature_440', 'molformer_feature_444', 'molformer_feature_445', 'molformer_feature_447', 'molformer_feature_448', 'molformer_feature_452', 'molformer_feature_453', 'molformer_feature_455', 'molformer_feature_461', 'molformer_feature_465', 'molformer_feature_466', 'molformer_feature_468', 'molformer_feature_469', 'molformer_feature_471', 'molformer_feature_472', 'molformer_feature_473', 'molformer_feature_475', 'molformer_feature_476', 'molformer_feature_479', 'molformer_feature_482', 'molformer_feature_484', 'molformer_feature_488', 'molformer_feature_489', 'molformer_feature_490', 'molformer_feature_492', 'molformer_feature_493', 'molformer_feature_497', 'molformer_feature_498', 'molformer_feature_499', 'molformer_feature_501', 'molformer_feature_503', 'molformer_feature_504', 'molformer_feature_506', 'molformer_feature_507', 'molformer_feature_511', 'molformer_feature_513', 'molformer_feature_514', 'molformer_feature_519', 'molformer_feature_521', 'molformer_feature_522', 'molformer_feature_524', 'molformer_feature_525', 'molformer_feature_526', 'molformer_feature_527', 'molformer_feature_528', 'molformer_feature_530', 'molformer_feature_533', 'molformer_feature_538', 'molformer_feature_540', 'molformer_feature_542', 'molformer_feature_549', 'molformer_feature_551', 'molformer_feature_552', 'molformer_feature_553', 'molformer_feature_556', 'molformer_feature_558', 'molformer_feature_559', 'molformer_feature_560', 'molformer_feature_561', 'molformer_feature_562', 'molformer_feature_563', 'molformer_feature_564', 'molformer_feature_565', 'molformer_feature_566', 'molformer_feature_567', 'molformer_feature_571', 'molformer_feature_572', 'molformer_feature_575', 'molformer_feature_576', 'molformer_feature_577', 'molformer_feature_580', 'molformer_feature_583', 'molformer_feature_585', 'molformer_feature_586', 'molformer_feature_588', 'molformer_feature_589', 'molformer_feature_590', 'molformer_feature_591', 'molformer_feature_592', 'molformer_feature_593', 'molformer_feature_595', 'molformer_feature_596', 'molformer_feature_599', 'molformer_feature_601', 'molformer_feature_602', 'molformer_feature_603', 'molformer_feature_604', 'molformer_feature_606', 'molformer_feature_607', 'molformer_feature_608', 'molformer_feature_609', 'molformer_feature_610', 'molformer_feature_611', 'molformer_feature_613', 'molformer_feature_615', 'molformer_feature_616', 'molformer_feature_619', 'molformer_feature_620', 'molformer_feature_626', 'molformer_feature_628', 'molformer_feature_629', 'molformer_feature_631', 'molformer_feature_634', 'molformer_feature_635', 'molformer_feature_637', 'molformer_feature_638', 'molformer_feature_641', 'molformer_feature_642', 'molformer_feature_643', 'molformer_feature_645', 'molformer_feature_646', 'molformer_feature_647', 'molformer_feature_648', 'molformer_feature_650', 'molformer_feature_651', 'molformer_feature_652', 'molformer_feature_653', 'molformer_feature_655', 'molformer_feature_660', 'molformer_feature_661', 'molformer_feature_663', 'molformer_feature_664', 'molformer_feature_666', 'molformer_feature_667', 'molformer_feature_675', 'molformer_feature_676', 'molformer_feature_680', 'molformer_feature_681', 'molformer_feature_682', 'molformer_feature_683', 'molformer_feature_684', 'molformer_feature_686', 'molformer_feature_690', 'molformer_feature_691', 'molformer_feature_692', 'molformer_feature_693', 'molformer_feature_695', 'molformer_feature_696', 'molformer_feature_697', 'molformer_feature_700', 'molformer_feature_701', 'molformer_feature_702', 'molformer_feature_706', 'molformer_feature_707', 'molformer_feature_709', 'molformer_feature_710', 'molformer_feature_713', 'molformer_feature_715', 'molformer_feature_716', 'molformer_feature_719', 'molformer_feature_722', 'molformer_feature_723', 'molformer_feature_725', 'molformer_feature_726', 'molformer_feature_727', 'molformer_feature_729', 'molformer_feature_730', 'molformer_feature_731', 'molformer_feature_732', 'molformer_feature_735', 'molformer_feature_736', 'molformer_feature_738', 'molformer_feature_740', 'molformer_feature_744', 'molformer_feature_745', 'molformer_feature_747', 'molformer_feature_748', 'molformer_feature_749', 'molformer_feature_751', 'molformer_feature_752', 'molformer_feature_753', 'molformer_feature_754', 'molformer_feature_756', 'molformer_feature_758', 'molformer_feature_760', 'molformer_feature_761', 'molformer_feature_762', 'molformer_feature_764', 'molformer_feature_765', 'molformer_feature_766', 'molformer_feature_768', 'molbert_features_4', 'molbert_features_5', 'molbert_features_7', 'molbert_features_9', 'molbert_features_12', 'molbert_features_14', 'molbert_features_17', 'molbert_features_21', 'molbert_features_24', 'molbert_features_25', 'molbert_features_26', 'molbert_features_38', 'molbert_features_42', 'molbert_features_43', 'molbert_features_46', 'molbert_features_47', 'molbert_features_51', 'molbert_features_53', 'molbert_features_54', 'molbert_features_56', 'molbert_features_59', 'molbert_features_61', 'molbert_features_62', 'molbert_features_63', 'molbert_features_64', 'molbert_features_65', 'molbert_features_66', 'molbert_features_68', 'molbert_features_69', 'molbert_features_73', 'molbert_features_74', 'molbert_features_76', 'molbert_features_77', 'molbert_features_78', 'molbert_features_82', 'molbert_features_83', 'molbert_features_84', 'molbert_features_86', 'molbert_features_88', 'molbert_features_91', 'molbert_features_97', 'molbert_features_99', 'molbert_features_100', 'molbert_features_102', 'molbert_features_104', 'molbert_features_105', 'molbert_features_106', 'molbert_features_107', 'molbert_features_110', 'molbert_features_111', 'molbert_features_118', 'molbert_features_124', 'molbert_features_125', 'molbert_features_129', 'molbert_features_131', 'molbert_features_132', 'molbert_features_133', 'molbert_features_137', 'molbert_features_140', 'molbert_features_144', 'molbert_features_145', 'molbert_features_150', 'molbert_features_151', 'molbert_features_157', 'molbert_features_158', 'molbert_features_159', 'molbert_features_160', 'molbert_features_161', 'molbert_features_162', 'molbert_features_163', 'molbert_features_165', 'molbert_features_170', 'molbert_features_175', 'molbert_features_178', 'molbert_features_180', 'molbert_features_183', 'molbert_features_185', 'molbert_features_187', 'molbert_features_188', 'molbert_features_190', 'molbert_features_191', 'molbert_features_197', 'molbert_features_198', 'molbert_features_204', 'molbert_features_205', 'molbert_features_209', 'molbert_features_210', 'molbert_features_211', 'molbert_features_213', 'molbert_features_215', 'molbert_features_217', 'molbert_features_220', 'molbert_features_223', 'molbert_features_224', 'molbert_features_225', 'molbert_features_230', 'molbert_features_231', 'molbert_features_233', 'molbert_features_234', 'molbert_features_239', 'molbert_features_240', 'molbert_features_242', 'molbert_features_246', 'molbert_features_247', 'molbert_features_248', 'molbert_features_250', 'molbert_features_251', 'molbert_features_256', 'molbert_features_257', 'molbert_features_259', 'molbert_features_260', 'molbert_features_261', 'molbert_features_264', 'molbert_features_265', 'molbert_features_266', 'molbert_features_268', 'molbert_features_269', 'molbert_features_270', 'molbert_features_271', 'molbert_features_275', 'molbert_features_277', 'molbert_features_278', 'molbert_features_279', 'molbert_features_281', 'molbert_features_282', 'molbert_features_283', 'molbert_features_284', 'molbert_features_285', 'molbert_features_287', 'molbert_features_289', 'molbert_features_294', 'molbert_features_295', 'molbert_features_296', 'molbert_features_297', 'molbert_features_299', 'molbert_features_300', 'molbert_features_306', 'molbert_features_313', 'molbert_features_317', 'molbert_features_320', 'molbert_features_322', 'molbert_features_325', 'molbert_features_326', 'molbert_features_328', 'molbert_features_329', 'molbert_features_333', 'molbert_features_335', 'molbert_features_337', 'molbert_features_339', 'molbert_features_342', 'molbert_features_343', 'molbert_features_346', 'molbert_features_349', 'molbert_features_353', 'molbert_features_355', 'molbert_features_362', 'molbert_features_363', 'molbert_features_364', 'molbert_features_369', 'molbert_features_370', 'molbert_features_373', 'molbert_features_374', 'molbert_features_375', 'molbert_features_376', 'molbert_features_382', 'molbert_features_386', 'molbert_features_387', 'molbert_features_389', 'molbert_features_391', 'molbert_features_392', 'molbert_features_394', 'molbert_features_398', 'molbert_features_399', 'molbert_features_403', 'molbert_features_408', 'molbert_features_409', 'molbert_features_410', 'molbert_features_411', 'molbert_features_418', 'molbert_features_419', 'molbert_features_421', 'molbert_features_427', 'molbert_features_429', 'molbert_features_431', 'molbert_features_432', 'molbert_features_434', 'molbert_features_435', 'molbert_features_436', 'molbert_features_439', 'molbert_features_441', 'molbert_features_442', 'molbert_features_444', 'molbert_features_446', 'molbert_features_448', 'molbert_features_449', 'molbert_features_450', 'molbert_features_452', 'molbert_features_457', 'molbert_features_458', 'molbert_features_459', 'molbert_features_461', 'molbert_features_464', 'molbert_features_465', 'molbert_features_468', 'molbert_features_469', 'molbert_features_471', 'molbert_features_473', 'molbert_features_474', 'molbert_features_478', 'molbert_features_479', 'molbert_features_481', 'molbert_features_482', 'molbert_features_484', 'molbert_features_485', 'molbert_features_487', 'molbert_features_488', 'molbert_features_489', 'molbert_features_490', 'molbert_features_492', 'molbert_features_495', 'molbert_features_497', 'molbert_features_498', 'molbert_features_500', 'molbert_features_502', 'molbert_features_503', 'molbert_features_509', 'molbert_features_512', 'molbert_features_515', 'molbert_features_516', 'molbert_features_517', 'molbert_features_519', 'molbert_features_526', 'molbert_features_527', 'molbert_features_530', 'molbert_features_536', 'molbert_features_540', 'molbert_features_542', 'molbert_features_543', 'molbert_features_544', 'molbert_features_546', 'molbert_features_548', 'molbert_features_550', 'molbert_features_553', 'molbert_features_555', 'molbert_features_560', 'molbert_features_561', 'molbert_features_563', 'molbert_features_565', 'molbert_features_566', 'molbert_features_567', 'molbert_features_569', 'molbert_features_573', 'molbert_features_575', 'molbert_features_576', 'molbert_features_578', 'molbert_features_579', 'molbert_features_580', 'molbert_features_582', 'molbert_features_585', 'molbert_features_586', 'molbert_features_587', 'molbert_features_592', 'molbert_features_595', 'molbert_features_596', 'molbert_features_597', 'molbert_features_599', 'molbert_features_605', 'molbert_features_609', 'molbert_features_614', 'molbert_features_615', 'molbert_features_616', 'molbert_features_618', 'molbert_features_619', 'molbert_features_623', 'molbert_features_624', 'molbert_features_629', 'molbert_features_630', 'molbert_features_637', 'molbert_features_638', 'molbert_features_642', 'molbert_features_646', 'molbert_features_648', 'molbert_features_649', 'molbert_features_653', 'molbert_features_654', 'molbert_features_655', 'molbert_features_657', 'molbert_features_662', 'molbert_features_665', 'molbert_features_668', 'molbert_features_669', 'molbert_features_675', 'molbert_features_676', 'molbert_features_677', 'molbert_features_684', 'molbert_features_688', 'molbert_features_689', 'molbert_features_690', 'molbert_features_691', 'molbert_features_692', 'molbert_features_694', 'molbert_features_699', 'molbert_features_700', 'molbert_features_701', 'molbert_features_715', 'molbert_features_716', 'molbert_features_720', 'molbert_features_723', 'molbert_features_725', 'molbert_features_727', 'molbert_features_728', 'molbert_features_729', 'molbert_features_730', 'molbert_features_732', 'molbert_features_733', 'molbert_features_736', 'molbert_features_737', 'molbert_features_739', 'molbert_features_750', 'molbert_features_752', 'molbert_features_755', 'molbert_features_756', 'molbert_features_760', 'molbert_features_761', 'molbert_features_767']\n"
     ]
    }
   ],
   "source": [
    "# check coefficients\n",
    "coefs = pd.Series(ct_best_elastic_model.coef_[0], index=ct_X_ensemble_valid2.columns)\n",
    "\n",
    "# Filter to get the selected features\n",
    "selected_features = coefs[coefs != 0].index.tolist()\n",
    "\n",
    "print(\"Selected Features:\", selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(295, 1923)\n",
      "(145, 1923)\n"
     ]
    }
   ],
   "source": [
    "ct_X_ensemble_valid2_selected = ct_X_ensemble_valid2_scaled\n",
    "ct_X_ensemble_test_selected = ct_X_ensemble_test_scaled\n",
    "# check shapes\n",
    "print(ct_X_ensemble_valid2_selected.shape)\n",
    "print(ct_X_ensemble_test_selected.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.9586206896551724,\n",
       " 'F1 Score': 0.5714285714285714,\n",
       " 'ROC-AUC': 0.9518518518518518,\n",
       " 'PR-AUC': 0.8479001825928181}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and train the SVM model\n",
    "from sklearn.svm import SVC\n",
    "import random\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "ct_svm_model = SVC(probability=True, random_state=0)\n",
    "ct_svm_model.fit(ct_X_ensemble_valid2_selected, ct_y_ensemble_valid2)\n",
    "\n",
    "# Predict the test set\n",
    "ct_svm_pred = ct_svm_model.predict(ct_X_ensemble_test_selected)\n",
    "ct_svm_probs = ct_svm_model.predict_proba(ct_X_ensemble_test_selected)\n",
    "\n",
    "# Calculate the metrics\n",
    "ct_svm_metrics = {\n",
    "    'Accuracy': accuracy_score(ct_y_ensemble_test, ct_svm_pred),\n",
    "    'F1 Score': f1_score(ct_y_ensemble_test, ct_svm_pred),\n",
    "    'ROC-AUC': roc_auc_score(ct_y_ensemble_test, ct_svm_probs[:, 1]),\n",
    "    \"PR-AUC\": average_precision_score(ct_y_ensemble_test, ct_svm_probs[:, 1])\n",
    "}\n",
    "\n",
    "ct_svm_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.9586206896551724,\n",
       " 'F1 Score': 0.5714285714285714,\n",
       " 'ROC-AUC': 0.9537037037037037,\n",
       " 'PR-AUC': 0.7985493230174081}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initailize and use a 5-fold cross-validation to tune the hyperparameters of a random forest model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "ct_rf_model = RandomForestClassifier(random_state=0)\n",
    "\n",
    "ct_rf_model.fit(ct_X_ensemble_valid2_selected, ct_y_ensemble_valid2)\n",
    "\n",
    "# Predict the test set\n",
    "ct_rf_best_pred = ct_rf_model.predict(ct_X_ensemble_test_selected)\n",
    "ct_rf_best_probs = ct_rf_model.predict_proba(ct_X_ensemble_test_selected)\n",
    "\n",
    "# Calculate the metrics\n",
    "ct_rf_best_metrics = {\n",
    "    \"Accuracy\": accuracy_score(ct_y_ensemble_test, ct_rf_best_pred),\n",
    "    \"F1 Score\": f1_score(ct_y_ensemble_test, ct_rf_best_pred),\n",
    "    \"ROC-AUC\": roc_auc_score(ct_y_ensemble_test, ct_rf_best_probs[:, 1]),\n",
    "    \"PR-AUC\": average_precision_score(ct_y_ensemble_test, ct_rf_best_probs[:, 1])\n",
    "}\n",
    "\n",
    "ct_rf_best_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [00:28<01:53,  2.83s/trial, best loss: -0.9099999999999999]\n",
      "Best hyperparameters: {'colsample_bytree': 0.9526919134012697, 'learning_rate': 0.25068293229696836, 'max_depth': 4.0, 'n_estimators': 100.0, 'subsample': 0.8411318103731124}\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score, make_scorer\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.early_stop import no_progress_loss\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "# Define the hyperparameter space using continuous distributions\n",
    "ct_xgb_hyperopt_space = {\n",
    "    'n_estimators': hp.quniform('n_estimators', 50, 200, 50),\n",
    "    'max_depth': hp.quniform('max_depth', 3, 7, 2),\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.001, 0.3),\n",
    "    'subsample': hp.uniform('subsample', 0.5, 1.0),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1.0)\n",
    "}\n",
    "\n",
    "# Convert float outputs of hp.quniform to int for certain parameters\n",
    "def objective(params):\n",
    "    params['n_estimators'] = int(params['n_estimators'])\n",
    "    params['max_depth'] = int(params['max_depth'])\n",
    "    \n",
    "    model = xgb.XGBClassifier(**params, random_state=0)\n",
    "    \n",
    "    # Cross-validated AUC score as the objective\n",
    "    roc_auc = make_scorer(roc_auc_score, response_method=None)\n",
    "    score = cross_val_score(model, ct_X_ensemble_valid2_selected, ct_y_ensemble_valid2, scoring=roc_auc, cv=5)\n",
    "    \n",
    "    # Minimize the negative ROC AUC score\n",
    "    return {'loss': -score.mean(), 'status': STATUS_OK}\n",
    "\n",
    "# Run the Bayesian optimization\n",
    "trials = Trials()\n",
    "ct_xgb_best_params = fmin(fn=objective, \n",
    "                          space=ct_xgb_hyperopt_space, \n",
    "                          algo=tpe.suggest, \n",
    "                          max_evals=50, \n",
    "                          trials=trials,\n",
    "                          rstate=np.random.default_rng(0),  # Seed for hyperopt\n",
    "                          early_stop_fn=no_progress_loss(10))\n",
    "\n",
    "print(\"Best hyperparameters:\", ct_xgb_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.9862068965517241,\n",
       " 'F1 Score': 0.8888888888888888,\n",
       " 'ROC-AUC': 0.9903703703703703,\n",
       " 'PR-AUC': 0.9354545454545454}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert parameters obtained from Hyperopt to the correct data type\n",
    "ct_xgb_best_params['n_estimators'] = int(ct_xgb_best_params['n_estimators'])\n",
    "ct_xgb_best_params['max_depth'] = int(ct_xgb_best_params['max_depth'])\n",
    "\n",
    "# Initialize and train the XGBoost model with the best parameters\n",
    "ct_xgb_model = xgb.XGBClassifier(**ct_xgb_best_params, random_state=0)\n",
    "ct_xgb_model.fit(ct_X_ensemble_valid2_selected, ct_y_ensemble_valid2)\n",
    "\n",
    "# Predict the test set\n",
    "ct_xgb_best_pred = ct_xgb_model.predict(ct_X_ensemble_test_selected)\n",
    "ct_xgb_best_probs = ct_xgb_model.predict_proba(ct_X_ensemble_test_selected)\n",
    "\n",
    "# Calculate the metrics\n",
    "ct_xgb_best_metrics = {\n",
    "    \"Accuracy\": accuracy_score(ct_y_ensemble_test, ct_xgb_best_pred),\n",
    "    \"F1 Score\": f1_score(ct_y_ensemble_test, ct_xgb_best_pred),\n",
    "    \"ROC-AUC\": roc_auc_score(ct_y_ensemble_test, ct_xgb_best_probs[:, 1]),\n",
    "    \"PR-AUC\": average_precision_score(ct_y_ensemble_test, ct_xgb_best_probs[:, 1])\n",
    "}\n",
    "\n",
    "ct_xgb_best_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 33/50 [03:48<01:57,  6.92s/trial, best loss: -0.9694053744997142]\n",
      "Best hyperparameters: {'dropout_rate': 0.05859227318975018, 'learning_rate': 0.0014876330911043408, 'num_layers': 4.0, 'num_neurons': 227.0}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.early_stop import no_progress_loss\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Define the neural network model\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, num_layers, num_neurons, dropout_rate):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        layers = [nn.Linear(input_size, num_neurons), nn.ReLU(), nn.Dropout(dropout_rate)]\n",
    "        \n",
    "        for _ in range(num_layers - 1):\n",
    "            layers += [nn.Linear(num_neurons, num_neurons), nn.ReLU(), nn.Dropout(dropout_rate)]\n",
    "        \n",
    "        layers += [nn.Linear(num_neurons, 1), nn.Sigmoid()]\n",
    "        \n",
    "        self.layers = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "# Objective function for Bayesian optimization\n",
    "def objective(params):\n",
    "    kf = KFold(n_splits=5)\n",
    "    roc_aucs = []\n",
    "\n",
    "    for train_index, val_index in kf.split(X):\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "        train_dataset = TensorDataset(torch.tensor(X_train.values.astype(np.float32)), \n",
    "                                      torch.tensor(y_train.values.astype(np.float32)).unsqueeze(1))\n",
    "        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "        model = SimpleNN(input_size=X_train.shape[1], num_layers=int(params['num_layers']), \n",
    "                         num_neurons=int(params['num_neurons']), dropout_rate=params['dropout_rate'])\n",
    "        criterion = nn.BCELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=params['learning_rate'])\n",
    "\n",
    "        model.train()\n",
    "        for epoch in range(100):\n",
    "            for inputs, targets in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            X_val_tensor = torch.tensor(X_val.values.astype(np.float32))\n",
    "            y_val_tensor = torch.tensor(y_val.values.astype(np.float32)).unsqueeze(-1)\n",
    "            outputs = model(X_val_tensor)\n",
    "            roc_auc = roc_auc_score(y_val_tensor.numpy(), outputs.numpy())\n",
    "            roc_aucs.append(roc_auc)\n",
    "\n",
    "    avg_roc_auc = np.mean(roc_aucs)\n",
    "    return {'loss': -avg_roc_auc, 'status': STATUS_OK}  # Maximize ROC AUC by minimizing the negative ROC AUC\n",
    "\n",
    "# Hyperparameter space\n",
    "space = {\n",
    "    'num_layers': hp.quniform('num_layers', 1, 5, 1),\n",
    "    'num_neurons': hp.quniform('num_neurons', 16, 256, 1),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.0001), np.log(0.01)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.0, 0.5)\n",
    "}\n",
    "\n",
    "X = ct_X_ensemble_valid2_selected\n",
    "y = ct_y_ensemble_valid2\n",
    "\n",
    "# Run Bayesian optimization\n",
    "trials = Trials()\n",
    "ct_nn_best_params = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=50,\n",
    "            trials=trials,\n",
    "            rstate=np.random.default_rng(0),  # Seed for hyperopt\n",
    "            early_stop_fn=no_progress_loss(10))\n",
    "\n",
    "print(\"Best hyperparameters:\", ct_nn_best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.9586206896551724,\n",
       " 'F1 Score': 0.7272727272727273,\n",
       " 'ROC-AUC': 0.9477777777777778,\n",
       " 'PR-AUC': 0.7598710317460318}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Define the neural network model again\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, num_layers, num_neurons, dropout_rate):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        layers = [nn.Linear(input_size, num_neurons), nn.ReLU(), nn.Dropout(dropout_rate)]\n",
    "        \n",
    "        for _ in range(num_layers - 1):\n",
    "            layers += [nn.Linear(num_neurons, num_neurons), nn.ReLU(), nn.Dropout(dropout_rate)]\n",
    "        \n",
    "        layers += [nn.Linear(num_neurons, 1), nn.Sigmoid()]\n",
    "        \n",
    "        self.layers = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "# Convert parameters to the correct format if necessary\n",
    "ct_nn_best_params = {\n",
    "    'num_layers': int(ct_nn_best_params['num_layers']),  # Extracted from Bayesian optimization results\n",
    "    'num_neurons': int(ct_nn_best_params['num_neurons']),  # Extracted from Bayesian optimization results\n",
    "    'dropout_rate': ct_nn_best_params['dropout_rate'],  # Extracted from Bayesian optimization results\n",
    "    'learning_rate': ct_nn_best_params['learning_rate']  # Extracted from Bayesian optimization results\n",
    "}\n",
    "\n",
    "# Prepare datasets\n",
    "X_train_tensor = torch.tensor(ct_X_ensemble_valid2_selected.values.astype(np.float32))\n",
    "y_train_tensor = torch.tensor(ct_y_ensemble_valid2.values.astype(np.float32)).unsqueeze(1)\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "X_test_tensor = torch.tensor(ct_X_ensemble_test_selected.values.astype(np.float32))\n",
    "y_test_tensor = torch.tensor(ct_y_ensemble_test.values.astype(np.float32)).unsqueeze(1)\n",
    "\n",
    "# Initialize the model\n",
    "model = SimpleNN(input_size=ct_X_ensemble_valid2_selected.shape[1], num_layers=ct_nn_best_params['num_layers'], \n",
    "                 num_neurons=ct_nn_best_params['num_neurons'], dropout_rate=ct_nn_best_params['dropout_rate'])\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=ct_nn_best_params['learning_rate'])\n",
    "\n",
    "# Training loop\n",
    "model.train()\n",
    "for epoch in range(100):  # Number of epochs can be adjusted\n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Evaluation on test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_test_tensor)\n",
    "    predictions = (outputs > 0.5).float()\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test_tensor.numpy(), predictions.numpy())\n",
    "    f1 = f1_score(y_test_tensor.numpy(), predictions.numpy())\n",
    "    roc_auc = roc_auc_score(y_test_tensor.numpy(), outputs.numpy())\n",
    "    pr_auc = average_precision_score(y_test_tensor.numpy(), outputs.numpy())\n",
    "\n",
    "    ct_nn_metrics = {\n",
    "        'Accuracy': accuracy,\n",
    "        'F1 Score': f1,\n",
    "        'ROC-AUC': roc_auc,\n",
    "        'PR-AUC': pr_auc\n",
    "    }\n",
    "\n",
    "ct_nn_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report all the metrics for ct\n",
    "ct_metrics_results[\"LASSO\"] = ct_lasso_metrics\n",
    "ct_metrics_results[\"Group Lasso (Two Groups)\"] = ct_two_groups_lasso_metrics\n",
    "ct_metrics_results[\"Group Lasso (Four Groups)\"] = ct_four_groups_lasso_metrics\n",
    "ct_metrics_results[\"Elastic Net\"] = ct_elastic_metrics\n",
    "ct_metrics_results[\"SVM\"] = ct_svm_metrics\n",
    "ct_metrics_results[\"Random Forest\"] = ct_rf_best_metrics\n",
    "ct_metrics_results[\"XGBoost\"] = ct_xgb_best_metrics\n",
    "ct_metrics_results[\"Neural Network\"] = ct_nn_metrics\n",
    "\n",
    "ct_metrics_df = pd.DataFrame(ct_metrics_results).T\n",
    "\n",
    "# keep 3 digits after the decimal point\n",
    "ct_metrics_df = ct_metrics_df.round(3)\n",
    "\n",
    "# export as csv\n",
    "ct_metrics_df.to_csv('./split3_ct_metrics_rawpreds.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fusion-env",
   "language": "python",
   "name": "fusion-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
